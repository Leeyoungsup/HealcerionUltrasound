{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 18:26:43.976287: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-26 18:26:44.098987: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-26 18:26:44.551385: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda-11.6/lib64:/home/gil/anaconda3/envs/LeeYS/lib/\n",
      "2023-06-26 18:26:44.551532: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda-11.6/lib64:/home/gil/anaconda3/envs/LeeYS/lib/\n",
      "2023-06-26 18:26:44.551542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras import datasets, layers, models, losses, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pre\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_size = (704,768, 3)\n",
    "pd_img_list=pd.read_csv('../../data/original_dataset/data_set.csv')['file_path']\n",
    "img_list=pd_img_list.to_list()\n",
    "pd_label_list=pd.read_csv('../../data/original_dataset/data_set.csv')['standard_frame']\n",
    "label_list=pd_label_list.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=256\n",
    "x = np.zeros((len(img_list),size,size,3))\n",
    "y = np.zeros((len(label_list),1))\n",
    "for i in range(len(img_list)):\n",
    "    x[i] =np.array(Image.open('../../data/original_dataset/'+img_list[i]).resize((size,size)))\n",
    "x=x/255\n",
    "y=np.array(label_list)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 18:28:30.808676: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-26 18:28:31.844882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38153 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0\n",
      "2023-06-26 18:28:31.847030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38153 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:25:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "INFO:tensorflow:batch_all_reduce: 218 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 218 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 18:28:58.035931: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-06-26 18:28:58.775660: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-06-26 18:28:59.572007: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 39s 203ms/step - loss: 0.4725 - accuracy: 0.8401 - val_loss: 0.6705 - val_accuracy: 0.8408\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 0.4257 - accuracy: 0.8485 - val_loss: 0.6519 - val_accuracy: 0.8408\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 18s 172ms/step - loss: 0.3863 - accuracy: 0.8485 - val_loss: 0.6314 - val_accuracy: 0.8408\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 0.3462 - accuracy: 0.8485 - val_loss: 0.6087 - val_accuracy: 0.8408\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 17s 168ms/step - loss: 0.3087 - accuracy: 0.8485 - val_loss: 0.5853 - val_accuracy: 0.8408\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 17s 170ms/step - loss: 0.2700 - accuracy: 0.8485 - val_loss: 0.5634 - val_accuracy: 0.8408\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 18s 173ms/step - loss: 0.2407 - accuracy: 0.8485 - val_loss: 0.5435 - val_accuracy: 0.8408\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 18s 178ms/step - loss: 0.2158 - accuracy: 0.8485 - val_loss: 0.5258 - val_accuracy: 0.8408\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 17s 167ms/step - loss: 0.1955 - accuracy: 0.8485 - val_loss: 0.5100 - val_accuracy: 0.8408\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 0.1787 - accuracy: 0.8485 - val_loss: 0.4937 - val_accuracy: 0.8408\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 0.1668 - accuracy: 0.8485 - val_loss: 0.4523 - val_accuracy: 0.8408\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 0.1568 - accuracy: 0.8485 - val_loss: 0.4432 - val_accuracy: 0.8408\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 17s 171ms/step - loss: 0.1443 - accuracy: 0.8485 - val_loss: 0.4540 - val_accuracy: 0.8408\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 17s 167ms/step - loss: 0.1413 - accuracy: 0.8485 - val_loss: 0.4625 - val_accuracy: 0.8408\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 19s 183ms/step - loss: 0.1347 - accuracy: 0.8485 - val_loss: 0.4715 - val_accuracy: 0.8408\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 19s 188ms/step - loss: 0.1290 - accuracy: 0.8485 - val_loss: 0.4808 - val_accuracy: 0.8408\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 20s 193ms/step - loss: 0.1260 - accuracy: 0.8485 - val_loss: 0.4902 - val_accuracy: 0.8408\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 19s 190ms/step - loss: 0.1231 - accuracy: 0.8485 - val_loss: 0.4994 - val_accuracy: 0.8408\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 19s 189ms/step - loss: 0.1212 - accuracy: 0.8485 - val_loss: 0.5086 - val_accuracy: 0.8408\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 18s 179ms/step - loss: 0.1192 - accuracy: 0.8485 - val_loss: 0.5169 - val_accuracy: 0.8408\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.1176 - accuracy: 0.8485 - val_loss: 0.5253 - val_accuracy: 0.8408\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 0.1181 - accuracy: 0.8485 - val_loss: 0.5329 - val_accuracy: 0.8408\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 0.1158 - accuracy: 0.8485 - val_loss: 0.5398 - val_accuracy: 0.8408\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 0.1136 - accuracy: 0.8485 - val_loss: 0.5458 - val_accuracy: 0.8408\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 0.1148 - accuracy: 0.8485 - val_loss: 0.5513 - val_accuracy: 0.8408\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.1131 - accuracy: 0.8485 - val_loss: 0.4527 - val_accuracy: 0.8408\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 0.1004 - accuracy: 0.8485 - val_loss: 0.5685 - val_accuracy: 0.8408\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 0.0842 - accuracy: 0.8485 - val_loss: 0.3366 - val_accuracy: 0.8408\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 0.0721 - accuracy: 0.8485 - val_loss: 0.2842 - val_accuracy: 0.8408\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 0.0643 - accuracy: 0.8485 - val_loss: 0.2375 - val_accuracy: 0.8408\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 17s 169ms/step - loss: 0.0603 - accuracy: 0.8485 - val_loss: 0.2121 - val_accuracy: 0.8408\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 18s 173ms/step - loss: 0.0546 - accuracy: 0.8758 - val_loss: 0.2319 - val_accuracy: 0.8408\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 0.0560 - accuracy: 0.9367 - val_loss: 0.1827 - val_accuracy: 0.8408\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 0.0505 - accuracy: 0.9495 - val_loss: 0.1676 - val_accuracy: 0.8408\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 0.0465 - accuracy: 0.9515 - val_loss: 0.1498 - val_accuracy: 0.8408\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 0.0417 - accuracy: 0.9585 - val_loss: 0.1379 - val_accuracy: 0.9870\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 0.0429 - accuracy: 0.9554 - val_loss: 0.1236 - val_accuracy: 0.9889\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 0.0388 - accuracy: 0.9602 - val_loss: 0.1164 - val_accuracy: 0.9907\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.0412 - accuracy: 0.9523 - val_loss: 0.1251 - val_accuracy: 0.9766\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 0.0378 - accuracy: 0.9559 - val_loss: 0.2045 - val_accuracy: 0.9260\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 17s 170ms/step - loss: 0.0345 - accuracy: 0.9608 - val_loss: 0.1240 - val_accuracy: 0.9741\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 17s 170ms/step - loss: 0.0357 - accuracy: 0.9552 - val_loss: 0.0951 - val_accuracy: 0.9827\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 17s 168ms/step - loss: 0.0330 - accuracy: 0.9586 - val_loss: 0.0812 - val_accuracy: 0.9907\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 17s 167ms/step - loss: 0.0305 - accuracy: 0.9633 - val_loss: 0.0746 - val_accuracy: 0.9926\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 18s 176ms/step - loss: 0.0301 - accuracy: 0.9614 - val_loss: 0.0729 - val_accuracy: 0.9914\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 18s 178ms/step - loss: 0.0283 - accuracy: 0.9650 - val_loss: 0.0650 - val_accuracy: 0.9926\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 18s 176ms/step - loss: 0.0270 - accuracy: 0.9665 - val_loss: 0.0625 - val_accuracy: 0.9944\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 18s 176ms/step - loss: 0.0251 - accuracy: 0.9693 - val_loss: 0.0517 - val_accuracy: 0.9975\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 0.0274 - accuracy: 0.9631 - val_loss: 0.0511 - val_accuracy: 0.9951\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 17s 170ms/step - loss: 0.0269 - accuracy: 0.9647 - val_loss: 0.0457 - val_accuracy: 0.9963\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 18s 172ms/step - loss: 0.0262 - accuracy: 0.9657 - val_loss: 0.0492 - val_accuracy: 0.9926\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 17s 168ms/step - loss: 0.0253 - accuracy: 0.9659 - val_loss: 0.0542 - val_accuracy: 0.9901\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 18s 175ms/step - loss: 0.0261 - accuracy: 0.9653 - val_loss: 0.0407 - val_accuracy: 0.9957\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 18s 176ms/step - loss: 0.0227 - accuracy: 0.9691 - val_loss: 0.0376 - val_accuracy: 0.9957\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 17s 171ms/step - loss: 0.0256 - accuracy: 0.9650 - val_loss: 0.0597 - val_accuracy: 0.9877\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 18s 178ms/step - loss: 0.0274 - accuracy: 0.9580 - val_loss: 0.9481 - val_accuracy: 0.2431\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 18s 177ms/step - loss: 0.0230 - accuracy: 0.9685 - val_loss: 0.3149 - val_accuracy: 0.9198\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 17s 171ms/step - loss: 0.0233 - accuracy: 0.9674 - val_loss: 0.0364 - val_accuracy: 0.9963\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 18s 172ms/step - loss: 0.0251 - accuracy: 0.9639 - val_loss: 0.0469 - val_accuracy: 0.9907\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 17s 171ms/step - loss: 0.0245 - accuracy: 0.9659 - val_loss: 0.0465 - val_accuracy: 0.9951\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 19s 184ms/step - loss: 0.0234 - accuracy: 0.9645 - val_loss: 0.0443 - val_accuracy: 0.9957\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 17s 166ms/step - loss: 0.0200 - accuracy: 0.9691 - val_loss: 0.0672 - val_accuracy: 0.9963\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 17s 169ms/step - loss: 0.0183 - accuracy: 0.9656 - val_loss: 0.0372 - val_accuracy: 0.9963\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 17s 167ms/step - loss: 0.0164 - accuracy: 0.9651 - val_loss: 0.0351 - val_accuracy: 0.9926\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 18s 174ms/step - loss: 0.0152 - accuracy: 0.9694 - val_loss: 0.0253 - val_accuracy: 0.9957\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 0.0134 - accuracy: 0.9762 - val_loss: 0.0334 - val_accuracy: 0.9914\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 17s 166ms/step - loss: 0.0131 - accuracy: 0.9853 - val_loss: 0.0406 - val_accuracy: 0.9914\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 17s 170ms/step - loss: 0.0168 - accuracy: 0.9795 - val_loss: 1.0781 - val_accuracy: 0.8408\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 16s 162ms/step - loss: 0.0169 - accuracy: 0.9753 - val_loss: 0.0311 - val_accuracy: 0.9944\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 18s 176ms/step - loss: 0.0138 - accuracy: 0.9810 - val_loss: 0.0293 - val_accuracy: 0.9926\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 0.0127 - accuracy: 0.9838 - val_loss: 0.0210 - val_accuracy: 0.9938\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 18s 174ms/step - loss: 0.0089 - accuracy: 0.9943 - val_loss: 0.0268 - val_accuracy: 0.9938\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 17s 167ms/step - loss: 0.0076 - accuracy: 0.9903 - val_loss: 0.0171 - val_accuracy: 0.9957\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 0.0063 - accuracy: 0.9884 - val_loss: 0.0160 - val_accuracy: 0.9957\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 18s 172ms/step - loss: 0.0059 - accuracy: 0.9863 - val_loss: 0.0183 - val_accuracy: 0.9951\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.0090 - accuracy: 0.9880 - val_loss: 0.0265 - val_accuracy: 0.9883\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.0083 - accuracy: 0.9856 - val_loss: 0.0331 - val_accuracy: 0.9907\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 0.0074 - accuracy: 0.9870 - val_loss: 0.0214 - val_accuracy: 0.9957\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 17s 169ms/step - loss: 0.0064 - accuracy: 0.9886 - val_loss: 0.0182 - val_accuracy: 0.9963\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 0.0056 - accuracy: 0.9914 - val_loss: 0.0180 - val_accuracy: 0.9951\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.0046 - accuracy: 0.9924 - val_loss: 0.0124 - val_accuracy: 0.9957\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 0.0043 - accuracy: 0.9952 - val_loss: 0.0251 - val_accuracy: 0.9926\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 18s 174ms/step - loss: 0.0041 - accuracy: 0.9952 - val_loss: 0.0210 - val_accuracy: 0.9951\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 0.0035 - accuracy: 0.9957 - val_loss: 0.0226 - val_accuracy: 0.9951\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.0029 - accuracy: 0.9969 - val_loss: 0.0225 - val_accuracy: 0.9951\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 0.0029 - accuracy: 0.9968 - val_loss: 0.0227 - val_accuracy: 0.9951\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 17s 171ms/step - loss: 0.0029 - accuracy: 0.9966 - val_loss: 0.0250 - val_accuracy: 0.9951\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 18s 173ms/step - loss: 0.0025 - accuracy: 0.9971 - val_loss: 0.0247 - val_accuracy: 0.9951\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.0024 - accuracy: 0.9974 - val_loss: 0.0218 - val_accuracy: 0.9951\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 0.0023 - accuracy: 0.9966 - val_loss: 0.0234 - val_accuracy: 0.9951\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 16s 162ms/step - loss: 0.0026 - accuracy: 0.9954 - val_loss: 0.0264 - val_accuracy: 0.9951\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 17s 166ms/step - loss: 0.0022 - accuracy: 0.9975 - val_loss: 0.0267 - val_accuracy: 0.9951\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 17s 167ms/step - loss: 0.0023 - accuracy: 0.9965 - val_loss: 0.0167 - val_accuracy: 0.9963\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 0.0030 - accuracy: 0.9948 - val_loss: 0.0339 - val_accuracy: 0.9932\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 0.0082 - accuracy: 0.9886 - val_loss: 0.0220 - val_accuracy: 0.9938\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 0.0129 - accuracy: 0.9792 - val_loss: 0.0604 - val_accuracy: 0.9815\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 16s 153ms/step - loss: 0.0053 - accuracy: 0.9918 - val_loss: 0.0309 - val_accuracy: 0.9938\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 0.0030 - accuracy: 0.9966 - val_loss: 0.0264 - val_accuracy: 0.9944\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 17s 164ms/step - loss: 0.0028 - accuracy: 0.9965 - val_loss: 0.0215 - val_accuracy: 0.9951\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 0.0050 - accuracy: 0.9918 - val_loss: 0.0245 - val_accuracy: 0.9938\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 0.0025 - accuracy: 0.9972 - val_loss: 0.0206 - val_accuracy: 0.9944\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 17s 164ms/step - loss: 0.0034 - accuracy: 0.9944 - val_loss: 0.0241 - val_accuracy: 0.9932\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.0040 - accuracy: 0.9966 - val_loss: 0.0138 - val_accuracy: 0.9969\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 0.0021 - accuracy: 0.9961 - val_loss: 0.0164 - val_accuracy: 0.9957\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 0.0016 - accuracy: 0.9965 - val_loss: 0.0184 - val_accuracy: 0.9951\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 0.0012 - accuracy: 0.9977 - val_loss: 0.0180 - val_accuracy: 0.9951\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 0.0013 - accuracy: 0.9965 - val_loss: 0.0186 - val_accuracy: 0.9951\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 17s 171ms/step - loss: 0.0016 - accuracy: 0.9969 - val_loss: 0.0211 - val_accuracy: 0.9951\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 17s 168ms/step - loss: 0.0012 - accuracy: 0.9983 - val_loss: 0.0199 - val_accuracy: 0.9951\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 9.4386e-04 - accuracy: 0.9989 - val_loss: 0.0187 - val_accuracy: 0.9957\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 0.0011 - accuracy: 0.9981 - val_loss: 0.0187 - val_accuracy: 0.9963\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 0.0204 - val_accuracy: 0.9951\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 0.0011 - accuracy: 0.9985 - val_loss: 0.0230 - val_accuracy: 0.9951\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 7.6460e-04 - accuracy: 0.9991 - val_loss: 0.0267 - val_accuracy: 0.9944\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 8.7856e-04 - accuracy: 0.9988 - val_loss: 0.0260 - val_accuracy: 0.9944\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 0.0011 - accuracy: 0.9975 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 9.4433e-04 - accuracy: 0.9985 - val_loss: 0.0262 - val_accuracy: 0.9944\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 17s 166ms/step - loss: 8.9313e-04 - accuracy: 0.9991 - val_loss: 0.0228 - val_accuracy: 0.9957\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 0.0010 - accuracy: 0.9986 - val_loss: 0.0235 - val_accuracy: 0.9957\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 9.1794e-04 - accuracy: 0.9989 - val_loss: 0.0270 - val_accuracy: 0.9951\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 7.1199e-04 - accuracy: 0.9989 - val_loss: 0.0245 - val_accuracy: 0.9957\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 7.8535e-04 - accuracy: 0.9991 - val_loss: 0.0240 - val_accuracy: 0.9957\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 7.3760e-04 - accuracy: 0.9994 - val_loss: 0.0235 - val_accuracy: 0.9957\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 8.5779e-04 - accuracy: 0.9989 - val_loss: 0.0312 - val_accuracy: 0.9944\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 17s 170ms/step - loss: 7.7993e-04 - accuracy: 0.9989 - val_loss: 0.0378 - val_accuracy: 0.9932\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 17s 170ms/step - loss: 7.3215e-04 - accuracy: 0.9989 - val_loss: 0.0363 - val_accuracy: 0.9938\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 17s 166ms/step - loss: 9.2146e-04 - accuracy: 0.9989 - val_loss: 0.0402 - val_accuracy: 0.9938\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 6.3576e-04 - accuracy: 0.9995 - val_loss: 0.0396 - val_accuracy: 0.9938\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 8.8140e-04 - accuracy: 0.9991 - val_loss: 0.0369 - val_accuracy: 0.9938\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 6.6993e-04 - accuracy: 0.9994 - val_loss: 0.0381 - val_accuracy: 0.9938\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 6.9282e-04 - accuracy: 0.9994 - val_loss: 0.0262 - val_accuracy: 0.9957\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 4.7603e-04 - accuracy: 0.9994 - val_loss: 0.0284 - val_accuracy: 0.9957\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 6.3489e-04 - accuracy: 0.9997 - val_loss: 0.0336 - val_accuracy: 0.9951\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 5.4361e-04 - accuracy: 0.9998 - val_loss: 0.0341 - val_accuracy: 0.9951\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 6.9844e-04 - accuracy: 0.9994 - val_loss: 0.0338 - val_accuracy: 0.9957\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 17s 170ms/step - loss: 5.9300e-04 - accuracy: 0.9995 - val_loss: 0.0335 - val_accuracy: 0.9957\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 6.1734e-04 - accuracy: 0.9994 - val_loss: 0.0278 - val_accuracy: 0.9951\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 6.8281e-04 - accuracy: 0.9992 - val_loss: 0.0178 - val_accuracy: 0.9969\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.0101 - accuracy: 0.9897 - val_loss: 0.0478 - val_accuracy: 0.9920\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 0.0079 - accuracy: 0.9909 - val_loss: 0.0491 - val_accuracy: 0.9901\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 0.0023 - accuracy: 0.9975 - val_loss: 0.0150 - val_accuracy: 0.9963\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.0028 - accuracy: 0.9961 - val_loss: 0.0188 - val_accuracy: 0.9951\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 0.0017 - accuracy: 0.9969 - val_loss: 0.0268 - val_accuracy: 0.9944\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 17s 164ms/step - loss: 6.2709e-04 - accuracy: 0.9991 - val_loss: 0.0194 - val_accuracy: 0.9957\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 4.6644e-04 - accuracy: 0.9995 - val_loss: 0.0199 - val_accuracy: 0.9957\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 5.0743e-04 - accuracy: 0.9994 - val_loss: 0.0194 - val_accuracy: 0.9957\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 5.4157e-04 - accuracy: 0.9995 - val_loss: 0.0103 - val_accuracy: 0.9975\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 4.7498e-04 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9969\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 4.1103e-04 - accuracy: 0.9998 - val_loss: 0.0192 - val_accuracy: 0.9963\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 4.3053e-04 - accuracy: 0.9995 - val_loss: 0.0215 - val_accuracy: 0.9957\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 4.9078e-04 - accuracy: 0.9991 - val_loss: 0.0230 - val_accuracy: 0.9963\n",
      "Epoch 152/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.0044 - accuracy: 0.9965 - val_loss: 0.0688 - val_accuracy: 0.9772\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 0.0038 - accuracy: 0.9951 - val_loss: 0.0276 - val_accuracy: 0.9938\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 0.0034 - accuracy: 0.9951 - val_loss: 0.0164 - val_accuracy: 0.9963\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 7.1913e-04 - accuracy: 0.9997 - val_loss: 0.0160 - val_accuracy: 0.9969\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 16s 162ms/step - loss: 8.1621e-04 - accuracy: 0.9991 - val_loss: 0.0211 - val_accuracy: 0.9957\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 5.8016e-04 - accuracy: 0.9991 - val_loss: 0.0228 - val_accuracy: 0.9957\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 5.4051e-04 - accuracy: 0.9992 - val_loss: 0.0205 - val_accuracy: 0.9957\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 16s 162ms/step - loss: 5.6852e-04 - accuracy: 0.9989 - val_loss: 0.0208 - val_accuracy: 0.9957\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 6.0607e-04 - accuracy: 0.9986 - val_loss: 0.0210 - val_accuracy: 0.9957\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 4.4726e-04 - accuracy: 0.9995 - val_loss: 0.0203 - val_accuracy: 0.9957\n",
      "Epoch 162/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 4.2986e-04 - accuracy: 0.9992 - val_loss: 0.0218 - val_accuracy: 0.9957\n",
      "Epoch 163/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 4.9578e-04 - accuracy: 0.9994 - val_loss: 0.0211 - val_accuracy: 0.9957\n",
      "Epoch 164/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 4.7384e-04 - accuracy: 0.9995 - val_loss: 0.0208 - val_accuracy: 0.9963\n",
      "Epoch 165/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 4.2303e-04 - accuracy: 0.9994 - val_loss: 0.0186 - val_accuracy: 0.9963\n",
      "Epoch 166/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 3.1560e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9951\n",
      "Epoch 167/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 4.4459e-04 - accuracy: 0.9992 - val_loss: 0.0248 - val_accuracy: 0.9951\n",
      "Epoch 168/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 2.6496e-04 - accuracy: 0.9998 - val_loss: 0.0251 - val_accuracy: 0.9951\n",
      "Epoch 169/500\n",
      "102/102 [==============================] - 17s 171ms/step - loss: 3.2669e-04 - accuracy: 0.9997 - val_loss: 0.0238 - val_accuracy: 0.9951\n",
      "Epoch 170/500\n",
      "102/102 [==============================] - 17s 168ms/step - loss: 3.6115e-04 - accuracy: 0.9994 - val_loss: 0.0213 - val_accuracy: 0.9963\n",
      "Epoch 171/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 2.3650e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9957\n",
      "Epoch 172/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 2.7829e-04 - accuracy: 0.9998 - val_loss: 0.0238 - val_accuracy: 0.9957\n",
      "Epoch 173/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 4.0443e-04 - accuracy: 0.9994 - val_loss: 0.0210 - val_accuracy: 0.9969\n",
      "Epoch 174/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 2.4810e-04 - accuracy: 0.9997 - val_loss: 0.0205 - val_accuracy: 0.9969\n",
      "Epoch 175/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 4.2485e-04 - accuracy: 0.9994 - val_loss: 0.0206 - val_accuracy: 0.9969\n",
      "Epoch 176/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 2.3657e-04 - accuracy: 0.9998 - val_loss: 0.0251 - val_accuracy: 0.9951\n",
      "Epoch 177/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 2.2788e-04 - accuracy: 0.9997 - val_loss: 0.0216 - val_accuracy: 0.9963\n",
      "Epoch 178/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.9836e-04 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9951\n",
      "Epoch 179/500\n",
      "102/102 [==============================] - 17s 168ms/step - loss: 3.9798e-04 - accuracy: 0.9988 - val_loss: 0.0251 - val_accuracy: 0.9951\n",
      "Epoch 180/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 2.8168e-04 - accuracy: 0.9995 - val_loss: 0.0253 - val_accuracy: 0.9957\n",
      "Epoch 181/500\n",
      "102/102 [==============================] - 16s 162ms/step - loss: 2.5785e-04 - accuracy: 0.9995 - val_loss: 0.0232 - val_accuracy: 0.9969\n",
      "Epoch 182/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.9475e-04 - accuracy: 0.9997 - val_loss: 0.0233 - val_accuracy: 0.9969\n",
      "Epoch 183/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 1.9051e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9963\n",
      "Epoch 184/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 1.9282e-04 - accuracy: 0.9997 - val_loss: 0.0235 - val_accuracy: 0.9957\n",
      "Epoch 185/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.5865e-04 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9957\n",
      "Epoch 186/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.8103e-04 - accuracy: 0.9997 - val_loss: 0.0264 - val_accuracy: 0.9951\n",
      "Epoch 187/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 2.0525e-04 - accuracy: 0.9998 - val_loss: 0.0243 - val_accuracy: 0.9957\n",
      "Epoch 188/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 1.8435e-04 - accuracy: 0.9997 - val_loss: 0.0259 - val_accuracy: 0.9957\n",
      "Epoch 189/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.8900e-04 - accuracy: 0.9998 - val_loss: 0.0277 - val_accuracy: 0.9957\n",
      "Epoch 190/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.1179e-04 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.9957\n",
      "Epoch 191/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 8.2438e-05 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.9951\n",
      "Epoch 192/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 1.8965e-04 - accuracy: 0.9998 - val_loss: 0.0309 - val_accuracy: 0.9951\n",
      "Epoch 193/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 0.0058 - accuracy: 0.9941 - val_loss: 0.0794 - val_accuracy: 0.9870\n",
      "Epoch 194/500\n",
      "102/102 [==============================] - 17s 166ms/step - loss: 0.0068 - accuracy: 0.9895 - val_loss: 0.0266 - val_accuracy: 0.9944\n",
      "Epoch 195/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 0.0040 - accuracy: 0.9938 - val_loss: 0.0192 - val_accuracy: 0.9963\n",
      "Epoch 196/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 6.7256e-04 - accuracy: 0.9992 - val_loss: 0.0191 - val_accuracy: 0.9957\n",
      "Epoch 197/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 2.3579e-04 - accuracy: 0.9998 - val_loss: 0.0195 - val_accuracy: 0.9951\n",
      "Epoch 198/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.4191e-04 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 0.9957\n",
      "Epoch 199/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 1.8852e-04 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9963\n",
      "Epoch 200/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 1.9009e-04 - accuracy: 0.9997 - val_loss: 0.0169 - val_accuracy: 0.9969\n",
      "Epoch 201/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 2.7187e-04 - accuracy: 0.9998 - val_loss: 0.0195 - val_accuracy: 0.9963\n",
      "Epoch 202/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 2.2048e-04 - accuracy: 0.9997 - val_loss: 0.0208 - val_accuracy: 0.9951\n",
      "Epoch 203/500\n",
      "102/102 [==============================] - 16s 162ms/step - loss: 1.3810e-04 - accuracy: 0.9998 - val_loss: 0.0199 - val_accuracy: 0.9963\n",
      "Epoch 204/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 1.8840e-04 - accuracy: 0.9998 - val_loss: 0.0239 - val_accuracy: 0.9951\n",
      "Epoch 205/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 1.5338e-04 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9951\n",
      "Epoch 206/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 2.3155e-04 - accuracy: 0.9997 - val_loss: 0.0217 - val_accuracy: 0.9951\n",
      "Epoch 207/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 1.2339e-04 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9957\n",
      "Epoch 208/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 2.1635e-04 - accuracy: 0.9997 - val_loss: 0.0225 - val_accuracy: 0.9963\n",
      "Epoch 209/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.8006e-04 - accuracy: 0.9998 - val_loss: 0.0228 - val_accuracy: 0.9963\n",
      "Epoch 210/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 2.9823e-04 - accuracy: 0.9997 - val_loss: 0.0253 - val_accuracy: 0.9951\n",
      "Epoch 211/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 1.0204e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9963\n",
      "Epoch 212/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.6698e-04 - accuracy: 0.9998 - val_loss: 0.0194 - val_accuracy: 0.9957\n",
      "Epoch 213/500\n",
      "102/102 [==============================] - 16s 153ms/step - loss: 1.3412e-04 - accuracy: 0.9998 - val_loss: 0.0220 - val_accuracy: 0.9957\n",
      "Epoch 214/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 1.1125e-04 - accuracy: 0.9998 - val_loss: 0.0254 - val_accuracy: 0.9951\n",
      "Epoch 215/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.3906e-04 - accuracy: 0.9997 - val_loss: 0.0267 - val_accuracy: 0.9951\n",
      "Epoch 216/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 9.2414e-05 - accuracy: 0.9998 - val_loss: 0.0273 - val_accuracy: 0.9951\n",
      "Epoch 217/500\n",
      "102/102 [==============================] - 17s 164ms/step - loss: 1.4235e-04 - accuracy: 0.9998 - val_loss: 0.0249 - val_accuracy: 0.9951\n",
      "Epoch 218/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 9.4078e-05 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9951\n",
      "Epoch 219/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 9.9585e-05 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9957\n",
      "Epoch 220/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.3620e-04 - accuracy: 0.9998 - val_loss: 0.0282 - val_accuracy: 0.9951\n",
      "Epoch 221/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.0896e-04 - accuracy: 0.9998 - val_loss: 0.0286 - val_accuracy: 0.9957\n",
      "Epoch 222/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 1.5719e-04 - accuracy: 0.9998 - val_loss: 0.0290 - val_accuracy: 0.9957\n",
      "Epoch 223/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.1931e-04 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9951\n",
      "Epoch 224/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 8.2487e-05 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9951\n",
      "Epoch 225/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.0744e-04 - accuracy: 0.9997 - val_loss: 0.0301 - val_accuracy: 0.9951\n",
      "Epoch 226/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.4986e-04 - accuracy: 0.9997 - val_loss: 0.0282 - val_accuracy: 0.9957\n",
      "Epoch 227/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 1.0386e-04 - accuracy: 0.9998 - val_loss: 0.0294 - val_accuracy: 0.9957\n",
      "Epoch 228/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 6.8841e-05 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9957\n",
      "Epoch 229/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.2082e-04 - accuracy: 0.9998 - val_loss: 0.0344 - val_accuracy: 0.9951\n",
      "Epoch 230/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.2149e-04 - accuracy: 0.9998 - val_loss: 0.0327 - val_accuracy: 0.9951\n",
      "Epoch 231/500\n",
      "102/102 [==============================] - 16s 162ms/step - loss: 1.3796e-04 - accuracy: 0.9997 - val_loss: 0.0379 - val_accuracy: 0.9951\n",
      "Epoch 232/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 8.5127e-05 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9951\n",
      "Epoch 233/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 1.6739e-04 - accuracy: 0.9995 - val_loss: 0.0353 - val_accuracy: 0.9951\n",
      "Epoch 234/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 9.2842e-05 - accuracy: 0.9998 - val_loss: 0.0377 - val_accuracy: 0.9951\n",
      "Epoch 235/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 2.0103e-04 - accuracy: 0.9997 - val_loss: 0.0348 - val_accuracy: 0.9957\n",
      "Epoch 236/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 7.5384e-05 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9957\n",
      "Epoch 237/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 6.5400e-05 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9957\n",
      "Epoch 238/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 2.4408e-04 - accuracy: 0.9997 - val_loss: 0.0349 - val_accuracy: 0.9951\n",
      "Epoch 239/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 8.0776e-05 - accuracy: 0.9998 - val_loss: 0.0338 - val_accuracy: 0.9957\n",
      "Epoch 240/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 1.6371e-04 - accuracy: 0.9995 - val_loss: 0.0332 - val_accuracy: 0.9957\n",
      "Epoch 241/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 1.1867e-04 - accuracy: 0.9998 - val_loss: 0.0318 - val_accuracy: 0.9957\n",
      "Epoch 242/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 8.6131e-05 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9957\n",
      "Epoch 243/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 8.5446e-05 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9957\n",
      "Epoch 244/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 1.1705e-04 - accuracy: 0.9998 - val_loss: 0.0425 - val_accuracy: 0.9951\n",
      "Epoch 245/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 8.0673e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9951\n",
      "Epoch 246/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 1.2596e-04 - accuracy: 0.9997 - val_loss: 0.0413 - val_accuracy: 0.9951\n",
      "Epoch 247/500\n",
      "102/102 [==============================] - 17s 166ms/step - loss: 1.0132e-04 - accuracy: 0.9998 - val_loss: 0.0400 - val_accuracy: 0.9957\n",
      "Epoch 248/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 7.9811e-05 - accuracy: 0.9998 - val_loss: 0.0379 - val_accuracy: 0.9957\n",
      "Epoch 249/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 1.0367e-04 - accuracy: 0.9998 - val_loss: 0.0372 - val_accuracy: 0.9957\n",
      "Epoch 250/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 9.9815e-05 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9951\n",
      "Epoch 251/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 1.7732e-04 - accuracy: 0.9997 - val_loss: 0.0346 - val_accuracy: 0.9957\n",
      "Epoch 252/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 0.0085 - accuracy: 0.9932 - val_loss: 0.0492 - val_accuracy: 0.9914\n",
      "Epoch 253/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 0.0038 - accuracy: 0.9949 - val_loss: 0.0335 - val_accuracy: 0.9938\n",
      "Epoch 254/500\n",
      "102/102 [==============================] - 16s 154ms/step - loss: 0.0020 - accuracy: 0.9978 - val_loss: 0.0371 - val_accuracy: 0.9938\n",
      "Epoch 255/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 7.9847e-04 - accuracy: 0.9991 - val_loss: 0.0375 - val_accuracy: 0.9938\n",
      "Epoch 256/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 6.3609e-04 - accuracy: 0.9995 - val_loss: 0.0352 - val_accuracy: 0.9938\n",
      "Epoch 257/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 6.0369e-04 - accuracy: 0.9992 - val_loss: 0.0349 - val_accuracy: 0.9938\n",
      "Epoch 258/500\n",
      "102/102 [==============================] - 16s 154ms/step - loss: 5.1850e-04 - accuracy: 0.9995 - val_loss: 0.0379 - val_accuracy: 0.9938\n",
      "Epoch 259/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 4.5568e-04 - accuracy: 0.9994 - val_loss: 0.0402 - val_accuracy: 0.9938\n",
      "Epoch 260/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 4.4494e-04 - accuracy: 0.9995 - val_loss: 0.0411 - val_accuracy: 0.9938\n",
      "Epoch 261/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 4.5186e-04 - accuracy: 0.9995 - val_loss: 0.0405 - val_accuracy: 0.9944\n",
      "Epoch 262/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 4.6251e-04 - accuracy: 0.9995 - val_loss: 0.0419 - val_accuracy: 0.9938\n",
      "Epoch 263/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 3.7585e-04 - accuracy: 0.9995 - val_loss: 0.0411 - val_accuracy: 0.9944\n",
      "Epoch 264/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 4.2037e-04 - accuracy: 0.9995 - val_loss: 0.0392 - val_accuracy: 0.9944\n",
      "Epoch 265/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 4.7678e-04 - accuracy: 0.9992 - val_loss: 0.0405 - val_accuracy: 0.9944\n",
      "Epoch 266/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 3.6748e-04 - accuracy: 0.9995 - val_loss: 0.0406 - val_accuracy: 0.9944\n",
      "Epoch 267/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 4.5717e-04 - accuracy: 0.9992 - val_loss: 0.0402 - val_accuracy: 0.9944\n",
      "Epoch 268/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 4.0575e-04 - accuracy: 0.9992 - val_loss: 0.0415 - val_accuracy: 0.9944\n",
      "Epoch 269/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 3.6926e-04 - accuracy: 0.9995 - val_loss: 0.0405 - val_accuracy: 0.9944\n",
      "Epoch 270/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 3.5010e-04 - accuracy: 0.9995 - val_loss: 0.0419 - val_accuracy: 0.9944\n",
      "Epoch 271/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 3.6456e-04 - accuracy: 0.9994 - val_loss: 0.0372 - val_accuracy: 0.9951\n",
      "Epoch 272/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 0.0012 - accuracy: 0.9988 - val_loss: 0.1169 - val_accuracy: 0.9766\n",
      "Epoch 273/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 0.0104 - accuracy: 0.9823 - val_loss: 0.0297 - val_accuracy: 0.9914\n",
      "Epoch 274/500\n",
      "102/102 [==============================] - 16s 154ms/step - loss: 0.0025 - accuracy: 0.9969 - val_loss: 0.0184 - val_accuracy: 0.9932\n",
      "Epoch 275/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 7.9278e-04 - accuracy: 0.9986 - val_loss: 0.0191 - val_accuracy: 0.9963\n",
      "Epoch 276/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 2.3554e-04 - accuracy: 0.9998 - val_loss: 0.0165 - val_accuracy: 0.9975\n",
      "Epoch 277/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 1.3301e-04 - accuracy: 0.9998 - val_loss: 0.0170 - val_accuracy: 0.9975\n",
      "Epoch 278/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 1.0704e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9975\n",
      "Epoch 279/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 1.0843e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9975\n",
      "Epoch 280/500\n",
      "102/102 [==============================] - 17s 166ms/step - loss: 1.8324e-04 - accuracy: 0.9997 - val_loss: 0.0153 - val_accuracy: 0.9975\n",
      "Epoch 281/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.7175e-04 - accuracy: 0.9998 - val_loss: 0.0353 - val_accuracy: 0.9951\n",
      "Epoch 282/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 5.3501e-05 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9957\n",
      "Epoch 283/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 1.0296e-04 - accuracy: 0.9998 - val_loss: 0.0265 - val_accuracy: 0.9969\n",
      "Epoch 284/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 5.4893e-05 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9969\n",
      "Epoch 285/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 5.8817e-05 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9969\n",
      "Epoch 286/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 7.5366e-05 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9969\n",
      "Epoch 287/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 1.1316e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9969\n",
      "Epoch 288/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.1976e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9969\n",
      "Epoch 289/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 1.2916e-04 - accuracy: 0.9998 - val_loss: 0.0263 - val_accuracy: 0.9969\n",
      "Epoch 290/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 8.7358e-05 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9969\n",
      "Epoch 291/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 7.2945e-05 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9969\n",
      "Epoch 292/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 7.7245e-05 - accuracy: 0.9998 - val_loss: 0.0251 - val_accuracy: 0.9969\n",
      "Epoch 293/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 6.2027e-05 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9969\n",
      "Epoch 294/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 3.8831e-05 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9963\n",
      "Epoch 295/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 4.1016e-05 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9969\n",
      "Epoch 296/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 5.9603e-05 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9969\n",
      "Epoch 297/500\n",
      "102/102 [==============================] - 17s 167ms/step - loss: 6.2114e-05 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9969\n",
      "Epoch 298/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 5.8602e-05 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9969\n",
      "Epoch 299/500\n",
      "102/102 [==============================] - 17s 164ms/step - loss: 6.7080e-05 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9969\n",
      "Epoch 300/500\n",
      "102/102 [==============================] - 17s 164ms/step - loss: 7.1616e-05 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9969\n",
      "Epoch 301/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 8.5372e-05 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9963\n",
      "Epoch 302/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.1548e-04 - accuracy: 0.9998 - val_loss: 0.0318 - val_accuracy: 0.9963\n",
      "Epoch 303/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 7.2872e-05 - accuracy: 0.9998 - val_loss: 0.0287 - val_accuracy: 0.9963\n",
      "Epoch 304/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 7.0757e-05 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9969\n",
      "Epoch 305/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 8.2791e-05 - accuracy: 0.9998 - val_loss: 0.0259 - val_accuracy: 0.9969\n",
      "Epoch 306/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 6.4707e-05 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9969\n",
      "Epoch 307/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 3.6604e-05 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9969\n",
      "Epoch 308/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 8.3943e-05 - accuracy: 0.9998 - val_loss: 0.0248 - val_accuracy: 0.9969\n",
      "Epoch 309/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 7.9679e-05 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9969\n",
      "Epoch 310/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 6.5863e-05 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9969\n",
      "Epoch 311/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 5.0468e-05 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9969\n",
      "Epoch 312/500\n",
      "102/102 [==============================] - 16s 154ms/step - loss: 5.3412e-05 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9969\n",
      "Epoch 313/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 5.7057e-05 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9969\n",
      "Epoch 314/500\n",
      "102/102 [==============================] - 16s 154ms/step - loss: 5.3370e-05 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9951\n",
      "Epoch 315/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 9.1018e-05 - accuracy: 0.9998 - val_loss: 0.0312 - val_accuracy: 0.9951\n",
      "Epoch 316/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 2.4851e-05 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9963\n",
      "Epoch 317/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 4.6328e-05 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9951\n",
      "Epoch 318/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 5.2148e-05 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9963\n",
      "Epoch 319/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 3.7585e-05 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9957\n",
      "Epoch 320/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 4.4352e-05 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9963\n",
      "Epoch 321/500\n",
      "102/102 [==============================] - 17s 164ms/step - loss: 1.0113e-04 - accuracy: 0.9997 - val_loss: 0.0349 - val_accuracy: 0.9951\n",
      "Epoch 322/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 6.7943e-05 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9963\n",
      "Epoch 323/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 2.2519e-05 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9963\n",
      "Epoch 324/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 4.2205e-05 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9963\n",
      "Epoch 325/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 4.9832e-05 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9963\n",
      "Epoch 326/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 6.2418e-05 - accuracy: 0.9998 - val_loss: 0.0296 - val_accuracy: 0.9963\n",
      "Epoch 327/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 6.3155e-05 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 0.9951\n",
      "Epoch 328/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 2.8520e-05 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9963\n",
      "Epoch 329/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 3.8406e-05 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9951\n",
      "Epoch 330/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 2.2398e-05 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9951\n",
      "Epoch 331/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 4.1835e-05 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 0.9957\n",
      "Epoch 332/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 3.6596e-05 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9957\n",
      "Epoch 333/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 3.8728e-05 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9944\n",
      "Epoch 334/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 3.4958e-05 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9951\n",
      "Epoch 335/500\n",
      "102/102 [==============================] - 17s 166ms/step - loss: 4.0341e-05 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9944\n",
      "Epoch 336/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 2.8569e-05 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9951\n",
      "Epoch 337/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 3.1526e-05 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9951\n",
      "Epoch 338/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 5.1860e-05 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9951\n",
      "Epoch 339/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 3.6089e-05 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9951\n",
      "Epoch 340/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 3.2083e-05 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9944\n",
      "Epoch 341/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 3.4950e-05 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9951\n",
      "Epoch 342/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.7949e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9951\n",
      "Epoch 343/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 3.3725e-05 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9944\n",
      "Epoch 344/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 3.3458e-05 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9957\n",
      "Epoch 345/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 2.6676e-05 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9963\n",
      "Epoch 346/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 3.6767e-05 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9963\n",
      "Epoch 347/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 3.2328e-05 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9957\n",
      "Epoch 348/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 2.3139e-05 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9957\n",
      "Epoch 349/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 2.3329e-05 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9951\n",
      "Epoch 350/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 4.1967e-05 - accuracy: 0.9998 - val_loss: 0.0433 - val_accuracy: 0.9944\n",
      "Epoch 351/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 3.4177e-05 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9957\n",
      "Epoch 352/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 0.0023 - accuracy: 0.9977 - val_loss: 0.2533 - val_accuracy: 0.9543\n",
      "Epoch 353/500\n",
      "102/102 [==============================] - 16s 162ms/step - loss: 0.0127 - accuracy: 0.9840 - val_loss: 0.0449 - val_accuracy: 0.9926\n",
      "Epoch 354/500\n",
      "102/102 [==============================] - 16s 162ms/step - loss: 0.0041 - accuracy: 0.9951 - val_loss: 0.0532 - val_accuracy: 0.9840\n",
      "Epoch 355/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.0042 - accuracy: 0.9920 - val_loss: 0.0193 - val_accuracy: 0.9957\n",
      "Epoch 356/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 0.0012 - accuracy: 0.9991 - val_loss: 0.0182 - val_accuracy: 0.9957\n",
      "Epoch 357/500\n",
      "102/102 [==============================] - 16s 162ms/step - loss: 6.1876e-04 - accuracy: 0.9995 - val_loss: 0.0203 - val_accuracy: 0.9957\n",
      "Epoch 358/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 5.2372e-04 - accuracy: 0.9995 - val_loss: 0.0201 - val_accuracy: 0.9951\n",
      "Epoch 359/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 4.5854e-04 - accuracy: 0.9995 - val_loss: 0.0225 - val_accuracy: 0.9944\n",
      "Epoch 360/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 5.0373e-04 - accuracy: 0.9995 - val_loss: 0.0227 - val_accuracy: 0.9957\n",
      "Epoch 361/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 4.7625e-04 - accuracy: 0.9995 - val_loss: 0.0218 - val_accuracy: 0.9944\n",
      "Epoch 362/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 4.0207e-04 - accuracy: 0.9995 - val_loss: 0.0183 - val_accuracy: 0.9951\n",
      "Epoch 363/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 0.0022 - accuracy: 0.9975 - val_loss: 0.0478 - val_accuracy: 0.9889\n",
      "Epoch 364/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 0.0015 - accuracy: 0.9980 - val_loss: 0.0217 - val_accuracy: 0.9944\n",
      "Epoch 365/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 4.5470e-04 - accuracy: 0.9995 - val_loss: 0.0237 - val_accuracy: 0.9944\n",
      "Epoch 366/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 3.7376e-04 - accuracy: 0.9995 - val_loss: 0.0217 - val_accuracy: 0.9944\n",
      "Epoch 367/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 2.7194e-04 - accuracy: 0.9995 - val_loss: 0.0197 - val_accuracy: 0.9963\n",
      "Epoch 368/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.6307e-04 - accuracy: 0.9998 - val_loss: 0.0249 - val_accuracy: 0.9951\n",
      "Epoch 369/500\n",
      "102/102 [==============================] - 17s 164ms/step - loss: 1.3292e-04 - accuracy: 0.9998 - val_loss: 0.0252 - val_accuracy: 0.9957\n",
      "Epoch 370/500\n",
      "102/102 [==============================] - 17s 168ms/step - loss: 1.3565e-04 - accuracy: 0.9998 - val_loss: 0.0226 - val_accuracy: 0.9957\n",
      "Epoch 371/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 1.2089e-04 - accuracy: 0.9998 - val_loss: 0.0235 - val_accuracy: 0.9957\n",
      "Epoch 372/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 2.0863e-04 - accuracy: 0.9997 - val_loss: 0.0244 - val_accuracy: 0.9957\n",
      "Epoch 373/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 1.2317e-04 - accuracy: 0.9998 - val_loss: 0.0262 - val_accuracy: 0.9951\n",
      "Epoch 374/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 7.4519e-05 - accuracy: 0.9998 - val_loss: 0.0291 - val_accuracy: 0.9951\n",
      "Epoch 375/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 6.0656e-05 - accuracy: 0.9998 - val_loss: 0.0245 - val_accuracy: 0.9951\n",
      "Epoch 376/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 3.2135e-05 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9944\n",
      "Epoch 377/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 2.5567e-05 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9951\n",
      "Epoch 378/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 3.3803e-05 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9951\n",
      "Epoch 379/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 2.1842e-05 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.9951\n",
      "Epoch 380/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 3.6261e-05 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9951\n",
      "Epoch 381/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 3.4329e-05 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9951\n",
      "Epoch 382/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 2.3993e-05 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9951\n",
      "Epoch 383/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 3.0599e-05 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9951\n",
      "Epoch 384/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 2.1670e-05 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9951\n",
      "Epoch 385/500\n",
      "102/102 [==============================] - 16s 155ms/step - loss: 7.3213e-05 - accuracy: 0.9998 - val_loss: 0.0306 - val_accuracy: 0.9951\n",
      "Epoch 386/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 1.6956e-05 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9951\n",
      "Epoch 387/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 1.2512e-05 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 0.9951\n",
      "Epoch 388/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 0.0028 - accuracy: 0.9978 - val_loss: 0.0888 - val_accuracy: 0.9889\n",
      "Epoch 389/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 0.0039 - accuracy: 0.9946 - val_loss: 0.0230 - val_accuracy: 0.9951\n",
      "Epoch 390/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 3.5395e-04 - accuracy: 0.9995 - val_loss: 0.0325 - val_accuracy: 0.9944\n",
      "Epoch 391/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 5.0004e-05 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9951\n",
      "Epoch 392/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 7.2163e-05 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9963\n",
      "Epoch 393/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 4.0268e-05 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9957\n",
      "Epoch 394/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 4.1071e-05 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9957\n",
      "Epoch 395/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 6.1844e-05 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9957\n",
      "Epoch 396/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 3.1220e-05 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9957\n",
      "Epoch 397/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 3.1226e-05 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9957\n",
      "Epoch 398/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 2.8646e-05 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9951\n",
      "Epoch 399/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 3.9487e-05 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9951\n",
      "Epoch 400/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 3.5899e-05 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9951\n",
      "Epoch 401/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 2.8137e-05 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9951\n",
      "Epoch 402/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 2.2037e-05 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9951\n",
      "Epoch 403/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.6690e-05 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9951\n",
      "Epoch 404/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 5.0561e-05 - accuracy: 0.9998 - val_loss: 0.0351 - val_accuracy: 0.9951\n",
      "Epoch 405/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 2.0881e-05 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9951\n",
      "Epoch 406/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 1.4606e-05 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9951\n",
      "Epoch 407/500\n",
      "102/102 [==============================] - 17s 166ms/step - loss: 1.5739e-05 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9951\n",
      "Epoch 408/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 1.8686e-05 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9951\n",
      "Epoch 409/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 1.8623e-05 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9951\n",
      "Epoch 410/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.9163e-05 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9951\n",
      "Epoch 411/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 2.1720e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9951\n",
      "Epoch 412/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 4.3061e-05 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9951\n",
      "Epoch 413/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 2.5609e-05 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9951\n",
      "Epoch 414/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 1.5624e-05 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9951\n",
      "Epoch 415/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 3.6530e-05 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9951\n",
      "Epoch 416/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 1.5598e-05 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9951\n",
      "Epoch 417/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 2.8736e-05 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9951\n",
      "Epoch 418/500\n",
      "102/102 [==============================] - 17s 164ms/step - loss: 1.4176e-05 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9951\n",
      "Epoch 419/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 1.6592e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9951\n",
      "Epoch 420/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 1.7997e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9951\n",
      "Epoch 421/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 1.5834e-05 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9951\n",
      "Epoch 422/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 2.7384e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9951\n",
      "Epoch 423/500\n",
      "102/102 [==============================] - 17s 166ms/step - loss: 1.8499e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9951\n",
      "Epoch 424/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 1.1954e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9951\n",
      "Epoch 425/500\n",
      "102/102 [==============================] - 17s 164ms/step - loss: 3.2700e-05 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9951\n",
      "Epoch 426/500\n",
      "102/102 [==============================] - 17s 165ms/step - loss: 2.1834e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9944\n",
      "Epoch 427/500\n",
      "102/102 [==============================] - 17s 166ms/step - loss: 1.7523e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9951\n",
      "Epoch 428/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 8.9243e-06 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9951\n",
      "Epoch 429/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 2.7411e-05 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9951\n",
      "Epoch 430/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 1.9866e-05 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9951\n",
      "Epoch 431/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 1.1292e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9951\n",
      "Epoch 432/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 1.3439e-05 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9951\n",
      "Epoch 433/500\n",
      "102/102 [==============================] - 16s 162ms/step - loss: 1.4616e-05 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9951\n",
      "Epoch 434/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 1.6942e-05 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9951\n",
      "Epoch 435/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 7.7887e-06 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9951\n",
      "Epoch 436/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 8.7602e-06 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9951\n",
      "Epoch 437/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 1.1237e-05 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9944\n",
      "Epoch 438/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 6.2074e-06 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9944\n",
      "Epoch 439/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 9.6120e-06 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9944\n",
      "Epoch 440/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 9.6419e-06 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9944\n",
      "Epoch 441/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 7.0093e-06 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9951\n",
      "Epoch 442/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0290 - val_accuracy: 0.9914\n",
      "Epoch 443/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 0.0044 - accuracy: 0.9941 - val_loss: 0.0511 - val_accuracy: 0.9815\n",
      "Epoch 444/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 0.0027 - accuracy: 0.9946 - val_loss: 0.0153 - val_accuracy: 0.9963\n",
      "Epoch 445/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 0.0024 - accuracy: 0.9981 - val_loss: 0.0381 - val_accuracy: 0.9951\n",
      "Epoch 446/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.0027 - accuracy: 0.9972 - val_loss: 0.1622 - val_accuracy: 0.9574\n",
      "Epoch 447/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 0.0012 - accuracy: 0.9985 - val_loss: 0.0210 - val_accuracy: 0.9951\n",
      "Epoch 448/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 1.4183e-04 - accuracy: 0.9998 - val_loss: 0.0199 - val_accuracy: 0.9957\n",
      "Epoch 449/500\n",
      "102/102 [==============================] - 16s 162ms/step - loss: 1.0187e-04 - accuracy: 0.9997 - val_loss: 0.0211 - val_accuracy: 0.9957\n",
      "Epoch 450/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 2.7585e-05 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9951\n",
      "Epoch 451/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 2.5089e-05 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9951\n",
      "Epoch 452/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 2.2156e-05 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9951\n",
      "Epoch 453/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 2.3225e-05 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9951\n",
      "Epoch 454/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 2.4696e-05 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9951\n",
      "Epoch 455/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 3.6927e-05 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9951\n",
      "Epoch 456/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 3.5361e-05 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9951\n",
      "Epoch 457/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 1.6715e-05 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9951\n",
      "Epoch 458/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 1.9128e-05 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9951\n",
      "Epoch 459/500\n",
      "102/102 [==============================] - 17s 164ms/step - loss: 2.0301e-05 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9951\n",
      "Epoch 460/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 1.0535e-05 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9951\n",
      "Epoch 461/500\n",
      "102/102 [==============================] - 16s 162ms/step - loss: 1.5465e-05 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.9951\n",
      "Epoch 462/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.9131e-05 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9951\n",
      "Epoch 463/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 8.6193e-06 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9951\n",
      "Epoch 464/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 1.1068e-05 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9951\n",
      "Epoch 465/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.8579e-05 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9951\n",
      "Epoch 466/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.8551e-05 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.9951\n",
      "Epoch 467/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 1.3574e-05 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9951\n",
      "Epoch 468/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.4016e-05 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9951\n",
      "Epoch 469/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.4784e-05 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9951\n",
      "Epoch 470/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 1.1901e-05 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9951\n",
      "Epoch 471/500\n",
      "102/102 [==============================] - 16s 156ms/step - loss: 2.4613e-05 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9951\n",
      "Epoch 472/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 8.1478e-06 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9951\n",
      "Epoch 473/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 6.0941e-05 - accuracy: 0.9998 - val_loss: 0.0333 - val_accuracy: 0.9951\n",
      "Epoch 474/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 2.1662e-05 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9951\n",
      "Epoch 475/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 1.9514e-05 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9951\n",
      "Epoch 476/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 8.4937e-06 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9951\n",
      "Epoch 477/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 7.0105e-06 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9951\n",
      "Epoch 478/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 2.2567e-05 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9951\n",
      "Epoch 479/500\n",
      "102/102 [==============================] - 16s 162ms/step - loss: 1.9947e-05 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9951\n",
      "Epoch 480/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 1.5100e-05 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9951\n",
      "Epoch 481/500\n",
      "102/102 [==============================] - 17s 162ms/step - loss: 1.1686e-05 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9951\n",
      "Epoch 482/500\n",
      "102/102 [==============================] - 17s 164ms/step - loss: 1.1858e-05 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9951\n",
      "Epoch 483/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 9.4310e-06 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9951\n",
      "Epoch 484/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 1.1641e-05 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9951\n",
      "Epoch 485/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 1.1929e-05 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9951\n",
      "Epoch 486/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 9.0295e-06 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9944\n",
      "Epoch 487/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 7.4940e-06 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9951\n",
      "Epoch 488/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 1.1214e-05 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9951\n",
      "Epoch 489/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 1.2615e-05 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9951\n",
      "Epoch 490/500\n",
      "102/102 [==============================] - 16s 157ms/step - loss: 9.9005e-06 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9951\n",
      "Epoch 491/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 4.9796e-06 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9944\n",
      "Epoch 492/500\n",
      "102/102 [==============================] - 16s 158ms/step - loss: 7.1378e-06 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9944\n",
      "Epoch 493/500\n",
      "102/102 [==============================] - 16s 161ms/step - loss: 5.7825e-06 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9944\n",
      "Epoch 494/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 8.1342e-06 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9944\n",
      "Epoch 495/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 9.0440e-06 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9944\n",
      "Epoch 496/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 8.0761e-06 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9938\n",
      "Epoch 497/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 1.1270e-05 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9938\n",
      "Epoch 498/500\n",
      "102/102 [==============================] - 16s 159ms/step - loss: 8.9267e-06 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9944\n",
      "Epoch 499/500\n",
      "102/102 [==============================] - 17s 163ms/step - loss: 9.7976e-06 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9938\n",
      "Epoch 500/500\n",
      "102/102 [==============================] - 16s 160ms/step - loss: 1.4777e-05 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9938\n"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint_filepath = \"../../model/resnet50_original_checkpoints_{epoch:03d}.tf\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only= True\n",
    ")\n",
    "class_weight = {1:0.15,0:0.85}\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=['/GPU:0','/GPU:1'])\n",
    "with mirrored_strategy.scope(): \n",
    "    input_t=K.Input(shape=(size,size, 3))\n",
    "    input_tensor = layers.experimental.preprocessing.Resizing(size, size, interpolation=\"bilinear\", input_shape=x_train.shape[1:])(input_t)\n",
    "    ResNet=ResNet50(include_top=True,weights='imagenet',input_tensor=input_tensor)\n",
    "    model = K.models.Sequential()\n",
    "    model.add(ResNet)\n",
    "    model.add(tf.keras.layers.Dropout(.2, input_shape=(64,)))\n",
    "    model.add(K.layers.Dense(64, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "    model.add(K.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=K.optimizers.Adam(lr=1e-4),\n",
    "                  loss=tf.keras.losses.binary_crossentropy,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    histo=model.fit(\n",
    "        x_train,y_train,\n",
    "        validation_data=(x_test,y_test),\n",
    "        epochs=500,\n",
    "        callbacks=[model_checkpoint_callback],\n",
    "        batch_size=64,shuffle=True,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "model.save('../../model/ResNet50_original256.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 1s 23ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "NotStandardFrame       1.00      0.99      1.00      1363\n",
      "   StandardFrame       0.96      1.00      0.98       258\n",
      "\n",
      "        accuracy                           0.99      1621\n",
      "       macro avg       0.98      1.00      0.99      1621\n",
      "    weighted avg       0.99      0.99      0.99      1621\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def plot_roc_curve(fper, tper):\n",
    "    \n",
    "    plt.plot(fper, tper, color='red', label='auc='+str(auc_score))\n",
    "    plt.plot([0, 1], [0, 1], color='green', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "cmap = plt.cm.Blues\n",
    "classes = ['NotStandardFrame','StandardFrame']\n",
    "prob = model.predict(x_test)\n",
    "t_prob=np.where(prob>0.5,1,0)\n",
    "fper, tper, thresholds = roc_curve(y_test, prob)\n",
    "auc_score=roc_auc_score(y_test, t_prob)\n",
    "plot_roc_curve(fper, tper)\n",
    "cm = confusion_matrix(y_test, t_prob)\n",
    "cm_display = ConfusionMatrixDisplay(cm,\n",
    "                              display_labels=classes).plot()\n",
    "\n",
    "\n",
    "# F1 , ,  \n",
    "report = classification_report(y_test, t_prob, target_names=classes)\n",
    "\n",
    "#  \n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
