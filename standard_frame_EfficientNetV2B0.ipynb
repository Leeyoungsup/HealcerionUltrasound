{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 13:39:22.261666: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-11 13:39:23.167442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras import datasets, layers, models, losses, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pre\n",
    "from glob import glob\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '6'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_img_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Train_dataframe.csv')['file_path'].to_list()\n",
    "Train_label_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Train_dataframe.csv')['standard'].to_list()\n",
    "Test_img_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Test_dataframe.csv')['file_path'].to_list()\n",
    "Test_label_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Test_dataframe.csv')['standard'].to_list()\n",
    "Val_img_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Validation_dataframe.csv')['file_path'].to_list()\n",
    "Val_label_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Validation_dataframe.csv')['standard'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_img_path='../../data/standardFrame_data/scale_skip/train'\n",
    "Test_img_path='../../data/standardFrame_data/scale_skip/test'\n",
    "Val_img_path='../../data/standardFrame_data/scale_skip/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=224\n",
    "x_train = np.zeros((len(Train_img_list),size,size,3))\n",
    "for i in range(len(Train_img_list)):\n",
    "    x_train[i] =np.array(Image.open(Train_img_path+Train_img_list[i]).resize((size,size)))\n",
    "x_train=x_train/255\n",
    "y_train=np.array(Train_label_list)\n",
    "\n",
    "x_test = np.zeros((len(Test_img_list),size,size,3))\n",
    "for i in range(len(Test_img_list)):\n",
    "    x_test[i] =np.array(Image.open(Test_img_path+Test_img_list[i]).resize((size,size)))\n",
    "x_test=x_test/255\n",
    "y_test=np.array(Test_label_list)\n",
    "\n",
    "x_val = np.zeros((len(Val_img_list),size,size,3))\n",
    "for i in range(len(Val_img_list)):\n",
    "    x_val[i] =np.array(Image.open(Val_img_path+Val_img_list[i]).resize((size,size)))\n",
    "x_val=x_val/255\n",
    "y_val=np.array(Val_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 13:43:09.638073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38163 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "2023-08-11 13:43:12.764480: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 13:43:24.032868: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/efficientnetv2-b0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-08-11 13:43:28.875100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8902\n",
      "2023-08-11 13:43:29.915552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-11 13:43:30.069569: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f593b6a7f00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-11 13:43:30.069606: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2023-08-11 13:43:30.089605: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-11 13:43:30.218969: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 84s 117ms/step - loss: 0.5476 - accuracy: 0.7343 - val_loss: 0.2752 - val_accuracy: 0.9335\n",
      "Epoch 2/500\n",
      "388/388 [==============================] - 37s 96ms/step - loss: 0.3919 - accuracy: 0.7985 - val_loss: 0.2418 - val_accuracy: 0.9335\n",
      "Epoch 3/500\n",
      "388/388 [==============================] - 37s 95ms/step - loss: 0.2740 - accuracy: 0.8769 - val_loss: 0.2595 - val_accuracy: 0.9335\n",
      "Epoch 4/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.2019 - accuracy: 0.9086 - val_loss: 0.3764 - val_accuracy: 0.9335\n",
      "Epoch 5/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.1734 - accuracy: 0.9235 - val_loss: 0.4006 - val_accuracy: 0.9335\n",
      "Epoch 6/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.1404 - accuracy: 0.9375 - val_loss: 0.4453 - val_accuracy: 0.9335\n",
      "Epoch 7/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.1216 - accuracy: 0.9470 - val_loss: 0.5322 - val_accuracy: 0.9335\n",
      "Epoch 8/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.1100 - accuracy: 0.9514 - val_loss: 0.4214 - val_accuracy: 0.9335\n",
      "Epoch 9/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0939 - accuracy: 0.9604 - val_loss: 2.5933 - val_accuracy: 0.0665\n",
      "Epoch 10/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0836 - accuracy: 0.9637 - val_loss: 0.4578 - val_accuracy: 0.9335\n",
      "Epoch 11/500\n",
      "388/388 [==============================] - 39s 101ms/step - loss: 0.0739 - accuracy: 0.9683 - val_loss: 0.4589 - val_accuracy: 0.9335\n",
      "Epoch 12/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0723 - accuracy: 0.9698 - val_loss: 0.5126 - val_accuracy: 0.9335\n",
      "Epoch 13/500\n",
      "388/388 [==============================] - 37s 96ms/step - loss: 0.0546 - accuracy: 0.9778 - val_loss: 0.5650 - val_accuracy: 0.9335\n",
      "Epoch 14/500\n",
      "388/388 [==============================] - 38s 97ms/step - loss: 0.0537 - accuracy: 0.9784 - val_loss: 0.6036 - val_accuracy: 0.9335\n",
      "Epoch 15/500\n",
      "388/388 [==============================] - 39s 101ms/step - loss: 0.0572 - accuracy: 0.9763 - val_loss: 0.4350 - val_accuracy: 0.9335\n",
      "Epoch 16/500\n",
      "388/388 [==============================] - 40s 104ms/step - loss: 0.0544 - accuracy: 0.9789 - val_loss: 0.6085 - val_accuracy: 0.9335\n",
      "Epoch 17/500\n",
      "388/388 [==============================] - 37s 96ms/step - loss: 0.0421 - accuracy: 0.9849 - val_loss: 0.6451 - val_accuracy: 0.9335\n",
      "Epoch 18/500\n",
      "388/388 [==============================] - 38s 98ms/step - loss: 0.0430 - accuracy: 0.9854 - val_loss: 0.2748 - val_accuracy: 0.9335\n",
      "Epoch 19/500\n",
      "388/388 [==============================] - 37s 95ms/step - loss: 0.0400 - accuracy: 0.9855 - val_loss: 0.6147 - val_accuracy: 0.9335\n",
      "Epoch 20/500\n",
      "388/388 [==============================] - 42s 108ms/step - loss: 0.0354 - accuracy: 0.9866 - val_loss: 0.6706 - val_accuracy: 0.9335\n",
      "Epoch 21/500\n",
      "388/388 [==============================] - 52s 133ms/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 0.3501 - val_accuracy: 0.9335\n",
      "Epoch 22/500\n",
      "388/388 [==============================] - 37s 96ms/step - loss: 0.0311 - accuracy: 0.9886 - val_loss: 0.5894 - val_accuracy: 0.9335\n",
      "Epoch 23/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0322 - accuracy: 0.9880 - val_loss: 0.2584 - val_accuracy: 0.9141\n",
      "Epoch 24/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0334 - accuracy: 0.9863 - val_loss: 0.3837 - val_accuracy: 0.9335\n",
      "Epoch 25/500\n",
      "388/388 [==============================] - 39s 100ms/step - loss: 0.0273 - accuracy: 0.9895 - val_loss: 0.6463 - val_accuracy: 0.9335\n",
      "Epoch 26/500\n",
      "388/388 [==============================] - 40s 104ms/step - loss: 0.0335 - accuracy: 0.9873 - val_loss: 0.6227 - val_accuracy: 0.9335\n",
      "Epoch 27/500\n",
      "388/388 [==============================] - 44s 113ms/step - loss: 0.0238 - accuracy: 0.9908 - val_loss: 0.6641 - val_accuracy: 0.9335\n",
      "Epoch 28/500\n",
      "388/388 [==============================] - 49s 127ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.6748 - val_accuracy: 0.9335\n",
      "Epoch 29/500\n",
      "388/388 [==============================] - 52s 133ms/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.5382 - val_accuracy: 0.9335\n",
      "Epoch 30/500\n",
      "388/388 [==============================] - 38s 99ms/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 4.4294 - val_accuracy: 0.0665\n",
      "Epoch 31/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0247 - accuracy: 0.9914 - val_loss: 0.3970 - val_accuracy: 0.9335\n",
      "Epoch 32/500\n",
      "388/388 [==============================] - 38s 98ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.6183 - val_accuracy: 0.9335\n",
      "Epoch 33/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.6581 - val_accuracy: 0.9335\n",
      "Epoch 34/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.6801 - val_accuracy: 0.9333\n",
      "Epoch 35/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0281 - accuracy: 0.9906 - val_loss: 0.7362 - val_accuracy: 0.9335\n",
      "Epoch 36/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0211 - accuracy: 0.9919 - val_loss: 6.4080 - val_accuracy: 0.0665\n",
      "Epoch 37/500\n",
      "388/388 [==============================] - 42s 107ms/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 0.7709 - val_accuracy: 0.9335\n",
      "Epoch 38/500\n",
      "388/388 [==============================] - 39s 100ms/step - loss: 0.0224 - accuracy: 0.9919 - val_loss: 0.6848 - val_accuracy: 0.9335\n",
      "Epoch 39/500\n",
      "388/388 [==============================] - 37s 96ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.7077 - val_accuracy: 0.9335\n",
      "Epoch 40/500\n",
      "388/388 [==============================] - 39s 101ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.7549 - val_accuracy: 0.9335\n",
      "Epoch 41/500\n",
      "388/388 [==============================] - 44s 114ms/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.3024 - val_accuracy: 0.9335\n",
      "Epoch 42/500\n",
      "388/388 [==============================] - 43s 111ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 0.5196 - val_accuracy: 0.9335\n",
      "Epoch 43/500\n",
      "388/388 [==============================] - 40s 102ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 7.5938 - val_accuracy: 0.0665\n",
      "Epoch 44/500\n",
      "388/388 [==============================] - 39s 100ms/step - loss: 0.0279 - accuracy: 0.9891 - val_loss: 0.7190 - val_accuracy: 0.9335\n",
      "Epoch 45/500\n",
      "388/388 [==============================] - 40s 102ms/step - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.6159 - val_accuracy: 0.9335\n",
      "Epoch 46/500\n",
      "388/388 [==============================] - 36s 93ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 0.5937 - val_accuracy: 0.9335\n",
      "Epoch 47/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0179 - accuracy: 0.9935 - val_loss: 0.4307 - val_accuracy: 0.9334\n",
      "Epoch 48/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0143 - accuracy: 0.9950 - val_loss: 0.7211 - val_accuracy: 0.9339\n",
      "Epoch 49/500\n",
      "388/388 [==============================] - 36s 93ms/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.5161 - val_accuracy: 0.9335\n",
      "Epoch 50/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0211 - accuracy: 0.9919 - val_loss: 0.7737 - val_accuracy: 0.9335\n",
      "Epoch 51/500\n",
      "388/388 [==============================] - 39s 101ms/step - loss: 0.0171 - accuracy: 0.9938 - val_loss: 0.4343 - val_accuracy: 0.9335\n",
      "Epoch 52/500\n",
      "388/388 [==============================] - 40s 103ms/step - loss: 0.0214 - accuracy: 0.9917 - val_loss: 5.1426 - val_accuracy: 0.0665\n",
      "Epoch 53/500\n",
      "388/388 [==============================] - 45s 115ms/step - loss: 0.0143 - accuracy: 0.9946 - val_loss: 0.8383 - val_accuracy: 0.9335\n",
      "Epoch 54/500\n",
      "388/388 [==============================] - 43s 111ms/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.7698 - val_accuracy: 0.9335\n",
      "Epoch 55/500\n",
      "388/388 [==============================] - 39s 100ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.3648 - val_accuracy: 0.9335\n",
      "Epoch 56/500\n",
      "388/388 [==============================] - 40s 104ms/step - loss: 0.0214 - accuracy: 0.9919 - val_loss: 0.7433 - val_accuracy: 0.9335\n",
      "Epoch 57/500\n",
      "388/388 [==============================] - 44s 112ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.2592 - val_accuracy: 0.9335\n",
      "Epoch 58/500\n",
      "388/388 [==============================] - 39s 101ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.7976 - val_accuracy: 0.9335\n",
      "Epoch 59/500\n",
      "388/388 [==============================] - 41s 105ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.5053 - val_accuracy: 0.9335\n",
      "Epoch 60/500\n",
      "388/388 [==============================] - 40s 102ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 3.1534 - val_accuracy: 0.0665\n",
      "Epoch 61/500\n",
      "388/388 [==============================] - 45s 115ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.6408 - val_accuracy: 0.9335\n",
      "Epoch 62/500\n",
      "388/388 [==============================] - 47s 122ms/step - loss: 0.0191 - accuracy: 0.9926 - val_loss: 0.5404 - val_accuracy: 0.9335\n",
      "Epoch 63/500\n",
      "388/388 [==============================] - 46s 117ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.2926 - val_accuracy: 0.9335\n",
      "Epoch 64/500\n",
      "388/388 [==============================] - 36s 93ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 7.0674 - val_accuracy: 0.0665\n",
      "Epoch 65/500\n",
      "388/388 [==============================] - 40s 103ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.6802 - val_accuracy: 0.9335\n",
      "Epoch 66/500\n",
      "388/388 [==============================] - 41s 105ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.7998 - val_accuracy: 0.9335\n",
      "Epoch 67/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.8315 - val_accuracy: 0.9335\n",
      "Epoch 68/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.8181 - val_accuracy: 0.9335\n",
      "Epoch 69/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0139 - accuracy: 0.9964 - val_loss: 0.3517 - val_accuracy: 0.9335\n",
      "Epoch 70/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.6530 - val_accuracy: 0.9335\n",
      "Epoch 71/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.8322 - val_accuracy: 0.9335\n",
      "Epoch 72/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.7962 - val_accuracy: 0.9335\n",
      "Epoch 73/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.6131 - val_accuracy: 0.9335\n",
      "Epoch 74/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.6649 - val_accuracy: 0.9335\n",
      "Epoch 75/500\n",
      "388/388 [==============================] - 37s 96ms/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.8083 - val_accuracy: 0.9335\n",
      "Epoch 76/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.8866 - val_accuracy: 0.9335\n",
      "Epoch 77/500\n",
      "388/388 [==============================] - 37s 95ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.8789 - val_accuracy: 0.9335\n",
      "Epoch 78/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 4.8181 - val_accuracy: 0.0665\n",
      "Epoch 79/500\n",
      "388/388 [==============================] - 37s 97ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.8781 - val_accuracy: 0.9338\n",
      "Epoch 80/500\n",
      "388/388 [==============================] - 40s 103ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.3467 - val_accuracy: 0.9335\n",
      "Epoch 81/500\n",
      "388/388 [==============================] - 40s 104ms/step - loss: 0.0155 - accuracy: 0.9941 - val_loss: 0.8639 - val_accuracy: 0.9335\n",
      "Epoch 82/500\n",
      "388/388 [==============================] - 39s 100ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.8912 - val_accuracy: 0.9335\n",
      "Epoch 83/500\n",
      "388/388 [==============================] - 36s 93ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 4.8169 - val_accuracy: 0.0665\n",
      "Epoch 84/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.6650 - val_accuracy: 0.6885\n",
      "Epoch 85/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.6508 - val_accuracy: 0.9335\n",
      "Epoch 86/500\n",
      "388/388 [==============================] - 37s 95ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.6774 - val_accuracy: 0.9335\n",
      "Epoch 87/500\n",
      "388/388 [==============================] - 40s 103ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.5169 - val_accuracy: 0.9335\n",
      "Epoch 88/500\n",
      "388/388 [==============================] - 37s 95ms/step - loss: 0.0176 - accuracy: 0.9950 - val_loss: 0.6164 - val_accuracy: 0.9335\n",
      "Epoch 89/500\n",
      "388/388 [==============================] - 36s 93ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.7391 - val_accuracy: 0.9335\n",
      "Epoch 90/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 6.4312 - val_accuracy: 0.0665\n",
      "Epoch 91/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.7613 - val_accuracy: 0.9335\n",
      "Epoch 92/500\n",
      "388/388 [==============================] - 36s 93ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.4457 - val_accuracy: 0.9335\n",
      "Epoch 93/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.4219 - val_accuracy: 0.9335\n",
      "Epoch 94/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.4515 - val_accuracy: 0.9335\n",
      "Epoch 95/500\n",
      "388/388 [==============================] - 37s 94ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.8846 - val_accuracy: 0.9335\n",
      "Epoch 96/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.4439 - val_accuracy: 0.9335\n",
      "Epoch 97/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.7529 - val_accuracy: 0.9335\n",
      "Epoch 98/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.6173 - val_accuracy: 0.9335\n",
      "Epoch 99/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.3365 - val_accuracy: 0.9335\n",
      "Epoch 100/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.5879 - val_accuracy: 0.9335\n",
      "Epoch 101/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.6430 - val_accuracy: 0.9335\n",
      "Epoch 102/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.7897 - val_accuracy: 0.9335\n",
      "Epoch 103/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.6170 - val_accuracy: 0.9334\n",
      "Epoch 104/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 7.3066 - val_accuracy: 0.0665\n",
      "Epoch 105/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.4913 - val_accuracy: 0.9335\n",
      "Epoch 106/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.6031 - val_accuracy: 0.9331\n",
      "Epoch 107/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 1.7185 - val_accuracy: 0.0665\n",
      "Epoch 108/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.2439 - val_accuracy: 0.9335\n",
      "Epoch 109/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0086 - accuracy: 0.9967 - val_loss: 0.6427 - val_accuracy: 0.9295\n",
      "Epoch 110/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.8293 - val_accuracy: 0.9335\n",
      "Epoch 111/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.9081 - val_accuracy: 0.9335\n",
      "Epoch 112/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.4108 - val_accuracy: 0.9335\n",
      "Epoch 113/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.2925 - val_accuracy: 0.9335\n",
      "Epoch 114/500\n",
      "388/388 [==============================] - 36s 94ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.3040 - val_accuracy: 0.9335\n",
      "Epoch 115/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.8871 - val_accuracy: 0.9335\n",
      "Epoch 116/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.7095 - val_accuracy: 0.9335\n",
      "Epoch 117/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.4062 - val_accuracy: 0.9335\n",
      "Epoch 118/500\n",
      "388/388 [==============================] - 37s 94ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.8816 - val_accuracy: 0.9335\n",
      "Epoch 119/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.7158 - val_accuracy: 0.9335\n",
      "Epoch 120/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.8923 - val_accuracy: 0.9335\n",
      "Epoch 121/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.7366 - val_accuracy: 0.9335\n",
      "Epoch 122/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.9188 - val_accuracy: 0.9335\n",
      "Epoch 123/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.8104 - val_accuracy: 0.9335\n",
      "Epoch 124/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.7984 - val_accuracy: 0.9335\n",
      "Epoch 125/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.9010 - val_accuracy: 0.9335\n",
      "Epoch 126/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.7848 - val_accuracy: 0.9335\n",
      "Epoch 127/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.4056 - val_accuracy: 0.9335\n",
      "Epoch 128/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.8661 - val_accuracy: 0.9335\n",
      "Epoch 129/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0168 - accuracy: 0.9940 - val_loss: 6.0768 - val_accuracy: 0.0665\n",
      "Epoch 130/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.9015 - val_accuracy: 0.9335\n",
      "Epoch 131/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.8099 - val_accuracy: 0.9335\n",
      "Epoch 132/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.7793 - val_accuracy: 0.9335\n",
      "Epoch 133/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.9346 - val_accuracy: 0.9335\n",
      "Epoch 134/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.8579 - val_accuracy: 0.9333\n",
      "Epoch 135/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 2.1562 - val_accuracy: 0.4416\n",
      "Epoch 136/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.8924 - val_accuracy: 0.9335\n",
      "Epoch 137/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.9455 - val_accuracy: 0.9335\n",
      "Epoch 138/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.9456 - val_accuracy: 0.9335\n",
      "Epoch 139/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.9816 - val_accuracy: 0.9335\n",
      "Epoch 140/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.4628 - val_accuracy: 0.9335\n",
      "Epoch 141/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0231 - accuracy: 0.9914 - val_loss: 0.7778 - val_accuracy: 0.9335\n",
      "Epoch 142/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.5149 - val_accuracy: 0.9335\n",
      "Epoch 143/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.9659 - val_accuracy: 0.9335\n",
      "Epoch 144/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 7.2166 - val_accuracy: 0.0665\n",
      "Epoch 145/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 6.9985 - val_accuracy: 0.0665\n",
      "Epoch 146/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.2557 - val_accuracy: 0.9335\n",
      "Epoch 147/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.9004 - val_accuracy: 0.9335\n",
      "Epoch 148/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.7460 - val_accuracy: 0.9335\n",
      "Epoch 149/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.8064 - val_accuracy: 0.9335\n",
      "Epoch 150/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.9026 - val_accuracy: 0.9335\n",
      "Epoch 151/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.7413 - val_accuracy: 0.9335\n",
      "Epoch 152/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.8385 - val_accuracy: 0.9335\n",
      "Epoch 153/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.8262 - val_accuracy: 0.9335\n",
      "Epoch 154/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.5619 - val_accuracy: 0.9335\n",
      "Epoch 155/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.8371 - val_accuracy: 0.9335\n",
      "Epoch 156/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.7619 - val_accuracy: 0.9335\n",
      "Epoch 157/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.8826 - val_accuracy: 0.9335\n",
      "Epoch 158/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.8303 - val_accuracy: 0.9335\n",
      "Epoch 159/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.9135 - val_accuracy: 0.9335\n",
      "Epoch 160/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.7443 - val_accuracy: 0.9330\n",
      "Epoch 161/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 6.1163 - val_accuracy: 0.0665\n",
      "Epoch 162/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.3447 - val_accuracy: 0.9335\n",
      "Epoch 163/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.7118 - val_accuracy: 0.9309\n",
      "Epoch 164/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.9194 - val_accuracy: 0.9339\n",
      "Epoch 165/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.8431 - val_accuracy: 0.9335\n",
      "Epoch 166/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.9592 - val_accuracy: 0.9335\n",
      "Epoch 167/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 1.0267 - val_accuracy: 0.9335\n",
      "Epoch 168/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 0.6445 - val_accuracy: 0.9335\n",
      "Epoch 169/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.9329 - val_accuracy: 0.9335\n",
      "Epoch 170/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.9049 - val_accuracy: 0.9329\n",
      "Epoch 171/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.2921 - val_accuracy: 0.9335\n",
      "Epoch 172/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.8702 - val_accuracy: 0.9335\n",
      "Epoch 173/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.8058 - val_accuracy: 0.9335\n",
      "Epoch 174/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.8620 - val_accuracy: 0.9335\n",
      "Epoch 175/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.8771 - val_accuracy: 0.9335\n",
      "Epoch 176/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.8903 - val_accuracy: 0.9335\n",
      "Epoch 177/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.8668 - val_accuracy: 0.9335\n",
      "Epoch 178/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.8684 - val_accuracy: 0.9335\n",
      "Epoch 179/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.8004 - val_accuracy: 0.9338\n",
      "Epoch 180/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.5152 - val_accuracy: 0.9335\n",
      "Epoch 181/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.7969 - val_accuracy: 0.9335\n",
      "Epoch 182/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.8331 - val_accuracy: 0.9335\n",
      "Epoch 183/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.8552 - val_accuracy: 0.9337\n",
      "Epoch 184/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 5.9266 - val_accuracy: 0.0665\n",
      "Epoch 185/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0134 - accuracy: 0.9948 - val_loss: 0.3722 - val_accuracy: 0.9335\n",
      "Epoch 186/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.3705 - val_accuracy: 0.9335\n",
      "Epoch 187/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.7939 - val_accuracy: 0.9335\n",
      "Epoch 188/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.6340 - val_accuracy: 0.9335\n",
      "Epoch 189/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.6009 - val_accuracy: 0.9334\n",
      "Epoch 190/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.7925 - val_accuracy: 0.9335\n",
      "Epoch 191/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.7782 - val_accuracy: 0.9333\n",
      "Epoch 192/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.5364 - val_accuracy: 0.7963\n",
      "Epoch 193/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.7831 - val_accuracy: 0.9335\n",
      "Epoch 194/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.6649 - val_accuracy: 0.9335\n",
      "Epoch 195/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 2.9094 - val_accuracy: 0.0665\n",
      "Epoch 196/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.3821 - val_accuracy: 0.9335\n",
      "Epoch 197/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.8077 - val_accuracy: 0.9335\n",
      "Epoch 198/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.7132 - val_accuracy: 0.9335\n",
      "Epoch 199/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.7222 - val_accuracy: 0.9335\n",
      "Epoch 200/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.6982 - val_accuracy: 0.9335\n",
      "Epoch 201/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.7079 - val_accuracy: 0.9337\n",
      "Epoch 202/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.8284 - val_accuracy: 0.9335\n",
      "Epoch 203/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.8284 - val_accuracy: 0.9335\n",
      "Epoch 204/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.8791 - val_accuracy: 0.9335\n",
      "Epoch 205/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.8270 - val_accuracy: 0.9335\n",
      "Epoch 206/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.5551 - val_accuracy: 0.9335\n",
      "Epoch 207/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0190 - accuracy: 0.9955 - val_loss: 0.6633 - val_accuracy: 0.9335\n",
      "Epoch 208/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.7002 - val_accuracy: 0.9335\n",
      "Epoch 209/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.7615 - val_accuracy: 0.9337\n",
      "Epoch 210/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.8306 - val_accuracy: 0.9335\n",
      "Epoch 211/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.8357 - val_accuracy: 0.9335\n",
      "Epoch 212/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.2433 - val_accuracy: 0.9335\n",
      "Epoch 213/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.5001 - val_accuracy: 0.9335\n",
      "Epoch 214/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.8281 - val_accuracy: 0.9335\n",
      "Epoch 215/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.8555 - val_accuracy: 0.9335\n",
      "Epoch 216/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.7200 - val_accuracy: 0.9335\n",
      "Epoch 217/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.5357 - val_accuracy: 0.9335\n",
      "Epoch 218/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.7501 - val_accuracy: 0.9335\n",
      "Epoch 219/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.8572 - val_accuracy: 0.9335\n",
      "Epoch 220/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.8454 - val_accuracy: 0.9335\n",
      "Epoch 221/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.9781 - val_accuracy: 0.9335\n",
      "Epoch 222/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.8156 - val_accuracy: 0.9335\n",
      "Epoch 223/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 1.7980 - val_accuracy: 0.0665\n",
      "Epoch 224/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.6620 - val_accuracy: 0.9335\n",
      "Epoch 225/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.4728 - val_accuracy: 0.9335\n",
      "Epoch 226/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.5911 - val_accuracy: 0.9337\n",
      "Epoch 227/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.7992 - val_accuracy: 0.9337\n",
      "Epoch 228/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.8014 - val_accuracy: 0.9335\n",
      "Epoch 229/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.8172 - val_accuracy: 0.9335\n",
      "Epoch 230/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.6453 - val_accuracy: 0.9335\n",
      "Epoch 231/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.2520 - val_accuracy: 0.9335\n",
      "Epoch 232/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.3968 - val_accuracy: 0.9335\n",
      "Epoch 233/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.9185 - val_accuracy: 0.9335\n",
      "Epoch 234/500\n",
      "388/388 [==============================] - 40s 102ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.9258 - val_accuracy: 0.9335\n",
      "Epoch 235/500\n",
      "388/388 [==============================] - 40s 104ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.9294 - val_accuracy: 0.9335\n",
      "Epoch 236/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.8500 - val_accuracy: 0.9335\n",
      "Epoch 237/500\n",
      "388/388 [==============================] - 39s 100ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.8373 - val_accuracy: 0.9335\n",
      "Epoch 238/500\n",
      "388/388 [==============================] - 41s 105ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.6997 - val_accuracy: 0.9335\n",
      "Epoch 239/500\n",
      "388/388 [==============================] - 42s 107ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.6496 - val_accuracy: 0.9335\n",
      "Epoch 240/500\n",
      "388/388 [==============================] - 41s 105ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.5735 - val_accuracy: 0.9335\n",
      "Epoch 241/500\n",
      "388/388 [==============================] - 43s 111ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.4746 - val_accuracy: 0.9335\n",
      "Epoch 242/500\n",
      "388/388 [==============================] - 46s 117ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.3136 - val_accuracy: 0.9335\n",
      "Epoch 243/500\n",
      "388/388 [==============================] - 38s 99ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 6.5202 - val_accuracy: 0.0665\n",
      "Epoch 244/500\n",
      "388/388 [==============================] - 40s 102ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.8952 - val_accuracy: 0.9335\n",
      "Epoch 245/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.9002 - val_accuracy: 0.9333\n",
      "Epoch 246/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.9282 - val_accuracy: 0.9335\n",
      "Epoch 247/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.7345 - val_accuracy: 0.9339\n",
      "Epoch 248/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.9160 - val_accuracy: 0.9335\n",
      "Epoch 249/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.3882 - val_accuracy: 0.9335\n",
      "Epoch 250/500\n",
      "388/388 [==============================] - 44s 113ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.8395 - val_accuracy: 0.9347\n",
      "Epoch 251/500\n",
      "388/388 [==============================] - 40s 104ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.8541 - val_accuracy: 0.9335\n",
      "Epoch 252/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.6892 - val_accuracy: 0.9351\n",
      "Epoch 253/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.8960 - val_accuracy: 0.9335\n",
      "Epoch 254/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.4688 - val_accuracy: 0.9335\n",
      "Epoch 255/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.7539 - val_accuracy: 0.9351\n",
      "Epoch 256/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.9495 - val_accuracy: 0.9335\n",
      "Epoch 257/500\n",
      "388/388 [==============================] - 38s 97ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.8662 - val_accuracy: 0.9335\n",
      "Epoch 258/500\n",
      "388/388 [==============================] - 42s 108ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.5187 - val_accuracy: 0.9335\n",
      "Epoch 259/500\n",
      "388/388 [==============================] - 39s 99ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.7672 - val_accuracy: 0.9338\n",
      "Epoch 260/500\n",
      "388/388 [==============================] - 45s 117ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.8845 - val_accuracy: 0.9335\n",
      "Epoch 261/500\n",
      "388/388 [==============================] - 50s 130ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.9121 - val_accuracy: 0.9335\n",
      "Epoch 262/500\n",
      "388/388 [==============================] - 47s 121ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.9071 - val_accuracy: 0.9335\n",
      "Epoch 263/500\n",
      "388/388 [==============================] - 43s 112ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.8937 - val_accuracy: 0.9335\n",
      "Epoch 264/500\n",
      "388/388 [==============================] - 37s 96ms/step - loss: 0.0114 - accuracy: 0.9975 - val_loss: 0.6603 - val_accuracy: 0.9335\n",
      "Epoch 265/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.7644 - val_accuracy: 0.9335\n",
      "Epoch 266/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.6223 - val_accuracy: 0.9317\n",
      "Epoch 267/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.8394 - val_accuracy: 0.9335\n",
      "Epoch 268/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.8211 - val_accuracy: 0.9335\n",
      "Epoch 269/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.7076 - val_accuracy: 0.9335\n",
      "Epoch 270/500\n",
      "388/388 [==============================] - 34s 86ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.6919 - val_accuracy: 0.9335\n",
      "Epoch 271/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.6627 - val_accuracy: 0.9342\n",
      "Epoch 272/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.7455 - val_accuracy: 0.9335\n",
      "Epoch 273/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.7476 - val_accuracy: 0.9335\n",
      "Epoch 274/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.3173 - val_accuracy: 0.9335\n",
      "Epoch 275/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.5950 - val_accuracy: 0.9335\n",
      "Epoch 276/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.6989 - val_accuracy: 0.9335\n",
      "Epoch 277/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.7195 - val_accuracy: 0.9335\n",
      "Epoch 278/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.8981 - val_accuracy: 0.9335\n",
      "Epoch 279/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.5497 - val_accuracy: 0.9335\n",
      "Epoch 280/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.8319 - val_accuracy: 0.9340\n",
      "Epoch 281/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.9607 - val_accuracy: 0.9335\n",
      "Epoch 282/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.6775 - val_accuracy: 0.9355\n",
      "Epoch 283/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.8845 - val_accuracy: 0.9335\n",
      "Epoch 284/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.7428 - val_accuracy: 0.9335\n",
      "Epoch 285/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.6787 - val_accuracy: 0.9335\n",
      "Epoch 286/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.4903 - val_accuracy: 0.9335\n",
      "Epoch 287/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.3382 - val_accuracy: 0.9335\n",
      "Epoch 288/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.5177 - val_accuracy: 0.9335\n",
      "Epoch 289/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.6747 - val_accuracy: 0.9335\n",
      "Epoch 290/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.3467 - val_accuracy: 0.9335\n",
      "Epoch 291/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.7466 - val_accuracy: 0.9335\n",
      "Epoch 292/500\n",
      "388/388 [==============================] - 34s 86ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.6674 - val_accuracy: 0.9335\n",
      "Epoch 293/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.5378 - val_accuracy: 0.9337\n",
      "Epoch 294/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.6566 - val_accuracy: 0.9335\n",
      "Epoch 295/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.5224 - val_accuracy: 0.9335\n",
      "Epoch 296/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.7525 - val_accuracy: 0.9335\n",
      "Epoch 297/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.7965 - val_accuracy: 0.9335\n",
      "Epoch 298/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.8331 - val_accuracy: 0.9335\n",
      "Epoch 299/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.4789 - val_accuracy: 0.9343\n",
      "Epoch 300/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.7129 - val_accuracy: 0.9335\n",
      "Epoch 301/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.7294 - val_accuracy: 0.9335\n",
      "Epoch 302/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.5299 - val_accuracy: 0.9335\n",
      "Epoch 303/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.7590 - val_accuracy: 0.9335\n",
      "Epoch 304/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.5990 - val_accuracy: 0.9335\n",
      "Epoch 305/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.7769 - val_accuracy: 0.9335\n",
      "Epoch 306/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.8144 - val_accuracy: 0.9335\n",
      "Epoch 307/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.6069 - val_accuracy: 0.9333\n",
      "Epoch 308/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.8372 - val_accuracy: 0.9335\n",
      "Epoch 309/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.8721 - val_accuracy: 0.9335\n",
      "Epoch 310/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.7655 - val_accuracy: 0.9335\n",
      "Epoch 311/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.7646 - val_accuracy: 0.9339\n",
      "Epoch 312/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.7166 - val_accuracy: 0.9335\n",
      "Epoch 313/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.6447 - val_accuracy: 0.9249\n",
      "Epoch 314/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.8822 - val_accuracy: 0.9335\n",
      "Epoch 315/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.8753 - val_accuracy: 0.9335\n",
      "Epoch 316/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.7769 - val_accuracy: 0.9335\n",
      "Epoch 317/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.5293 - val_accuracy: 0.9335\n",
      "Epoch 318/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0247 - accuracy: 0.9946 - val_loss: 0.4803 - val_accuracy: 0.9335\n",
      "Epoch 319/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.6107 - val_accuracy: 0.9335\n",
      "Epoch 320/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.6827 - val_accuracy: 0.9335\n",
      "Epoch 321/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.6274 - val_accuracy: 0.9334\n",
      "Epoch 322/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.5322 - val_accuracy: 0.9335\n",
      "Epoch 323/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.6361 - val_accuracy: 0.9335\n",
      "Epoch 324/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.6575 - val_accuracy: 0.9333\n",
      "Epoch 325/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.5188 - val_accuracy: 0.9344\n",
      "Epoch 326/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.6483 - val_accuracy: 0.9348\n",
      "Epoch 327/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.8608 - val_accuracy: 0.9335\n",
      "Epoch 328/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.8388 - val_accuracy: 0.9335\n",
      "Epoch 329/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.8846 - val_accuracy: 0.9335\n",
      "Epoch 330/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.7946 - val_accuracy: 0.9335\n",
      "Epoch 331/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.8869 - val_accuracy: 0.9335\n",
      "Epoch 332/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.7208 - val_accuracy: 0.9335\n",
      "Epoch 333/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.8995 - val_accuracy: 0.9335\n",
      "Epoch 334/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 1.0080 - val_accuracy: 0.9335\n",
      "Epoch 335/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.7965 - val_accuracy: 0.9330\n",
      "Epoch 336/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.7896 - val_accuracy: 0.9327\n",
      "Epoch 337/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.8513 - val_accuracy: 0.9335\n",
      "Epoch 338/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.3512 - val_accuracy: 0.9335\n",
      "Epoch 339/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.6160 - val_accuracy: 0.9335\n",
      "Epoch 340/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.8456 - val_accuracy: 0.9335\n",
      "Epoch 341/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.4748 - val_accuracy: 0.9335\n",
      "Epoch 342/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.5604 - val_accuracy: 0.9335\n",
      "Epoch 343/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.8878 - val_accuracy: 0.9335\n",
      "Epoch 344/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5299 - val_accuracy: 0.9335\n",
      "Epoch 345/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.6397 - val_accuracy: 0.9335\n",
      "Epoch 346/500\n",
      "388/388 [==============================] - 34s 86ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 1.8796 - val_accuracy: 0.0665\n",
      "Epoch 347/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.5952 - val_accuracy: 0.9342\n",
      "Epoch 348/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.8412 - val_accuracy: 0.9337\n",
      "Epoch 349/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5270 - val_accuracy: 0.8493\n",
      "Epoch 350/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.3617 - val_accuracy: 0.9335\n",
      "Epoch 351/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.6661 - val_accuracy: 0.9325\n",
      "Epoch 352/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 1.0103 - val_accuracy: 0.9335\n",
      "Epoch 353/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.5854 - val_accuracy: 0.9335\n",
      "Epoch 354/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.8546 - val_accuracy: 0.9335\n",
      "Epoch 355/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.6700 - val_accuracy: 0.9335\n",
      "Epoch 356/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.7919 - val_accuracy: 0.9338\n",
      "Epoch 357/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.5469 - val_accuracy: 0.9335\n",
      "Epoch 358/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0133 - accuracy: 0.9971 - val_loss: 0.5584 - val_accuracy: 0.9335\n",
      "Epoch 359/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.6016 - val_accuracy: 0.9335\n",
      "Epoch 360/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.7349 - val_accuracy: 0.9335\n",
      "Epoch 361/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.3825 - val_accuracy: 0.9335\n",
      "Epoch 362/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.5301 - val_accuracy: 0.9362\n",
      "Epoch 363/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.6390 - val_accuracy: 0.9351\n",
      "Epoch 364/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.7413 - val_accuracy: 0.9338\n",
      "Epoch 365/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.8630 - val_accuracy: 0.9337\n",
      "Epoch 366/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.4731 - val_accuracy: 0.9335\n",
      "Epoch 367/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.7264 - val_accuracy: 0.9335\n",
      "Epoch 368/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.6031 - val_accuracy: 0.9349\n",
      "Epoch 369/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.6374 - val_accuracy: 0.9334\n",
      "Epoch 370/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.7024 - val_accuracy: 0.9335\n",
      "Epoch 371/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.5822 - val_accuracy: 0.9353\n",
      "Epoch 372/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.9020 - val_accuracy: 0.9335\n",
      "Epoch 373/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.7533 - val_accuracy: 0.9335\n",
      "Epoch 374/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.8486 - val_accuracy: 0.9333\n",
      "Epoch 375/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.5550 - val_accuracy: 0.9333\n",
      "Epoch 376/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.8148 - val_accuracy: 0.9327\n",
      "Epoch 377/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.9380 - val_accuracy: 0.9338\n",
      "Epoch 378/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 1.0253 - val_accuracy: 0.9335\n",
      "Epoch 379/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 1.0019 - val_accuracy: 0.9335\n",
      "Epoch 380/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 1.0051 - val_accuracy: 0.9335\n",
      "Epoch 381/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0108 - accuracy: 0.9978 - val_loss: 0.7437 - val_accuracy: 0.9335\n",
      "Epoch 382/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.6398 - val_accuracy: 0.9342\n",
      "Epoch 383/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.4162 - val_accuracy: 0.9335\n",
      "Epoch 384/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.6752 - val_accuracy: 0.9335\n",
      "Epoch 385/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.2636 - val_accuracy: 0.9335\n",
      "Epoch 386/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.5782 - val_accuracy: 0.9334\n",
      "Epoch 387/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.2447 - val_accuracy: 0.9335\n",
      "Epoch 388/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.5544 - val_accuracy: 0.9335\n",
      "Epoch 389/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.5236 - val_accuracy: 0.9333\n",
      "Epoch 390/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.6785 - val_accuracy: 0.9339\n",
      "Epoch 391/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.4796 - val_accuracy: 0.9335\n",
      "Epoch 392/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.5463 - val_accuracy: 0.9338\n",
      "Epoch 393/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.3090 - val_accuracy: 0.9337\n",
      "Epoch 394/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.2996 - val_accuracy: 0.9335\n",
      "Epoch 395/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.5034 - val_accuracy: 0.9344\n",
      "Epoch 396/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.7788 - val_accuracy: 0.9335\n",
      "Epoch 397/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.5824 - val_accuracy: 0.9295\n",
      "Epoch 398/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.6963 - val_accuracy: 0.9304\n",
      "Epoch 399/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.2853 - val_accuracy: 0.9335\n",
      "Epoch 400/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.7486 - val_accuracy: 0.9335\n",
      "Epoch 401/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.2725 - val_accuracy: 0.9335\n",
      "Epoch 402/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.7246 - val_accuracy: 0.9335\n",
      "Epoch 403/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.5007 - val_accuracy: 0.9335\n",
      "Epoch 404/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.7334 - val_accuracy: 0.9338\n",
      "Epoch 405/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.6622 - val_accuracy: 0.9308\n",
      "Epoch 406/500\n",
      "388/388 [==============================] - 34s 86ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.7455 - val_accuracy: 0.9329\n",
      "Epoch 407/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.7326 - val_accuracy: 0.9335\n",
      "Epoch 408/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.6252 - val_accuracy: 0.9335\n",
      "Epoch 409/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.6654 - val_accuracy: 0.9335\n",
      "Epoch 410/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.6004 - val_accuracy: 0.9320\n",
      "Epoch 411/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.7170 - val_accuracy: 0.9335\n",
      "Epoch 412/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.8513 - val_accuracy: 0.9335\n",
      "Epoch 413/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.7952 - val_accuracy: 0.9335\n",
      "Epoch 414/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.8910 - val_accuracy: 0.9335\n",
      "Epoch 415/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.8188 - val_accuracy: 0.9335\n",
      "Epoch 416/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.6121 - val_accuracy: 0.9335\n",
      "Epoch 417/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.8307 - val_accuracy: 0.9335\n",
      "Epoch 418/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.8701 - val_accuracy: 0.9335\n",
      "Epoch 419/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.9478 - val_accuracy: 0.9335\n",
      "Epoch 420/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.8847 - val_accuracy: 0.9335\n",
      "Epoch 421/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.9029 - val_accuracy: 0.9335\n",
      "Epoch 422/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.8174 - val_accuracy: 0.9335\n",
      "Epoch 423/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.6878 - val_accuracy: 0.9313\n",
      "Epoch 424/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.9332 - val_accuracy: 0.9335\n",
      "Epoch 425/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.8108 - val_accuracy: 0.9335\n",
      "Epoch 426/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.7266 - val_accuracy: 0.9335\n",
      "Epoch 427/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.8835 - val_accuracy: 0.9333\n",
      "Epoch 428/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.6815 - val_accuracy: 0.9335\n",
      "Epoch 429/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.7894 - val_accuracy: 0.9335\n",
      "Epoch 430/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.7270 - val_accuracy: 0.9335\n",
      "Epoch 431/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0095 - accuracy: 0.9986 - val_loss: 0.5139 - val_accuracy: 0.9335\n",
      "Epoch 432/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0136 - accuracy: 0.9968 - val_loss: 0.5724 - val_accuracy: 0.9335\n",
      "Epoch 433/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.6876 - val_accuracy: 0.9335\n",
      "Epoch 434/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0091 - accuracy: 0.9986 - val_loss: 0.4577 - val_accuracy: 0.9335\n",
      "Epoch 435/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.5724 - val_accuracy: 0.9335\n",
      "Epoch 436/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.5841 - val_accuracy: 0.9334\n",
      "Epoch 437/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.6744 - val_accuracy: 0.9335\n",
      "Epoch 438/500\n",
      "388/388 [==============================] - 34s 86ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.4525 - val_accuracy: 0.9335\n",
      "Epoch 439/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.6459 - val_accuracy: 0.9335\n",
      "Epoch 440/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.5410 - val_accuracy: 0.9335\n",
      "Epoch 441/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.6753 - val_accuracy: 0.9335\n",
      "Epoch 442/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.6217 - val_accuracy: 0.9355\n",
      "Epoch 443/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.8012 - val_accuracy: 0.9335\n",
      "Epoch 444/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.7908 - val_accuracy: 0.9335\n",
      "Epoch 445/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.7950 - val_accuracy: 0.9335\n",
      "Epoch 446/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.6335 - val_accuracy: 0.9297\n",
      "Epoch 447/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.5846 - val_accuracy: 0.9335\n",
      "Epoch 448/500\n",
      "388/388 [==============================] - 34s 86ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.6821 - val_accuracy: 0.9335\n",
      "Epoch 449/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.6819 - val_accuracy: 0.9335\n",
      "Epoch 450/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.7204 - val_accuracy: 0.9335\n",
      "Epoch 451/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.7520 - val_accuracy: 0.9335\n",
      "Epoch 452/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.6979 - val_accuracy: 0.9331\n",
      "Epoch 453/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.6238 - val_accuracy: 0.9335\n",
      "Epoch 454/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.4932 - val_accuracy: 0.9335\n",
      "Epoch 455/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 0.6032 - val_accuracy: 0.9335\n",
      "Epoch 456/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.5178 - val_accuracy: 0.9335\n",
      "Epoch 457/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0081 - accuracy: 0.9987 - val_loss: 0.5847 - val_accuracy: 0.9335\n",
      "Epoch 458/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.6462 - val_accuracy: 0.9335\n",
      "Epoch 459/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.6021 - val_accuracy: 0.9337\n",
      "Epoch 460/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.6460 - val_accuracy: 0.9335\n",
      "Epoch 461/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.6990 - val_accuracy: 0.9334\n",
      "Epoch 462/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.3552 - val_accuracy: 0.9335\n",
      "Epoch 463/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.6717 - val_accuracy: 0.9355\n",
      "Epoch 464/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.8129 - val_accuracy: 0.9335\n",
      "Epoch 465/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.7526 - val_accuracy: 0.9335\n",
      "Epoch 466/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0104 - accuracy: 0.9975 - val_loss: 0.7462 - val_accuracy: 0.9335\n",
      "Epoch 467/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.6696 - val_accuracy: 0.9335\n",
      "Epoch 468/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.5655 - val_accuracy: 0.9333\n",
      "Epoch 469/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.5439 - val_accuracy: 0.9334\n",
      "Epoch 470/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.7623 - val_accuracy: 0.9338\n",
      "Epoch 471/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.8055 - val_accuracy: 0.9335\n",
      "Epoch 472/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.8726 - val_accuracy: 0.9335\n",
      "Epoch 473/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.5717 - val_accuracy: 0.9337\n",
      "Epoch 474/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.6954 - val_accuracy: 0.9335\n",
      "Epoch 475/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.6932 - val_accuracy: 0.9335\n",
      "Epoch 476/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.8103 - val_accuracy: 0.9335\n",
      "Epoch 477/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.8508 - val_accuracy: 0.9335\n",
      "Epoch 478/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.7595 - val_accuracy: 0.9339\n",
      "Epoch 479/500\n",
      "388/388 [==============================] - 34s 86ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.7216 - val_accuracy: 0.9353\n",
      "Epoch 480/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.8481 - val_accuracy: 0.9303\n",
      "Epoch 481/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.8189 - val_accuracy: 0.9316\n",
      "Epoch 482/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.8885 - val_accuracy: 0.9335\n",
      "Epoch 483/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.5231 - val_accuracy: 0.9344\n",
      "Epoch 484/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0127 - accuracy: 0.9975 - val_loss: 0.6501 - val_accuracy: 0.9335\n",
      "Epoch 485/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.5131 - val_accuracy: 0.9337\n",
      "Epoch 486/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.5265 - val_accuracy: 0.9325\n",
      "Epoch 487/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.7439 - val_accuracy: 0.9335\n",
      "Epoch 488/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.6343 - val_accuracy: 0.9329\n",
      "Epoch 489/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.6815 - val_accuracy: 0.9326\n",
      "Epoch 490/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.7936 - val_accuracy: 0.9334\n",
      "Epoch 491/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 0.6416 - val_accuracy: 0.9335\n",
      "Epoch 492/500\n",
      "388/388 [==============================] - 35s 89ms/step - loss: 0.0157 - accuracy: 0.9961 - val_loss: 0.4198 - val_accuracy: 0.9334\n",
      "Epoch 493/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.5945 - val_accuracy: 0.9324\n",
      "Epoch 494/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.6001 - val_accuracy: 0.9340\n",
      "Epoch 495/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.8065 - val_accuracy: 0.9333\n",
      "Epoch 496/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.6065 - val_accuracy: 0.9335\n",
      "Epoch 497/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.5968 - val_accuracy: 0.9348\n",
      "Epoch 498/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.6535 - val_accuracy: 0.9344\n",
      "Epoch 499/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.6880 - val_accuracy: 0.9335\n",
      "Epoch 500/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.7253 - val_accuracy: 0.9335\n"
     ]
    }
   ],
   "source": [
    "def batch_generator(image, label, batchsize):\n",
    "    N = len(image)\n",
    "    indices = np.arange(N)  # 0부터 N-1까지의 인덱스 배열 생성\n",
    "    np.random.shuffle(indices)  # 인덱스 배열을 무작위로 섞음\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i + batchsize <= N:\n",
    "            batch_indices = indices[i:i+batchsize]\n",
    "            i = i + batchsize\n",
    "        else:  # 남은 데이터가 batchsize보다 작을 때, 배열을 wrap around하여 다시 섞음\n",
    "            batch_indices = np.concatenate((indices[i:], indices[:batchsize - (N - i)]))\n",
    "            i = batchsize - (N - i)\n",
    "\n",
    "            np.random.shuffle(indices)  # 다음 에포크를 위해 인덱스 배열을 무작위로 섞음\n",
    "\n",
    "        yield image[batch_indices], label[batch_indices]\n",
    "        \n",
    "checkpoint_filepath = \"../../model/skip/EfficientNetV2B0_checkpoints.h5\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only= True\n",
    ")\n",
    "class_weight_ratio=compute_class_weight(class_weight = \"balanced\" , \n",
    "                     classes=np.unique(y_train), \n",
    "                     y = y_train)\n",
    "class_weight = {0:class_weight_ratio[0],1:class_weight_ratio[1]}\n",
    "\n",
    "input_t=K.Input(shape=(size,size, 3))\n",
    "input_tensor = layers.experimental.preprocessing.Resizing(size, size, interpolation=\"bilinear\", input_shape=x_train.shape[1:])(input_t)\n",
    "ResNet=EfficientNetV2B0(include_top=True,weights='imagenet',input_tensor=input_tensor)\n",
    "model = K.models.Sequential()\n",
    "model.add(ResNet)\n",
    "model.add(tf.keras.layers.Dropout(.2, input_shape=(64,)))\n",
    "model.add(K.layers.Dense(64, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "model.add(K.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=K.optimizers.Adam(lr=2e-4),\n",
    "                loss=tf.keras.losses.binary_crossentropy,\n",
    "                metrics=[\"accuracy\"])\n",
    "histo=model.fit(\n",
    "    batch_generator(x_train,y_train,64),\n",
    "    validation_data=(x_val,y_val),\n",
    "    epochs=500,\n",
    "    steps_per_epoch=len(x_train)//64,\n",
    "    callbacks=model_checkpoint_callback,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weight\n",
    ")\n",
    "model.save('../../model/skip/EfficientNetV2B0.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
