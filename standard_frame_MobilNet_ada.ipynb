{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras import datasets, layers, models, losses, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pre\n",
    "from glob import glob\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2,3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_img_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Train_dataframe.csv')['file_path'].to_list()\n",
    "Train_label_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Train_dataframe.csv')['standard'].to_list()\n",
    "Test_img_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Test_dataframe.csv')['file_path'].to_list()\n",
    "Test_label_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Test_dataframe.csv')['standard'].to_list()\n",
    "Val_img_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Validation_dataframe.csv')['file_path'].to_list()\n",
    "Val_label_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Validation_dataframe.csv')['standard'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_img_path='../../data/standardFrame_data/scale_skip/train'\n",
    "Test_img_path='../../data/standardFrame_data/scale_skip/test'\n",
    "Val_img_path='../../data/standardFrame_data/scale_skip/val'\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.5),\n",
    "    iaa.Affine(\n",
    "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "            rotate=(-30, 30),\n",
    "            shear=(-16, 16)\n",
    "            ),\n",
    "    iaa.TranslateX(px=(-20, 20)),\n",
    "    iaa.TranslateY(px=(-20, 20)),\n",
    "\n",
    "], random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=224\n",
    "x_train = np.zeros((len(Train_img_list)*4,size,size,3))\n",
    "y_train = np.zeros((len(Train_img_list)*4))\n",
    "for i in range(len(Train_img_list)):\n",
    "    x_train[i*4] =cv2.cvtColor(np.array(Image.open(Train_img_path+Train_img_list[i]).resize((size,size)).convert('L')),cv2.COLOR_GRAY2RGB)\n",
    "    x_train[i*4+1] =cv2.cvtColor(seq(images=np.array(Image.open(Train_img_path+Train_img_list[i]).resize((size,size)).convert('L'))),cv2.COLOR_GRAY2RGB)\n",
    "    x_train[i*4+2] =cv2.cvtColor(seq(images=np.array(Image.open(Train_img_path+Train_img_list[i]).resize((size,size)).convert('L'))),cv2.COLOR_GRAY2RGB)\n",
    "    x_train[i*4+3] =cv2.cvtColor(seq(images=np.array(Image.open(Train_img_path+Train_img_list[i]).resize((size,size)).convert('L'))),cv2.COLOR_GRAY2RGB)\n",
    "    y_train[i*4]=Train_label_list[i]\n",
    "    y_train[i*4+1]=Train_label_list[i]\n",
    "    y_train[i*4+2]=Train_label_list[i]\n",
    "    y_train[i*4+3]=Train_label_list[i]\n",
    "    \n",
    "x_train=x_train/255\n",
    "\n",
    "x_test = np.zeros((len(Test_img_list),size,size,3))\n",
    "for i in range(len(Test_img_list)):\n",
    "    x_test[i] =np.array(Image.open(Test_img_path+Test_img_list[i]).resize((size,size)))\n",
    "x_test=x_test/255\n",
    "y_test=np.array(Test_label_list)\n",
    "\n",
    "x_val = np.zeros((len(Val_img_list),size,size,3))\n",
    "for i in range(len(Val_img_list)):\n",
    "    x_val[i] =np.array(Image.open(Val_img_path+Val_img_list[i]).resize((size,size)))\n",
    "x_val=x_val/255\n",
    "y_val=np.array(Val_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(image, label, batchsize):\n",
    "    N = len(image)\n",
    "    indices = np.arange(N)  # 0부터 N-1까지의 인덱스 배열 생성\n",
    "    np.random.shuffle(indices)  # 인덱스 배열을 무작위로 섞음\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i + batchsize <= N:\n",
    "            batch_indices = indices[i:i+batchsize]\n",
    "            i = i + batchsize\n",
    "        else:  # 남은 데이터가 batchsize보다 작을 때, 배열을 wrap around하여 다시 섞음\n",
    "            batch_indices = np.concatenate((indices[i:], indices[:batchsize - (N - i)]))\n",
    "            i = batchsize - (N - i)\n",
    "\n",
    "            np.random.shuffle(indices)  # 다음 에포크를 위해 인덱스 배열을 무작위로 섞음\n",
    "\n",
    "        yield image[batch_indices], label[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_filepath = \"../../model/skip/MobileNetV2_ada_checkpoints.h5\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only= True\n",
    ")\n",
    "class_weight_ratio=compute_class_weight(class_weight = \"balanced\" , \n",
    "                     classes=np.unique(y_train), \n",
    "                     y = y_train)\n",
    "class_weight = {0:class_weight_ratio[0],1:class_weight_ratio[1]}\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=['/GPU:0','/GPU:1'])\n",
    "with mirrored_strategy.scope(): \n",
    "    input_t=K.Input(shape=(size,size, 3))\n",
    "    input_tensor = layers.experimental.preprocessing.Resizing(size, size, interpolation=\"bilinear\", input_shape=x_train.shape[1:])(input_t)\n",
    "    ResNet=K.applications.MobileNetV2(include_top=True,weights='imagenet',input_tensor=input_tensor)\n",
    "    model = K.models.Sequential()\n",
    "    model.add(ResNet)\n",
    "    model.add(tf.keras.layers.Dropout(.2, input_shape=(64,)))\n",
    "    model.add(K.layers.Dense(64, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "    model.add(K.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=K.optimizers.Adam(lr=2e-4),\n",
    "                    loss=tf.keras.losses.binary_crossentropy,\n",
    "                    metrics=[\"accuracy\"])\n",
    "    histo=model.fit(\n",
    "        batch_generator(x_train,y_train,64),\n",
    "        validation_data=(x_val,y_val),\n",
    "        epochs=500,\n",
    "        steps_per_epoch=len(x_train)//64,\n",
    "        callbacks=[model_checkpoint_callback],\n",
    "        shuffle=True,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    model.save('../../model/skip/MobileNetV2_ada.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
