{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 14:59:51.473466: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-23 14:59:52.034720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras as K\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm  \n",
    "# For data preprocessing\n",
    "from keras import losses\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow import image as tf_image\n",
    "from tensorflow import data as tf_data\n",
    "from tensorflow import io as tf_io\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# (2) keras backend 문법 사용 가능\n",
    "\n",
    "def dice_score_loss(y_true, y_pred):\n",
    "  numerator = 2. * tf.reduce_sum(y_true * y_pred)\n",
    "  denominator = tf.reduce_sum(y_true + y_pred)\n",
    "  return tf.reduce_mean(1 - numerator / denominator)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9857338845430198e6c87adffb6982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20088 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 8\n",
    "NUM_CLASSES = 4\n",
    "train_df = pd.read_csv(\n",
    "    '../../data/segmentationDDH/train_aug_segmentation_dataset.csv')\n",
    "val_df = pd.read_csv(\n",
    "    '../../data/segmentationDDH/val_aug_segmentation_dataset.csv')\n",
    "\n",
    "train_img_list = train_df['file name'].to_list()\n",
    "train_label_list = train_df['standard mask'].to_list()\n",
    "train_case_list = train_df['case'].to_list()\n",
    "train_img_path = '../../data/segmentationDDH/aug_dataset/train/'\n",
    "val_img_list = val_df['file name'].to_list()\n",
    "val_label_list = val_df['standard mask'].to_list()\n",
    "val_case_list = val_df['case'].to_list()\n",
    "val_img_path = '../../data/segmentationDDH/aug_dataset/val/'\n",
    "\n",
    "val_image=np.zeros((len(val_img_list),IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "val_mask=np.zeros((len(val_img_list),IMAGE_SIZE,IMAGE_SIZE,4),dtype=np.uint8)    \n",
    "train_image=np.zeros((len(train_img_list),IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "train_mask=np.zeros((len(train_img_list),IMAGE_SIZE,IMAGE_SIZE,4),dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(len(train_img_list))):\n",
    "    train_image[i] = np.array(Image.open(\n",
    "        train_img_path+str(train_case_list[i])+'/image/'+train_img_list[i]).resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    train_mask[i,:,:,0]=np.array(Image.open(\n",
    "        train_img_path+str(train_case_list[i])+'/mask/'+str(train_label_list[i]).zfill(5)+'/1'+train_img_list[i][train_img_list[i].find('_'):]).resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    train_mask[i,:,:,1]=np.array(Image.open(\n",
    "        train_img_path+str(train_case_list[i])+'/mask/'+str(train_label_list[i]).zfill(5)+'/2'+train_img_list[i][train_img_list[i].find('_'):]).resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    train_mask[i,:,:,2]=np.array(Image.open(\n",
    "        train_img_path+str(train_case_list[i])+'/mask/'+str(train_label_list[i]).zfill(5)+'/3'+train_img_list[i][train_img_list[i].find('_'):]).resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    train_mask[i,:,:,3]=np.array(Image.open(\n",
    "        train_img_path+str(train_case_list[i])+'/mask/'+str(train_label_list[i]).zfill(5)+'/4'+train_img_list[i][train_img_list[i].find('_'):]).resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "\n",
    "    \n",
    "\n",
    "for i in tqdm(range(len(val_img_list))):\n",
    "    val_image[i] = np.array(Image.open(\n",
    "        val_img_path+str(val_case_list[i])+'/image/'+val_img_list[i]).resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    val_mask[i,:,:,0]=np.array(Image.open(\n",
    "        val_img_path+str(val_case_list[i])+'/mask/'+str(val_label_list[i]).zfill(5)+'/1.png').resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    val_mask[i,:,:,1]=np.array(Image.open(\n",
    "        val_img_path+str(val_case_list[i])+'/mask/'+str(val_label_list[i]).zfill(5)+'/2.png').resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    val_mask[i,:,:,2]=np.array(Image.open(\n",
    "        val_img_path+str(val_case_list[i])+'/mask/'+str(val_label_list[i]).zfill(5)+'/3.png').resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    val_mask[i,:,:,3]=np.array(Image.open(\n",
    "        val_img_path+str(val_case_list[i])+'/mask/'+str(val_label_list[i]).zfill(5)+'/4.png').resize((IMAGE_SIZE, IMAGE_SIZE)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return ops.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output\n",
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "    preprocessed = keras.applications.resnet50.preprocess_input(model_input)\n",
    "    resnet50 = keras.applications.ResNet50(\n",
    "        weights=\"imagenet\", include_top=False, input_tensor=preprocessed\n",
    "    )\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "    input_a = layers.UpSampling2D(\n",
    "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
    "    return keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \"\"\"\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = K.eval(y_true)\n",
    "    y_pred = K.eval(y_pred)\n",
    "    intersection = np.sum(np.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection) / (np.sum(np.square(y_true), -1) + np.sum(np.square(y_pred), -1))\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    model=DeeplabV3Plus(IMAGE_SIZE,NUM_CLASSES)\n",
    "    checkpoint_filepath = \"../../model/segmentation/DeepLabV3_tf_checkpoints.keras\"\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_best_only= True\n",
    "    )\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=[dice_coef_loss],metrics=[dice_coef]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_image, train_mask, batch_size=BATCH_SIZE, epochs=300, validation_data=(val_image, val_mask),callbacks=model_checkpoint_callback\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
