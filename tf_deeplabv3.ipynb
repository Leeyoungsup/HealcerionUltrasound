{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm  \n",
    "# For data preprocessing\n",
    "from keras import losses\n",
    "from keras.losses import binary_crossentropy\n",
    "from PIL import Image\n",
    "from tensorflow import image as tf_image\n",
    "from tensorflow import data as tf_data\n",
    "from tensorflow import io as tf_io\n",
    "from keras import backend as K\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# (2) keras backend 문법 사용 가능\n",
    "\n",
    "def dice_score_loss(y_true, y_pred):\n",
    "  numerator = 2. * tf.reduce_sum(y_true * y_pred)\n",
    "  denominator = tf.reduce_sum(y_true + y_pred)\n",
    "  return tf.reduce_mean(1 - numerator / denominator)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d191ba3d51c4899913046ec47ac5ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20088 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab11fa9ef2e481b92826cfb821ffbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/479 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 8\n",
    "NUM_CLASSES = 4\n",
    "train_df = pd.read_csv(\n",
    "    '../../data/segmentationDDH/train_aug_segmentation_dataset.csv')\n",
    "val_df = pd.read_csv(\n",
    "    '../../data/segmentationDDH/val_aug_segmentation_dataset.csv')\n",
    "\n",
    "train_img_list = train_df['file name'].to_list()\n",
    "train_label_list = train_df['standard mask'].to_list()\n",
    "train_case_list = train_df['case'].to_list()\n",
    "train_img_path = '../../data/segmentationDDH/aug_dataset/train/'\n",
    "val_img_list = val_df['file name'].to_list()\n",
    "val_label_list = val_df['standard mask'].to_list()\n",
    "val_case_list = val_df['case'].to_list()\n",
    "val_img_path = '../../data/segmentationDDH/aug_dataset/val/'\n",
    "\n",
    "val_image=np.zeros((len(val_img_list),IMAGE_SIZE,IMAGE_SIZE,3),dtype=np.float32)\n",
    "val_mask=np.zeros((len(val_img_list),IMAGE_SIZE,IMAGE_SIZE,4),dtype=np.float32)    \n",
    "train_image=np.zeros((len(train_img_list),IMAGE_SIZE,IMAGE_SIZE,3),dtype=np.float32)\n",
    "train_mask=np.zeros((len(train_img_list),IMAGE_SIZE,IMAGE_SIZE,4),dtype=np.float32)\n",
    "\n",
    "for i in tqdm(range(len(train_img_list))):\n",
    "    train_image[i] = np.array(Image.open(\n",
    "        train_img_path+str(train_case_list[i])+'/image/'+train_img_list[i]).resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    train_mask[i,:,:,0]=np.array(Image.open(\n",
    "        train_img_path+str(train_case_list[i])+'/mask/'+str(train_label_list[i]).zfill(5)+'/1'+train_img_list[i][train_img_list[i].find('_'):]).resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    train_mask[i,:,:,1]=np.array(Image.open(\n",
    "        train_img_path+str(train_case_list[i])+'/mask/'+str(train_label_list[i]).zfill(5)+'/2'+train_img_list[i][train_img_list[i].find('_'):]).resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    train_mask[i,:,:,2]=np.array(Image.open(\n",
    "        train_img_path+str(train_case_list[i])+'/mask/'+str(train_label_list[i]).zfill(5)+'/3'+train_img_list[i][train_img_list[i].find('_'):]).resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    train_mask[i,:,:,3]=np.array(Image.open(\n",
    "        train_img_path+str(train_case_list[i])+'/mask/'+str(train_label_list[i]).zfill(5)+'/4'+train_img_list[i][train_img_list[i].find('_'):]).resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "\n",
    "    \n",
    "\n",
    "for i in tqdm(range(len(val_img_list))):\n",
    "    val_image[i] = np.array(Image.open(\n",
    "        val_img_path+str(val_case_list[i])+'/image/'+val_img_list[i]).resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    val_mask[i,:,:,0]=np.array(Image.open(\n",
    "        val_img_path+str(val_case_list[i])+'/mask/'+str(val_label_list[i]).zfill(5)+'/1.png').resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    val_mask[i,:,:,1]=np.array(Image.open(\n",
    "        val_img_path+str(val_case_list[i])+'/mask/'+str(val_label_list[i]).zfill(5)+'/2.png').resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    val_mask[i,:,:,2]=np.array(Image.open(\n",
    "        val_img_path+str(val_case_list[i])+'/mask/'+str(val_label_list[i]).zfill(5)+'/3.png').resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    val_mask[i,:,:,3]=np.array(Image.open(\n",
    "        val_img_path+str(val_case_list[i])+'/mask/'+str(val_label_list[i]).zfill(5)+'/4.png').resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "train_image=train_image/255.0\n",
    "val_image=val_image/255.0\n",
    "train_mask=train_mask/255.0\n",
    "val_mask=val_mask/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return ops.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output\n",
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "    preprocessed = keras.applications.resnet50.preprocess_input(model_input)\n",
    "    resnet50 = keras.applications.ResNet50(\n",
    "        weights=\"imagenet\", include_top=False, input_tensor=preprocessed\n",
    "    )\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "    input_a = layers.UpSampling2D(\n",
    "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
    "    return keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "\n",
    "def dice_loss(pred, target, num_classes=4):\n",
    "    smooth = 1.\n",
    "    dice_per_class = tf.Variable(tf.zeros(num_classes))\n",
    "    \n",
    "    for class_id in range(num_classes):\n",
    "        pred_class = pred[:, :,:, class_id]\n",
    "        target_class = target[:, :,:, class_id]\n",
    "\n",
    "        intersection = tf.reduce_sum(pred_class * target_class)\n",
    "        A_sum = tf.reduce_sum(pred_class * pred_class)\n",
    "        B_sum = tf.reduce_sum(target_class * target_class)\n",
    "\n",
    "        dice_per_class[class_id].assign(1 - (2. * intersection + smooth) / (A_sum + B_sum + smooth))\n",
    "    with tf.GradientTape():\n",
    "        return tf.reduce_mean(dice_per_class)\n",
    "\n",
    "def dice_cof(pred, target):\n",
    "    with tf.GradientTape():\n",
    "        return 1-dice_loss(pred, target, num_classes=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 09:08:31.857794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38158 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m model_checkpoint_callback \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m      5\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mcheckpoint_filepath,\n\u001b[1;32m      6\u001b[0m     save_best_only\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mdice_loss, optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[dice_cof])\n\u001b[0;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/src/optimizers/base_optimizer.py:571\u001b[0m, in \u001b[0;36mBaseOptimizer._filter_empty_gradients\u001b[0;34m(self, grads, vars)\u001b[0m\n\u001b[1;32m    567\u001b[0m filtered \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    568\u001b[0m     (g, v) \u001b[38;5;28;01mfor\u001b[39;00m g, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(grads, \u001b[38;5;28mvars\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    569\u001b[0m ]\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filtered:\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo gradients provided for any variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(filtered) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(grads):\n\u001b[1;32m    573\u001b[0m     missing_grad_vars \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    574\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m g, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(grads, \u001b[38;5;28mvars\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    575\u001b[0m     ]\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with tf.GradientTape():\n",
    "    model=DeeplabV3Plus(IMAGE_SIZE,NUM_CLASSES)\n",
    "    checkpoint_filepath = \"../../model/segmentation/DeepLabV3_tf_checkpoints.keras\"\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_best_only= True\n",
    "    )\n",
    "    model.compile(loss=dice_loss, optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=[dice_cof])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_image, train_mask, batch_size=BATCH_SIZE, epochs=100, validation_data=(val_image, val_mask),callbacks=[model_checkpoint_callback]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.dice_loss(pred, target, num_classes=4)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
