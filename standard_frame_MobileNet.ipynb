{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 13:40:09.218596: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-11 13:40:09.925314: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from keras.applications import MobileNet\n",
    "from tensorflow.keras import datasets, layers, models, losses, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pre\n",
    "from glob import glob\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_img_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Train_dataframe.csv')['file_path'].to_list()\n",
    "Train_label_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Train_dataframe.csv')['standard'].to_list()\n",
    "Test_img_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Test_dataframe.csv')['file_path'].to_list()\n",
    "Test_label_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Test_dataframe.csv')['standard'].to_list()\n",
    "Val_img_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Validation_dataframe.csv')['file_path'].to_list()\n",
    "Val_label_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Validation_dataframe.csv')['standard'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_img_path='../../data/standardFrame_data/scale_skip/train'\n",
    "Test_img_path='../../data/standardFrame_data/scale_skip/test'\n",
    "Val_img_path='../../data/standardFrame_data/scale_skip/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=224\n",
    "x_train = np.zeros((len(Train_img_list),size,size,3))\n",
    "for i in range(len(Train_img_list)):\n",
    "    x_train[i] =np.array(Image.open(Train_img_path+Train_img_list[i]).resize((size,size)))\n",
    "x_train=x_train/255\n",
    "y_train=np.array(Train_label_list)\n",
    "\n",
    "x_test = np.zeros((len(Test_img_list),size,size,3))\n",
    "for i in range(len(Test_img_list)):\n",
    "    x_test[i] =np.array(Image.open(Test_img_path+Test_img_list[i]).resize((size,size)))\n",
    "x_test=x_test/255\n",
    "y_test=np.array(Test_label_list)\n",
    "\n",
    "x_val = np.zeros((len(Val_img_list),size,size,3))\n",
    "for i in range(len(Val_img_list)):\n",
    "    x_val[i] =np.array(Image.open(Val_img_path+Val_img_list[i]).resize((size,size)))\n",
    "x_val=x_val/255\n",
    "y_val=np.array(Val_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 13:43:54.214753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38163 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 13:43:55.763902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-08-11 13:43:59.084567: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/mobilenet_1.00_224/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-08-11 13:44:00.493530: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8902\n",
      "2023-08-11 13:44:01.220675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-11 13:44:01.242023: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7efe897e0660 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-11 13:44:01.242048: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2023-08-11 13:44:01.246472: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-11 13:44:01.372807: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 53s 102ms/step - loss: 0.5806 - accuracy: 0.6927 - val_loss: 1.0653 - val_accuracy: 0.3583\n",
      "Epoch 2/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.4782 - accuracy: 0.7636 - val_loss: 0.6016 - val_accuracy: 0.6608\n",
      "Epoch 3/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.4432 - accuracy: 0.7415 - val_loss: 0.4443 - val_accuracy: 0.7700\n",
      "Epoch 4/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.3722 - accuracy: 0.7783 - val_loss: 0.2444 - val_accuracy: 0.8551\n",
      "Epoch 5/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.2829 - accuracy: 0.8537 - val_loss: 0.2017 - val_accuracy: 0.9271\n",
      "Epoch 6/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.2551 - accuracy: 0.8791 - val_loss: 0.2389 - val_accuracy: 0.9054\n",
      "Epoch 7/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.2094 - accuracy: 0.9046 - val_loss: 0.2541 - val_accuracy: 0.9239\n",
      "Epoch 8/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.1775 - accuracy: 0.9220 - val_loss: 0.2473 - val_accuracy: 0.9054\n",
      "Epoch 9/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.1536 - accuracy: 0.9348 - val_loss: 0.2657 - val_accuracy: 0.9333\n",
      "Epoch 10/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.1348 - accuracy: 0.9388 - val_loss: 0.2384 - val_accuracy: 0.9049\n",
      "Epoch 11/500\n",
      "388/388 [==============================] - 36s 93ms/step - loss: 0.1163 - accuracy: 0.9498 - val_loss: 0.3297 - val_accuracy: 0.9312\n",
      "Epoch 12/500\n",
      "388/388 [==============================] - 38s 99ms/step - loss: 0.1137 - accuracy: 0.9516 - val_loss: 0.2760 - val_accuracy: 0.9005\n",
      "Epoch 13/500\n",
      "388/388 [==============================] - 37s 95ms/step - loss: 0.1147 - accuracy: 0.9491 - val_loss: 0.2434 - val_accuracy: 0.9210\n",
      "Epoch 14/500\n",
      "388/388 [==============================] - 38s 97ms/step - loss: 0.0957 - accuracy: 0.9557 - val_loss: 0.3253 - val_accuracy: 0.9282\n",
      "Epoch 15/500\n",
      "388/388 [==============================] - 39s 102ms/step - loss: 0.0830 - accuracy: 0.9637 - val_loss: 0.3277 - val_accuracy: 0.9284\n",
      "Epoch 16/500\n",
      "388/388 [==============================] - 40s 104ms/step - loss: 0.0846 - accuracy: 0.9642 - val_loss: 0.3844 - val_accuracy: 0.9330\n",
      "Epoch 17/500\n",
      "388/388 [==============================] - 37s 95ms/step - loss: 0.0656 - accuracy: 0.9733 - val_loss: 0.3095 - val_accuracy: 0.9312\n",
      "Epoch 18/500\n",
      "388/388 [==============================] - 38s 98ms/step - loss: 0.0635 - accuracy: 0.9739 - val_loss: 0.3467 - val_accuracy: 0.9236\n",
      "Epoch 19/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0661 - accuracy: 0.9738 - val_loss: 0.5484 - val_accuracy: 0.9326\n",
      "Epoch 20/500\n",
      "388/388 [==============================] - 43s 111ms/step - loss: 0.0511 - accuracy: 0.9791 - val_loss: 0.3325 - val_accuracy: 0.9219\n",
      "Epoch 21/500\n",
      "388/388 [==============================] - 52s 134ms/step - loss: 0.0391 - accuracy: 0.9853 - val_loss: 0.6289 - val_accuracy: 0.9309\n",
      "Epoch 22/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0453 - accuracy: 0.9799 - val_loss: 0.8644 - val_accuracy: 0.9335\n",
      "Epoch 23/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0370 - accuracy: 0.9865 - val_loss: 0.4736 - val_accuracy: 0.9313\n",
      "Epoch 24/500\n",
      "388/388 [==============================] - 38s 97ms/step - loss: 0.0338 - accuracy: 0.9851 - val_loss: 0.6372 - val_accuracy: 0.9327\n",
      "Epoch 25/500\n",
      "388/388 [==============================] - 38s 98ms/step - loss: 0.0336 - accuracy: 0.9857 - val_loss: 0.5025 - val_accuracy: 0.9321\n",
      "Epoch 26/500\n",
      "388/388 [==============================] - 40s 102ms/step - loss: 0.0314 - accuracy: 0.9890 - val_loss: 0.7703 - val_accuracy: 0.9333\n",
      "Epoch 27/500\n",
      "388/388 [==============================] - 42s 109ms/step - loss: 0.0312 - accuracy: 0.9894 - val_loss: 0.3285 - val_accuracy: 0.9325\n",
      "Epoch 28/500\n",
      "388/388 [==============================] - 48s 125ms/step - loss: 0.0351 - accuracy: 0.9864 - val_loss: 0.6787 - val_accuracy: 0.9324\n",
      "Epoch 29/500\n",
      "388/388 [==============================] - 49s 125ms/step - loss: 0.0350 - accuracy: 0.9872 - val_loss: 0.5439 - val_accuracy: 0.9315\n",
      "Epoch 30/500\n",
      "388/388 [==============================] - 42s 107ms/step - loss: 0.0348 - accuracy: 0.9869 - val_loss: 0.8561 - val_accuracy: 0.9337\n",
      "Epoch 31/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0353 - accuracy: 0.9871 - val_loss: 0.5330 - val_accuracy: 0.9312\n",
      "Epoch 32/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.8512 - val_accuracy: 0.9335\n",
      "Epoch 33/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0334 - accuracy: 0.9863 - val_loss: 0.4239 - val_accuracy: 0.9242\n",
      "Epoch 34/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0284 - accuracy: 0.9899 - val_loss: 0.6211 - val_accuracy: 0.9321\n",
      "Epoch 35/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 0.8379 - val_accuracy: 0.9333\n",
      "Epoch 36/500\n",
      "388/388 [==============================] - 37s 96ms/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 0.8333 - val_accuracy: 0.9334\n",
      "Epoch 37/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0314 - accuracy: 0.9892 - val_loss: 0.4753 - val_accuracy: 0.9208\n",
      "Epoch 38/500\n",
      "388/388 [==============================] - 35s 91ms/step - loss: 0.0257 - accuracy: 0.9900 - val_loss: 0.4507 - val_accuracy: 0.9268\n",
      "Epoch 39/500\n",
      "388/388 [==============================] - 41s 107ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.7495 - val_accuracy: 0.9331\n",
      "Epoch 40/500\n",
      "388/388 [==============================] - 37s 96ms/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.6938 - val_accuracy: 0.9299\n",
      "Epoch 41/500\n",
      "388/388 [==============================] - 40s 103ms/step - loss: 0.0128 - accuracy: 0.9952 - val_loss: 0.6111 - val_accuracy: 0.9302\n",
      "Epoch 42/500\n",
      "388/388 [==============================] - 49s 127ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.2834 - val_accuracy: 0.9052\n",
      "Epoch 43/500\n",
      "388/388 [==============================] - 38s 99ms/step - loss: 0.0177 - accuracy: 0.9935 - val_loss: 0.3985 - val_accuracy: 0.9230\n",
      "Epoch 44/500\n",
      "388/388 [==============================] - 37s 97ms/step - loss: 0.0215 - accuracy: 0.9923 - val_loss: 0.8387 - val_accuracy: 0.9299\n",
      "Epoch 45/500\n",
      "388/388 [==============================] - 42s 110ms/step - loss: 0.0229 - accuracy: 0.9918 - val_loss: 0.5837 - val_accuracy: 0.9324\n",
      "Epoch 46/500\n",
      "388/388 [==============================] - 34s 87ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.5120 - val_accuracy: 0.9308\n",
      "Epoch 47/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.4225 - val_accuracy: 0.9300\n",
      "Epoch 48/500\n",
      "388/388 [==============================] - 34s 86ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.5590 - val_accuracy: 0.9320\n",
      "Epoch 49/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.3993 - val_accuracy: 0.9276\n",
      "Epoch 50/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0107 - accuracy: 0.9959 - val_loss: 0.6220 - val_accuracy: 0.9321\n",
      "Epoch 51/500\n",
      "388/388 [==============================] - 36s 93ms/step - loss: 0.0306 - accuracy: 0.9880 - val_loss: 0.6610 - val_accuracy: 0.9273\n",
      "Epoch 52/500\n",
      "388/388 [==============================] - 41s 107ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.6879 - val_accuracy: 0.9326\n",
      "Epoch 53/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.2973 - val_accuracy: 0.9132\n",
      "Epoch 54/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.8468 - val_accuracy: 0.9330\n",
      "Epoch 55/500\n",
      "388/388 [==============================] - 41s 106ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.6724 - val_accuracy: 0.9318\n",
      "Epoch 56/500\n",
      "388/388 [==============================] - 40s 103ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.3025 - val_accuracy: 0.9258\n",
      "Epoch 57/500\n",
      "388/388 [==============================] - 36s 94ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.6187 - val_accuracy: 0.9317\n",
      "Epoch 58/500\n",
      "388/388 [==============================] - 41s 106ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.6838 - val_accuracy: 0.9333\n",
      "Epoch 59/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.6111 - val_accuracy: 0.9320\n",
      "Epoch 60/500\n",
      "388/388 [==============================] - 38s 99ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.6796 - val_accuracy: 0.8597\n",
      "Epoch 61/500\n",
      "388/388 [==============================] - 42s 108ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.6162 - val_accuracy: 0.9284\n",
      "Epoch 62/500\n",
      "388/388 [==============================] - 42s 108ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.7776 - val_accuracy: 0.9284\n",
      "Epoch 63/500\n",
      "388/388 [==============================] - 40s 103ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 0.3713 - val_accuracy: 0.9157\n",
      "Epoch 64/500\n",
      "388/388 [==============================] - 37s 96ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.6074 - val_accuracy: 0.9299\n",
      "Epoch 65/500\n",
      "388/388 [==============================] - 36s 92ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.5437 - val_accuracy: 0.9318\n",
      "Epoch 66/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.5802 - val_accuracy: 0.9299\n",
      "Epoch 67/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.7239 - val_accuracy: 0.9318\n",
      "Epoch 68/500\n",
      "388/388 [==============================] - 34s 89ms/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 0.5850 - val_accuracy: 0.9316\n",
      "Epoch 69/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.3401 - val_accuracy: 0.9194\n",
      "Epoch 70/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.4695 - val_accuracy: 0.9241\n",
      "Epoch 71/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.5292 - val_accuracy: 0.9298\n",
      "Epoch 72/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.6480 - val_accuracy: 0.9271\n",
      "Epoch 73/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.6473 - val_accuracy: 0.9309\n",
      "Epoch 74/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.4627 - val_accuracy: 0.9129\n",
      "Epoch 75/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.3049 - val_accuracy: 0.9160\n",
      "Epoch 76/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.6773 - val_accuracy: 0.9330\n",
      "Epoch 77/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.5846 - val_accuracy: 0.9318\n",
      "Epoch 78/500\n",
      "388/388 [==============================] - 32s 84ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.5163 - val_accuracy: 0.9147\n",
      "Epoch 79/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0127 - accuracy: 0.9948 - val_loss: 0.8735 - val_accuracy: 0.9315\n",
      "Epoch 80/500\n",
      "388/388 [==============================] - 35s 90ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.6504 - val_accuracy: 0.9308\n",
      "Epoch 81/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0171 - accuracy: 0.9940 - val_loss: 0.7178 - val_accuracy: 0.9308\n",
      "Epoch 82/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.8016 - val_accuracy: 0.9313\n",
      "Epoch 83/500\n",
      "388/388 [==============================] - 38s 97ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.8636 - val_accuracy: 0.9322\n",
      "Epoch 84/500\n",
      "388/388 [==============================] - 41s 105ms/step - loss: 0.0145 - accuracy: 0.9946 - val_loss: 0.8374 - val_accuracy: 0.9325\n",
      "Epoch 85/500\n",
      "388/388 [==============================] - 37s 96ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.4144 - val_accuracy: 0.9264\n",
      "Epoch 86/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 1.0129 - val_accuracy: 0.9331\n",
      "Epoch 87/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0202 - accuracy: 0.9920 - val_loss: 0.8830 - val_accuracy: 0.9316\n",
      "Epoch 88/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.9994 - val_accuracy: 0.9327\n",
      "Epoch 89/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.7753 - val_accuracy: 0.9313\n",
      "Epoch 90/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.6265 - val_accuracy: 0.9285\n",
      "Epoch 91/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.3423 - val_accuracy: 0.9052\n",
      "Epoch 92/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.9659 - val_accuracy: 0.9316\n",
      "Epoch 93/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.9037 - val_accuracy: 0.9317\n",
      "Epoch 94/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.6034 - val_accuracy: 0.9300\n",
      "Epoch 95/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.6263 - val_accuracy: 0.9291\n",
      "Epoch 96/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 0.5285 - val_accuracy: 0.9245\n",
      "Epoch 97/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.7086 - val_accuracy: 0.9264\n",
      "Epoch 98/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.7110 - val_accuracy: 0.9309\n",
      "Epoch 99/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.5478 - val_accuracy: 0.9284\n",
      "Epoch 100/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.6697 - val_accuracy: 0.9312\n",
      "Epoch 101/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.6427 - val_accuracy: 0.9317\n",
      "Epoch 102/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0153 - accuracy: 0.9961 - val_loss: 0.6375 - val_accuracy: 0.9317\n",
      "Epoch 103/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.7049 - val_accuracy: 0.9329\n",
      "Epoch 104/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.5371 - val_accuracy: 0.9324\n",
      "Epoch 105/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.6302 - val_accuracy: 0.9331\n",
      "Epoch 106/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.7024 - val_accuracy: 0.9329\n",
      "Epoch 107/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.6350 - val_accuracy: 0.9331\n",
      "Epoch 108/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.4446 - val_accuracy: 0.9251\n",
      "Epoch 109/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.6100 - val_accuracy: 0.9318\n",
      "Epoch 110/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.7127 - val_accuracy: 0.9317\n",
      "Epoch 111/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.6031 - val_accuracy: 0.9303\n",
      "Epoch 112/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.4457 - val_accuracy: 0.9299\n",
      "Epoch 113/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.7039 - val_accuracy: 0.9322\n",
      "Epoch 114/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.6854 - val_accuracy: 0.9273\n",
      "Epoch 115/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.7171 - val_accuracy: 0.9297\n",
      "Epoch 116/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.7108 - val_accuracy: 0.9286\n",
      "Epoch 117/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.5320 - val_accuracy: 0.9303\n",
      "Epoch 118/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.5674 - val_accuracy: 0.9298\n",
      "Epoch 119/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.7389 - val_accuracy: 0.9321\n",
      "Epoch 120/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.7897 - val_accuracy: 0.9294\n",
      "Epoch 121/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.4311 - val_accuracy: 0.9272\n",
      "Epoch 122/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.7648 - val_accuracy: 0.9308\n",
      "Epoch 123/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.8529 - val_accuracy: 0.9300\n",
      "Epoch 124/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 0.3289 - val_accuracy: 0.9232\n",
      "Epoch 125/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.5735 - val_accuracy: 0.9304\n",
      "Epoch 126/500\n",
      "388/388 [==============================] - 34s 88ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.4860 - val_accuracy: 0.9308\n",
      "Epoch 127/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.5775 - val_accuracy: 0.9303\n",
      "Epoch 128/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.7370 - val_accuracy: 0.9315\n",
      "Epoch 129/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.5782 - val_accuracy: 0.7894\n",
      "Epoch 130/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.5730 - val_accuracy: 0.9312\n",
      "Epoch 131/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.4457 - val_accuracy: 0.9300\n",
      "Epoch 132/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.5688 - val_accuracy: 0.9312\n",
      "Epoch 133/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.4918 - val_accuracy: 0.9255\n",
      "Epoch 134/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.6716 - val_accuracy: 0.9285\n",
      "Epoch 135/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.6601 - val_accuracy: 0.9303\n",
      "Epoch 136/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.6655 - val_accuracy: 0.9261\n",
      "Epoch 137/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.4241 - val_accuracy: 0.9261\n",
      "Epoch 138/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.4722 - val_accuracy: 0.9222\n",
      "Epoch 139/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.5277 - val_accuracy: 0.9329\n",
      "Epoch 140/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.5192 - val_accuracy: 0.9337\n",
      "Epoch 141/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.6010 - val_accuracy: 0.9288\n",
      "Epoch 142/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.5916 - val_accuracy: 0.9284\n",
      "Epoch 143/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.8607 - val_accuracy: 0.9335\n",
      "Epoch 144/500\n",
      "388/388 [==============================] - 32s 84ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.4851 - val_accuracy: 0.9279\n",
      "Epoch 145/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.3957 - val_accuracy: 0.9217\n",
      "Epoch 146/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.6908 - val_accuracy: 0.9309\n",
      "Epoch 147/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.6981 - val_accuracy: 0.9321\n",
      "Epoch 148/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.7654 - val_accuracy: 0.9318\n",
      "Epoch 149/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.8099 - val_accuracy: 0.9313\n",
      "Epoch 150/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.6957 - val_accuracy: 0.9294\n",
      "Epoch 151/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.7466 - val_accuracy: 0.9302\n",
      "Epoch 152/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.7722 - val_accuracy: 0.9299\n",
      "Epoch 153/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.8071 - val_accuracy: 0.9308\n",
      "Epoch 154/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.7813 - val_accuracy: 0.9285\n",
      "Epoch 155/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.7155 - val_accuracy: 0.9291\n",
      "Epoch 156/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.7452 - val_accuracy: 0.9297\n",
      "Epoch 157/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.7669 - val_accuracy: 0.9285\n",
      "Epoch 158/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.5128 - val_accuracy: 0.8668\n",
      "Epoch 159/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0180 - accuracy: 0.9952 - val_loss: 0.3895 - val_accuracy: 0.8636\n",
      "Epoch 160/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0219 - accuracy: 0.9930 - val_loss: 0.6077 - val_accuracy: 0.9318\n",
      "Epoch 161/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.5972 - val_accuracy: 0.9308\n",
      "Epoch 162/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.3615 - val_accuracy: 0.9102\n",
      "Epoch 163/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.6409 - val_accuracy: 0.9327\n",
      "Epoch 164/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.7307 - val_accuracy: 0.9333\n",
      "Epoch 165/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.5571 - val_accuracy: 0.9279\n",
      "Epoch 166/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.4676 - val_accuracy: 0.9264\n",
      "Epoch 167/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.6533 - val_accuracy: 0.9318\n",
      "Epoch 168/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.6618 - val_accuracy: 0.9320\n",
      "Epoch 169/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.7235 - val_accuracy: 0.9330\n",
      "Epoch 170/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4774 - val_accuracy: 0.9215\n",
      "Epoch 171/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.5356 - val_accuracy: 0.9329\n",
      "Epoch 172/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.5968 - val_accuracy: 0.9327\n",
      "Epoch 173/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.6194 - val_accuracy: 0.9330\n",
      "Epoch 174/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.6099 - val_accuracy: 0.9324\n",
      "Epoch 175/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.6653 - val_accuracy: 0.9337\n",
      "Epoch 176/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.7038 - val_accuracy: 0.9330\n",
      "Epoch 177/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.7230 - val_accuracy: 0.9331\n",
      "Epoch 178/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.7269 - val_accuracy: 0.9322\n",
      "Epoch 179/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.7488 - val_accuracy: 0.9321\n",
      "Epoch 180/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0176 - accuracy: 0.9956 - val_loss: 0.4902 - val_accuracy: 0.9311\n",
      "Epoch 181/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0160 - accuracy: 0.9940 - val_loss: 0.7359 - val_accuracy: 0.9337\n",
      "Epoch 182/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.6532 - val_accuracy: 0.9334\n",
      "Epoch 183/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.5330 - val_accuracy: 0.9327\n",
      "Epoch 184/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.6217 - val_accuracy: 0.9338\n",
      "Epoch 185/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.5088 - val_accuracy: 0.9298\n",
      "Epoch 186/500\n",
      "388/388 [==============================] - 33s 86ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.6138 - val_accuracy: 0.9318\n",
      "Epoch 187/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.7264 - val_accuracy: 0.9329\n",
      "Epoch 188/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.4119 - val_accuracy: 0.9255\n",
      "Epoch 189/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.6803 - val_accuracy: 0.9313\n",
      "Epoch 190/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5364 - val_accuracy: 0.9282\n",
      "Epoch 191/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.7649 - val_accuracy: 0.9302\n",
      "Epoch 192/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.7912 - val_accuracy: 0.9313\n",
      "Epoch 193/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.8249 - val_accuracy: 0.9312\n",
      "Epoch 194/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 1.0287 - val_accuracy: 0.9325\n",
      "Epoch 195/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.9207 - val_accuracy: 0.9303\n",
      "Epoch 196/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.9604 - val_accuracy: 0.9322\n",
      "Epoch 197/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.6279 - val_accuracy: 0.9298\n",
      "Epoch 198/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.7509 - val_accuracy: 0.9329\n",
      "Epoch 199/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0094 - accuracy: 0.9964 - val_loss: 0.6722 - val_accuracy: 0.9290\n",
      "Epoch 200/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.8040 - val_accuracy: 0.9324\n",
      "Epoch 201/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.7459 - val_accuracy: 0.9312\n",
      "Epoch 202/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.8172 - val_accuracy: 0.9315\n",
      "Epoch 203/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.8252 - val_accuracy: 0.9318\n",
      "Epoch 204/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.8497 - val_accuracy: 0.9318\n",
      "Epoch 205/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.4197 - val_accuracy: 0.9169\n",
      "Epoch 206/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.6964 - val_accuracy: 0.9315\n",
      "Epoch 207/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.5501 - val_accuracy: 0.9309\n",
      "Epoch 208/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.5132 - val_accuracy: 0.9312\n",
      "Epoch 209/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.5947 - val_accuracy: 0.9317\n",
      "Epoch 210/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.7022 - val_accuracy: 0.9312\n",
      "Epoch 211/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.5519 - val_accuracy: 0.9311\n",
      "Epoch 212/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0156 - accuracy: 0.9959 - val_loss: 0.4422 - val_accuracy: 0.9291\n",
      "Epoch 213/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.5611 - val_accuracy: 0.9325\n",
      "Epoch 214/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.5135 - val_accuracy: 0.9293\n",
      "Epoch 215/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.5630 - val_accuracy: 0.9308\n",
      "Epoch 216/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.6534 - val_accuracy: 0.9303\n",
      "Epoch 217/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.5896 - val_accuracy: 0.9291\n",
      "Epoch 218/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.6560 - val_accuracy: 0.9327\n",
      "Epoch 219/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.5865 - val_accuracy: 0.9308\n",
      "Epoch 220/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.5125 - val_accuracy: 0.9315\n",
      "Epoch 221/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.5803 - val_accuracy: 0.9315\n",
      "Epoch 222/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.5426 - val_accuracy: 0.9309\n",
      "Epoch 223/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.6231 - val_accuracy: 0.9294\n",
      "Epoch 224/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.4521 - val_accuracy: 0.9290\n",
      "Epoch 225/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.5340 - val_accuracy: 0.9285\n",
      "Epoch 226/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.5535 - val_accuracy: 0.9289\n",
      "Epoch 227/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.6092 - val_accuracy: 0.9279\n",
      "Epoch 228/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.7287 - val_accuracy: 0.9293\n",
      "Epoch 229/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 9.3246e-04 - accuracy: 0.9998 - val_loss: 0.7602 - val_accuracy: 0.9282\n",
      "Epoch 230/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.6409 - val_accuracy: 0.9325\n",
      "Epoch 231/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.6347 - val_accuracy: 0.9315\n",
      "Epoch 232/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.5345 - val_accuracy: 0.9304\n",
      "Epoch 233/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.3675 - val_accuracy: 0.9106\n",
      "Epoch 234/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.5595 - val_accuracy: 0.9311\n",
      "Epoch 235/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5926 - val_accuracy: 0.9295\n",
      "Epoch 236/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.6489 - val_accuracy: 0.9303\n",
      "Epoch 237/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.6527 - val_accuracy: 0.9304\n",
      "Epoch 238/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.6791 - val_accuracy: 0.9311\n",
      "Epoch 239/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.6973 - val_accuracy: 0.9294\n",
      "Epoch 240/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.5445 - val_accuracy: 0.9303\n",
      "Epoch 241/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.5638 - val_accuracy: 0.9322\n",
      "Epoch 242/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4964 - val_accuracy: 0.9316\n",
      "Epoch 243/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.4125 - val_accuracy: 0.9288\n",
      "Epoch 244/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.5892 - val_accuracy: 0.9317\n",
      "Epoch 245/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.6675 - val_accuracy: 0.9316\n",
      "Epoch 246/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.6904 - val_accuracy: 0.9315\n",
      "Epoch 247/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.7176 - val_accuracy: 0.9315\n",
      "Epoch 248/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.7562 - val_accuracy: 0.9315\n",
      "Epoch 249/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.7629 - val_accuracy: 0.9315\n",
      "Epoch 250/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.7899 - val_accuracy: 0.9316\n",
      "Epoch 251/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.5161 - val_accuracy: 0.9290\n",
      "Epoch 252/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.7238 - val_accuracy: 0.9329\n",
      "Epoch 253/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.7489 - val_accuracy: 0.9317\n",
      "Epoch 254/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.8889 - val_accuracy: 0.9327\n",
      "Epoch 255/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.8480 - val_accuracy: 0.9333\n",
      "Epoch 256/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 0.9339 - val_accuracy: 0.9337\n",
      "Epoch 257/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.5871 - val_accuracy: 0.9308\n",
      "Epoch 258/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.6310 - val_accuracy: 0.9316\n",
      "Epoch 259/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.7578 - val_accuracy: 0.9321\n",
      "Epoch 260/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.7152 - val_accuracy: 0.9317\n",
      "Epoch 261/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.7548 - val_accuracy: 0.9309\n",
      "Epoch 262/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.6983 - val_accuracy: 0.9306\n",
      "Epoch 263/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.9183 - val_accuracy: 0.9329\n",
      "Epoch 264/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.7669 - val_accuracy: 0.9300\n",
      "Epoch 265/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0290 - accuracy: 0.9900 - val_loss: 0.5322 - val_accuracy: 0.9277\n",
      "Epoch 266/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.6449 - val_accuracy: 0.9307\n",
      "Epoch 267/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.9400 - val_accuracy: 0.9327\n",
      "Epoch 268/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.6802 - val_accuracy: 0.9266\n",
      "Epoch 269/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.7340 - val_accuracy: 0.9284\n",
      "Epoch 270/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 0.3384 - val_accuracy: 0.9272\n",
      "Epoch 271/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.6042 - val_accuracy: 0.9277\n",
      "Epoch 272/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.6957 - val_accuracy: 0.9281\n",
      "Epoch 273/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.6594 - val_accuracy: 0.9290\n",
      "Epoch 274/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.6178 - val_accuracy: 0.9281\n",
      "Epoch 275/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.6376 - val_accuracy: 0.9255\n",
      "Epoch 276/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.6576 - val_accuracy: 0.9271\n",
      "Epoch 277/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.8082 - val_accuracy: 0.9286\n",
      "Epoch 278/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.9411 - val_accuracy: 0.9312\n",
      "Epoch 279/500\n",
      "388/388 [==============================] - 30s 78ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.9014 - val_accuracy: 0.9307\n",
      "Epoch 280/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.9890 - val_accuracy: 0.9312\n",
      "Epoch 281/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.7939 - val_accuracy: 0.9299\n",
      "Epoch 282/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.7734 - val_accuracy: 0.9281\n",
      "Epoch 283/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.4864 - val_accuracy: 0.9205\n",
      "Epoch 284/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.7954 - val_accuracy: 0.9303\n",
      "Epoch 285/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.8247 - val_accuracy: 0.9293\n",
      "Epoch 286/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.9009 - val_accuracy: 0.9308\n",
      "Epoch 287/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.8824 - val_accuracy: 0.9300\n",
      "Epoch 288/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.7801 - val_accuracy: 0.9320\n",
      "Epoch 289/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.6320 - val_accuracy: 0.9249\n",
      "Epoch 290/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.8721 - val_accuracy: 0.9313\n",
      "Epoch 291/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.8607 - val_accuracy: 0.9307\n",
      "Epoch 292/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.8655 - val_accuracy: 0.9303\n",
      "Epoch 293/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.8981 - val_accuracy: 0.9304\n",
      "Epoch 294/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.6458 - val_accuracy: 0.9280\n",
      "Epoch 295/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.7059 - val_accuracy: 0.9316\n",
      "Epoch 296/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.8073 - val_accuracy: 0.9311\n",
      "Epoch 297/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.8877 - val_accuracy: 0.9308\n",
      "Epoch 298/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.7018 - val_accuracy: 0.9308\n",
      "Epoch 299/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.7525 - val_accuracy: 0.9313\n",
      "Epoch 300/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.6740 - val_accuracy: 0.9289\n",
      "Epoch 301/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.7883 - val_accuracy: 0.9295\n",
      "Epoch 302/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.8820 - val_accuracy: 0.9320\n",
      "Epoch 303/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.8680 - val_accuracy: 0.9312\n",
      "Epoch 304/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.9580 - val_accuracy: 0.9326\n",
      "Epoch 305/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.5982 - val_accuracy: 0.9277\n",
      "Epoch 306/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.5600 - val_accuracy: 0.9324\n",
      "Epoch 307/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.6555 - val_accuracy: 0.9326\n",
      "Epoch 308/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.7363 - val_accuracy: 0.9325\n",
      "Epoch 309/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0247 - accuracy: 0.9938 - val_loss: 0.6776 - val_accuracy: 0.9327\n",
      "Epoch 310/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.5949 - val_accuracy: 0.9249\n",
      "Epoch 311/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.7333 - val_accuracy: 0.9324\n",
      "Epoch 312/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.7052 - val_accuracy: 0.9309\n",
      "Epoch 313/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.7414 - val_accuracy: 0.9317\n",
      "Epoch 314/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.7614 - val_accuracy: 0.9318\n",
      "Epoch 315/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.6889 - val_accuracy: 0.9239\n",
      "Epoch 316/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.7860 - val_accuracy: 0.9318\n",
      "Epoch 317/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.8155 - val_accuracy: 0.9318\n",
      "Epoch 318/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.8361 - val_accuracy: 0.9317\n",
      "Epoch 319/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.8403 - val_accuracy: 0.9317\n",
      "Epoch 320/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.9397 - val_accuracy: 0.9313\n",
      "Epoch 321/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.5183 - val_accuracy: 0.9263\n",
      "Epoch 322/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.6921 - val_accuracy: 0.9306\n",
      "Epoch 323/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.7667 - val_accuracy: 0.9311\n",
      "Epoch 324/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.7622 - val_accuracy: 0.9321\n",
      "Epoch 325/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.7658 - val_accuracy: 0.9317\n",
      "Epoch 326/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.7466 - val_accuracy: 0.9285\n",
      "Epoch 327/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.7460 - val_accuracy: 0.9302\n",
      "Epoch 328/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.6875 - val_accuracy: 0.9316\n",
      "Epoch 329/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 0.8710 - val_accuracy: 0.9333\n",
      "Epoch 330/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.9099 - val_accuracy: 0.9329\n",
      "Epoch 331/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.8796 - val_accuracy: 0.9321\n",
      "Epoch 332/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.8864 - val_accuracy: 0.9320\n",
      "Epoch 333/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.9277 - val_accuracy: 0.9326\n",
      "Epoch 334/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.9299 - val_accuracy: 0.9322\n",
      "Epoch 335/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.9417 - val_accuracy: 0.9322\n",
      "Epoch 336/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.9567 - val_accuracy: 0.9322\n",
      "Epoch 337/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.9798 - val_accuracy: 0.9324\n",
      "Epoch 338/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.9801 - val_accuracy: 0.9322\n",
      "Epoch 339/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 1.0226 - val_accuracy: 0.9325\n",
      "Epoch 340/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.9963 - val_accuracy: 0.9324\n",
      "Epoch 341/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 1.0357 - val_accuracy: 0.9324\n",
      "Epoch 342/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 1.0573 - val_accuracy: 0.9325\n",
      "Epoch 343/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.9222 - val_accuracy: 0.9246\n",
      "Epoch 344/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0551 - accuracy: 0.9839 - val_loss: 0.6948 - val_accuracy: 0.9327\n",
      "Epoch 345/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0277 - accuracy: 0.9925 - val_loss: 0.6367 - val_accuracy: 0.9333\n",
      "Epoch 346/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.6335 - val_accuracy: 0.9318\n",
      "Epoch 347/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.6269 - val_accuracy: 0.9317\n",
      "Epoch 348/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.7269 - val_accuracy: 0.9327\n",
      "Epoch 349/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.7741 - val_accuracy: 0.9330\n",
      "Epoch 350/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.7832 - val_accuracy: 0.9327\n",
      "Epoch 351/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.8115 - val_accuracy: 0.9326\n",
      "Epoch 352/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0203 - accuracy: 0.9980 - val_loss: 0.3914 - val_accuracy: 0.9330\n",
      "Epoch 353/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.5328 - val_accuracy: 0.9277\n",
      "Epoch 354/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0269 - accuracy: 0.9925 - val_loss: 0.4503 - val_accuracy: 0.9307\n",
      "Epoch 355/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.6112 - val_accuracy: 0.9311\n",
      "Epoch 356/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.6764 - val_accuracy: 0.9306\n",
      "Epoch 357/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.6664 - val_accuracy: 0.9315\n",
      "Epoch 358/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.6960 - val_accuracy: 0.9313\n",
      "Epoch 359/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.7415 - val_accuracy: 0.9312\n",
      "Epoch 360/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.7560 - val_accuracy: 0.9322\n",
      "Epoch 361/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.7160 - val_accuracy: 0.9312\n",
      "Epoch 362/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.6765 - val_accuracy: 0.9326\n",
      "Epoch 363/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.7556 - val_accuracy: 0.9327\n",
      "Epoch 364/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 0.4349 - val_accuracy: 0.9325\n",
      "Epoch 365/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 0.5820 - val_accuracy: 0.9333\n",
      "Epoch 366/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.5615 - val_accuracy: 0.9326\n",
      "Epoch 367/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.5331 - val_accuracy: 0.9322\n",
      "Epoch 368/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.5774 - val_accuracy: 0.9327\n",
      "Epoch 369/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.5552 - val_accuracy: 0.9333\n",
      "Epoch 370/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.5415 - val_accuracy: 0.9325\n",
      "Epoch 371/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.6168 - val_accuracy: 0.9334\n",
      "Epoch 372/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0126 - accuracy: 0.9975 - val_loss: 0.4624 - val_accuracy: 0.9338\n",
      "Epoch 373/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.5817 - val_accuracy: 0.9331\n",
      "Epoch 374/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 0.5575 - val_accuracy: 0.9329\n",
      "Epoch 375/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5525 - val_accuracy: 0.9334\n",
      "Epoch 376/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.5387 - val_accuracy: 0.9331\n",
      "Epoch 377/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.5495 - val_accuracy: 0.9334\n",
      "Epoch 378/500\n",
      "388/388 [==============================] - 33s 84ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.5141 - val_accuracy: 0.9318\n",
      "Epoch 379/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.5970 - val_accuracy: 0.9330\n",
      "Epoch 380/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.5910 - val_accuracy: 0.9326\n",
      "Epoch 381/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.6512 - val_accuracy: 0.9318\n",
      "Epoch 382/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.7419 - val_accuracy: 0.9306\n",
      "Epoch 383/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.6413 - val_accuracy: 0.9308\n",
      "Epoch 384/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.5946 - val_accuracy: 0.9297\n",
      "Epoch 385/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.6746 - val_accuracy: 0.9311\n",
      "Epoch 386/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.7188 - val_accuracy: 0.9318\n",
      "Epoch 387/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.7509 - val_accuracy: 0.9311\n",
      "Epoch 388/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.7716 - val_accuracy: 0.9315\n",
      "Epoch 389/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.7740 - val_accuracy: 0.9303\n",
      "Epoch 390/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 9.4436e-04 - accuracy: 0.9998 - val_loss: 0.8232 - val_accuracy: 0.9306\n",
      "Epoch 391/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.8431 - val_accuracy: 0.9311\n",
      "Epoch 392/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.8755 - val_accuracy: 0.9313\n",
      "Epoch 393/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.8945 - val_accuracy: 0.9313\n",
      "Epoch 394/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.9016 - val_accuracy: 0.9315\n",
      "Epoch 395/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.9264 - val_accuracy: 0.9315\n",
      "Epoch 396/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.9193 - val_accuracy: 0.9309\n",
      "Epoch 397/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.9466 - val_accuracy: 0.9315\n",
      "Epoch 398/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.9741 - val_accuracy: 0.9318\n",
      "Epoch 399/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.9902 - val_accuracy: 0.9317\n",
      "Epoch 400/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0601 - accuracy: 0.9828 - val_loss: 0.4984 - val_accuracy: 0.9334\n",
      "Epoch 401/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.5070 - val_accuracy: 0.9311\n",
      "Epoch 402/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.4609 - val_accuracy: 0.9294\n",
      "Epoch 403/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.5838 - val_accuracy: 0.9317\n",
      "Epoch 404/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.6179 - val_accuracy: 0.9311\n",
      "Epoch 405/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.6847 - val_accuracy: 0.9320\n",
      "Epoch 406/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.6249 - val_accuracy: 0.9290\n",
      "Epoch 407/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.7575 - val_accuracy: 0.9313\n",
      "Epoch 408/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.7455 - val_accuracy: 0.9304\n",
      "Epoch 409/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.4953 - val_accuracy: 0.9293\n",
      "Epoch 410/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 0.6169 - val_accuracy: 0.9282\n",
      "Epoch 411/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.6005 - val_accuracy: 0.9300\n",
      "Epoch 412/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.6942 - val_accuracy: 0.9306\n",
      "Epoch 413/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6730 - val_accuracy: 0.9231\n",
      "Epoch 414/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.7903 - val_accuracy: 0.9307\n",
      "Epoch 415/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.8209 - val_accuracy: 0.9303\n",
      "Epoch 416/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.8372 - val_accuracy: 0.9295\n",
      "Epoch 417/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.8722 - val_accuracy: 0.9304\n",
      "Epoch 418/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.7310 - val_accuracy: 0.9298\n",
      "Epoch 419/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.7512 - val_accuracy: 0.9306\n",
      "Epoch 420/500\n",
      "388/388 [==============================] - 33s 85ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.7971 - val_accuracy: 0.9273\n",
      "Epoch 421/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.6403 - val_accuracy: 0.9300\n",
      "Epoch 422/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.6968 - val_accuracy: 0.9300\n",
      "Epoch 423/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.7395 - val_accuracy: 0.9276\n",
      "Epoch 424/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.8537 - val_accuracy: 0.9286\n",
      "Epoch 425/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.8428 - val_accuracy: 0.9290\n",
      "Epoch 426/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.6353 - val_accuracy: 0.9257\n",
      "Epoch 427/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.8244 - val_accuracy: 0.9334\n",
      "Epoch 428/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.5835 - val_accuracy: 0.9297\n",
      "Epoch 429/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.7129 - val_accuracy: 0.9335\n",
      "Epoch 430/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.6920 - val_accuracy: 0.9315\n",
      "Epoch 431/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 0.5477 - val_accuracy: 0.9321\n",
      "Epoch 432/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.5633 - val_accuracy: 0.9316\n",
      "Epoch 433/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6402 - val_accuracy: 0.9306\n",
      "Epoch 434/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.6900 - val_accuracy: 0.9317\n",
      "Epoch 435/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.7297 - val_accuracy: 0.9318\n",
      "Epoch 436/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.7544 - val_accuracy: 0.9320\n",
      "Epoch 437/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.7733 - val_accuracy: 0.9317\n",
      "Epoch 438/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.7915 - val_accuracy: 0.9322\n",
      "Epoch 439/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.8274 - val_accuracy: 0.9320\n",
      "Epoch 440/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.8532 - val_accuracy: 0.9320\n",
      "Epoch 441/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0341 - accuracy: 0.9912 - val_loss: 0.3900 - val_accuracy: 0.9286\n",
      "Epoch 442/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.5831 - val_accuracy: 0.9312\n",
      "Epoch 443/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.5872 - val_accuracy: 0.9299\n",
      "Epoch 444/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.6333 - val_accuracy: 0.9217\n",
      "Epoch 445/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.5358 - val_accuracy: 0.9143\n",
      "Epoch 446/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.6638 - val_accuracy: 0.9303\n",
      "Epoch 447/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.7378 - val_accuracy: 0.9304\n",
      "Epoch 448/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.7629 - val_accuracy: 0.9311\n",
      "Epoch 449/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.7738 - val_accuracy: 0.9298\n",
      "Epoch 450/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.8002 - val_accuracy: 0.9297\n",
      "Epoch 451/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.8098 - val_accuracy: 0.9293\n",
      "Epoch 452/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.8260 - val_accuracy: 0.9300\n",
      "Epoch 453/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.8441 - val_accuracy: 0.9299\n",
      "Epoch 454/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.8083 - val_accuracy: 0.9334\n",
      "Epoch 455/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.6014 - val_accuracy: 0.9303\n",
      "Epoch 456/500\n",
      "388/388 [==============================] - 31s 79ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.6714 - val_accuracy: 0.9302\n",
      "Epoch 457/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.7085 - val_accuracy: 0.9289\n",
      "Epoch 458/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.6797 - val_accuracy: 0.9312\n",
      "Epoch 459/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.7158 - val_accuracy: 0.9315\n",
      "Epoch 460/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.7396 - val_accuracy: 0.9313\n",
      "Epoch 461/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.8082 - val_accuracy: 0.9329\n",
      "Epoch 462/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.7371 - val_accuracy: 0.9299\n",
      "Epoch 463/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.8030 - val_accuracy: 0.9326\n",
      "Epoch 464/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.8116 - val_accuracy: 0.9329\n",
      "Epoch 465/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.8586 - val_accuracy: 0.9324\n",
      "Epoch 466/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.7570 - val_accuracy: 0.9309\n",
      "Epoch 467/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.6996 - val_accuracy: 0.9293\n",
      "Epoch 468/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.7984 - val_accuracy: 0.9307\n",
      "Epoch 469/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.8317 - val_accuracy: 0.9306\n",
      "Epoch 470/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.8394 - val_accuracy: 0.9291\n",
      "Epoch 471/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.8766 - val_accuracy: 0.9298\n",
      "Epoch 472/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.8650 - val_accuracy: 0.9284\n",
      "Epoch 473/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.8865 - val_accuracy: 0.9302\n",
      "Epoch 474/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.7908 - val_accuracy: 0.9303\n",
      "Epoch 475/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0200 - accuracy: 0.9951 - val_loss: 0.4456 - val_accuracy: 0.9255\n",
      "Epoch 476/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.5455 - val_accuracy: 0.9298\n",
      "Epoch 477/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0128 - accuracy: 0.9978 - val_loss: 0.5026 - val_accuracy: 0.9304\n",
      "Epoch 478/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.5701 - val_accuracy: 0.9297\n",
      "Epoch 479/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.5681 - val_accuracy: 0.9311\n",
      "Epoch 480/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.5802 - val_accuracy: 0.9312\n",
      "Epoch 481/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.5521 - val_accuracy: 0.9315\n",
      "Epoch 482/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.5747 - val_accuracy: 0.9309\n",
      "Epoch 483/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.5661 - val_accuracy: 0.9307\n",
      "Epoch 484/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.6235 - val_accuracy: 0.9313\n",
      "Epoch 485/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.6298 - val_accuracy: 0.9294\n",
      "Epoch 486/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.6656 - val_accuracy: 0.9295\n",
      "Epoch 487/500\n",
      "388/388 [==============================] - 31s 81ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.5799 - val_accuracy: 0.9304\n",
      "Epoch 488/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.7074 - val_accuracy: 0.9312\n",
      "Epoch 489/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.6548 - val_accuracy: 0.9291\n",
      "Epoch 490/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.6696 - val_accuracy: 0.9286\n",
      "Epoch 491/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.7114 - val_accuracy: 0.9284\n",
      "Epoch 492/500\n",
      "388/388 [==============================] - 31s 80ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.7460 - val_accuracy: 0.9284\n",
      "Epoch 493/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.7718 - val_accuracy: 0.9281\n",
      "Epoch 494/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.6059 - val_accuracy: 0.9306\n",
      "Epoch 495/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.5448 - val_accuracy: 0.9302\n",
      "Epoch 496/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.4878 - val_accuracy: 0.9237\n",
      "Epoch 497/500\n",
      "388/388 [==============================] - 32s 83ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.6315 - val_accuracy: 0.9307\n",
      "Epoch 498/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.6627 - val_accuracy: 0.9307\n",
      "Epoch 499/500\n",
      "388/388 [==============================] - 32s 82ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.6863 - val_accuracy: 0.9306\n",
      "Epoch 500/500\n",
      "388/388 [==============================] - 32s 81ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.7123 - val_accuracy: 0.9299\n"
     ]
    }
   ],
   "source": [
    "def batch_generator(image, label, batchsize):\n",
    "    N = len(image)\n",
    "    indices = np.arange(N)  # 0부터 N-1까지의 인덱스 배열 생성\n",
    "    np.random.shuffle(indices)  # 인덱스 배열을 무작위로 섞음\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i + batchsize <= N:\n",
    "            batch_indices = indices[i:i+batchsize]\n",
    "            i = i + batchsize\n",
    "        else:  # 남은 데이터가 batchsize보다 작을 때, 배열을 wrap around하여 다시 섞음\n",
    "            batch_indices = np.concatenate((indices[i:], indices[:batchsize - (N - i)]))\n",
    "            i = batchsize - (N - i)\n",
    "\n",
    "            np.random.shuffle(indices)  # 다음 에포크를 위해 인덱스 배열을 무작위로 섞음\n",
    "\n",
    "        yield image[batch_indices], label[batch_indices]\n",
    "        \n",
    "checkpoint_filepath = \"../../model/skip/MobileNetV1_checkpoints.h5\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only= True\n",
    ")\n",
    "class_weight_ratio=compute_class_weight(class_weight = \"balanced\" , \n",
    "                     classes=np.unique(y_train), \n",
    "                     y = y_train)\n",
    "class_weight = {0:class_weight_ratio[0],1:class_weight_ratio[1]}\n",
    "\n",
    "input_t=K.Input(shape=(size,size, 3))\n",
    "input_tensor = layers.experimental.preprocessing.Resizing(size, size, interpolation=\"bilinear\", input_shape=x_train.shape[1:])(input_t)\n",
    "ResNet=MobileNet(include_top=True,weights='imagenet',input_tensor=input_tensor)\n",
    "model = K.models.Sequential()\n",
    "model.add(ResNet)\n",
    "model.add(tf.keras.layers.Dropout(.2, input_shape=(64,)))\n",
    "model.add(K.layers.Dense(64, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "model.add(K.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=K.optimizers.Adam(lr=2e-4),\n",
    "                loss=tf.keras.losses.binary_crossentropy,\n",
    "                metrics=[\"accuracy\"])\n",
    "histo=model.fit(\n",
    "    batch_generator(x_train,y_train,64),\n",
    "    validation_data=(x_val,y_val),\n",
    "    epochs=500,\n",
    "    steps_per_epoch=len(x_train)//64,\n",
    "    callbacks=model_checkpoint_callback,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weight\n",
    ")\n",
    "model.save('../../model/skip/MobileNetV1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
