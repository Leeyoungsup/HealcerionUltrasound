{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 13:39:47.448640: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-11 13:39:48.134903: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from keras.applications import DenseNet121\n",
    "from tensorflow.keras import datasets, layers, models, losses, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pre\n",
    "from glob import glob\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_img_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Train_dataframe.csv')['file_path'].to_list()\n",
    "Train_label_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Train_dataframe.csv')['standard'].to_list()\n",
    "Test_img_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Test_dataframe.csv')['file_path'].to_list()\n",
    "Test_label_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Test_dataframe.csv')['standard'].to_list()\n",
    "Val_img_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Validation_dataframe.csv')['file_path'].to_list()\n",
    "Val_label_list=pd.read_csv('../../data/standardFrame_data/scale_skip/Validation_dataframe.csv')['standard'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_img_path='../../data/standardFrame_data/scale_skip/train'\n",
    "Test_img_path='../../data/standardFrame_data/scale_skip/test'\n",
    "Val_img_path='../../data/standardFrame_data/scale_skip/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=224\n",
    "x_train = np.zeros((len(Train_img_list),size,size,3))\n",
    "for i in range(len(Train_img_list)):\n",
    "    x_train[i] =np.array(Image.open(Train_img_path+Train_img_list[i]).resize((size,size)))\n",
    "x_train=x_train/255\n",
    "y_train=np.array(Train_label_list)\n",
    "\n",
    "x_test = np.zeros((len(Test_img_list),size,size,3))\n",
    "for i in range(len(Test_img_list)):\n",
    "    x_test[i] =np.array(Image.open(Test_img_path+Test_img_list[i]).resize((size,size)))\n",
    "x_test=x_test/255\n",
    "y_test=np.array(Test_label_list)\n",
    "\n",
    "x_val = np.zeros((len(Val_img_list),size,size,3))\n",
    "for i in range(len(Val_img_list)):\n",
    "    x_val[i] =np.array(Image.open(Val_img_path+Val_img_list[i]).resize((size,size)))\n",
    "x_val=x_val/255\n",
    "y_val=np.array(Val_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 13:43:29.686490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38163 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:a1:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 13:43:33.435791: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-08-11 13:43:52.801541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8902\n",
      "2023-08-11 13:43:55.359804: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-11 13:43:55.363801: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x55ac16b58e30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-11 13:43:55.363844: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2023-08-11 13:43:55.397394: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-11 13:43:55.542947: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 128s 188ms/step - loss: 0.5335 - accuracy: 0.7339 - val_loss: 0.4576 - val_accuracy: 0.6341\n",
      "Epoch 2/500\n",
      "388/388 [==============================] - 61s 156ms/step - loss: 0.3829 - accuracy: 0.7627 - val_loss: 1.3569 - val_accuracy: 0.3249\n",
      "Epoch 3/500\n",
      "388/388 [==============================] - 63s 162ms/step - loss: 0.3322 - accuracy: 0.8011 - val_loss: 0.3026 - val_accuracy: 0.8525\n",
      "Epoch 4/500\n",
      "388/388 [==============================] - 62s 159ms/step - loss: 0.2950 - accuracy: 0.8340 - val_loss: 0.2782 - val_accuracy: 0.8611\n",
      "Epoch 5/500\n",
      "388/388 [==============================] - 62s 159ms/step - loss: 0.2752 - accuracy: 0.8556 - val_loss: 0.2123 - val_accuracy: 0.8909\n",
      "Epoch 6/500\n",
      "388/388 [==============================] - 60s 154ms/step - loss: 0.2445 - accuracy: 0.8736 - val_loss: 0.2450 - val_accuracy: 0.9088\n",
      "Epoch 7/500\n",
      "388/388 [==============================] - 60s 156ms/step - loss: 0.2293 - accuracy: 0.8861 - val_loss: 0.1832 - val_accuracy: 0.9268\n",
      "Epoch 8/500\n",
      "388/388 [==============================] - 58s 150ms/step - loss: 0.2062 - accuracy: 0.9002 - val_loss: 0.5063 - val_accuracy: 0.9325\n",
      "Epoch 9/500\n",
      "388/388 [==============================] - 58s 148ms/step - loss: 0.1966 - accuracy: 0.9030 - val_loss: 0.2160 - val_accuracy: 0.9099\n",
      "Epoch 10/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.1836 - accuracy: 0.9137 - val_loss: 0.2606 - val_accuracy: 0.9334\n",
      "Epoch 11/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.1925 - accuracy: 0.9064 - val_loss: 0.2304 - val_accuracy: 0.8936\n",
      "Epoch 12/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.1681 - accuracy: 0.9213 - val_loss: 0.4901 - val_accuracy: 0.7988\n",
      "Epoch 13/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.1528 - accuracy: 0.9265 - val_loss: 0.3040 - val_accuracy: 0.9348\n",
      "Epoch 14/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.1475 - accuracy: 0.9273 - val_loss: 0.2175 - val_accuracy: 0.9183\n",
      "Epoch 15/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.1409 - accuracy: 0.9344 - val_loss: 0.3312 - val_accuracy: 0.9141\n",
      "Epoch 16/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.1325 - accuracy: 0.9366 - val_loss: 0.3112 - val_accuracy: 0.9253\n",
      "Epoch 17/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.1226 - accuracy: 0.9431 - val_loss: 0.4928 - val_accuracy: 0.8226\n",
      "Epoch 18/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.1193 - accuracy: 0.9425 - val_loss: 0.3046 - val_accuracy: 0.9222\n",
      "Epoch 19/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.1103 - accuracy: 0.9478 - val_loss: 0.3946 - val_accuracy: 0.9286\n",
      "Epoch 20/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.1062 - accuracy: 0.9486 - val_loss: 0.4669 - val_accuracy: 0.9130\n",
      "Epoch 21/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.1066 - accuracy: 0.9491 - val_loss: 0.5720 - val_accuracy: 0.9318\n",
      "Epoch 22/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.1034 - accuracy: 0.9523 - val_loss: 0.4794 - val_accuracy: 0.9335\n",
      "Epoch 23/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0939 - accuracy: 0.9554 - val_loss: 0.4792 - val_accuracy: 0.9316\n",
      "Epoch 24/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0864 - accuracy: 0.9606 - val_loss: 0.5157 - val_accuracy: 0.9275\n",
      "Epoch 25/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0846 - accuracy: 0.9590 - val_loss: 0.4228 - val_accuracy: 0.9275\n",
      "Epoch 26/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0896 - accuracy: 0.9579 - val_loss: 0.6612 - val_accuracy: 0.9340\n",
      "Epoch 27/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0873 - accuracy: 0.9614 - val_loss: 0.3486 - val_accuracy: 0.9152\n",
      "Epoch 28/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0694 - accuracy: 0.9696 - val_loss: 0.3640 - val_accuracy: 0.9094\n",
      "Epoch 29/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.1029 - accuracy: 0.9537 - val_loss: 0.4106 - val_accuracy: 0.9128\n",
      "Epoch 30/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0796 - accuracy: 0.9639 - val_loss: 0.5584 - val_accuracy: 0.9321\n",
      "Epoch 31/500\n",
      "388/388 [==============================] - 56s 146ms/step - loss: 0.0674 - accuracy: 0.9696 - val_loss: 0.3685 - val_accuracy: 0.9266\n",
      "Epoch 32/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0609 - accuracy: 0.9740 - val_loss: 0.4819 - val_accuracy: 0.9276\n",
      "Epoch 33/500\n",
      "388/388 [==============================] - 55s 143ms/step - loss: 0.0665 - accuracy: 0.9724 - val_loss: 0.3443 - val_accuracy: 0.9030\n",
      "Epoch 34/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0578 - accuracy: 0.9743 - val_loss: 0.4404 - val_accuracy: 0.9311\n",
      "Epoch 35/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0623 - accuracy: 0.9733 - val_loss: 0.3394 - val_accuracy: 0.9111\n",
      "Epoch 36/500\n",
      "388/388 [==============================] - 56s 143ms/step - loss: 0.0548 - accuracy: 0.9762 - val_loss: 0.3215 - val_accuracy: 0.9127\n",
      "Epoch 37/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0572 - accuracy: 0.9767 - val_loss: 0.3902 - val_accuracy: 0.9228\n",
      "Epoch 38/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0596 - accuracy: 0.9754 - val_loss: 0.3757 - val_accuracy: 0.9334\n",
      "Epoch 39/500\n",
      "388/388 [==============================] - 56s 143ms/step - loss: 0.0524 - accuracy: 0.9776 - val_loss: 0.5589 - val_accuracy: 0.7981\n",
      "Epoch 40/500\n",
      "388/388 [==============================] - 56s 143ms/step - loss: 0.0517 - accuracy: 0.9793 - val_loss: 0.5507 - val_accuracy: 0.9316\n",
      "Epoch 41/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0467 - accuracy: 0.9801 - val_loss: 0.5105 - val_accuracy: 0.9170\n",
      "Epoch 42/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0456 - accuracy: 0.9817 - val_loss: 0.3654 - val_accuracy: 0.9041\n",
      "Epoch 43/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0667 - accuracy: 0.9754 - val_loss: 0.4794 - val_accuracy: 0.9322\n",
      "Epoch 44/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0448 - accuracy: 0.9814 - val_loss: 0.5404 - val_accuracy: 0.9324\n",
      "Epoch 45/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0394 - accuracy: 0.9839 - val_loss: 0.4819 - val_accuracy: 0.9272\n",
      "Epoch 46/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0367 - accuracy: 0.9854 - val_loss: 0.5199 - val_accuracy: 0.8945\n",
      "Epoch 47/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0396 - accuracy: 0.9832 - val_loss: 0.4877 - val_accuracy: 0.9245\n",
      "Epoch 48/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0405 - accuracy: 0.9832 - val_loss: 0.4502 - val_accuracy: 0.9249\n",
      "Epoch 49/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0340 - accuracy: 0.9862 - val_loss: 0.5888 - val_accuracy: 0.9003\n",
      "Epoch 50/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0449 - accuracy: 0.9794 - val_loss: 0.5157 - val_accuracy: 0.8761\n",
      "Epoch 51/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0374 - accuracy: 0.9853 - val_loss: 0.4168 - val_accuracy: 0.9210\n",
      "Epoch 52/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0451 - accuracy: 0.9802 - val_loss: 0.4789 - val_accuracy: 0.8951\n",
      "Epoch 53/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0364 - accuracy: 0.9851 - val_loss: 0.4292 - val_accuracy: 0.9108\n",
      "Epoch 54/500\n",
      "388/388 [==============================] - 55s 143ms/step - loss: 0.0272 - accuracy: 0.9890 - val_loss: 0.5391 - val_accuracy: 0.9270\n",
      "Epoch 55/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0355 - accuracy: 0.9872 - val_loss: 0.5611 - val_accuracy: 0.9308\n",
      "Epoch 56/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0332 - accuracy: 0.9878 - val_loss: 0.4402 - val_accuracy: 0.9281\n",
      "Epoch 57/500\n",
      "388/388 [==============================] - 58s 150ms/step - loss: 0.0352 - accuracy: 0.9866 - val_loss: 0.3030 - val_accuracy: 0.9133\n",
      "Epoch 58/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0283 - accuracy: 0.9894 - val_loss: 0.6285 - val_accuracy: 0.9324\n",
      "Epoch 59/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.4945 - val_accuracy: 0.9288\n",
      "Epoch 60/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0303 - accuracy: 0.9875 - val_loss: 0.6312 - val_accuracy: 0.9307\n",
      "Epoch 61/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0306 - accuracy: 0.9872 - val_loss: 0.6926 - val_accuracy: 0.9306\n",
      "Epoch 62/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0263 - accuracy: 0.9893 - val_loss: 0.5266 - val_accuracy: 0.9067\n",
      "Epoch 63/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0296 - accuracy: 0.9876 - val_loss: 0.5075 - val_accuracy: 0.9230\n",
      "Epoch 64/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0335 - accuracy: 0.9850 - val_loss: 0.7835 - val_accuracy: 0.9261\n",
      "Epoch 65/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0276 - accuracy: 0.9895 - val_loss: 0.6954 - val_accuracy: 0.9321\n",
      "Epoch 66/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0268 - accuracy: 0.9903 - val_loss: 0.4911 - val_accuracy: 0.9206\n",
      "Epoch 67/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0225 - accuracy: 0.9919 - val_loss: 0.6771 - val_accuracy: 0.9327\n",
      "Epoch 68/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.5191 - val_accuracy: 0.9047\n",
      "Epoch 69/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0287 - accuracy: 0.9880 - val_loss: 0.7312 - val_accuracy: 0.9312\n",
      "Epoch 70/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0287 - accuracy: 0.9899 - val_loss: 0.3520 - val_accuracy: 0.9107\n",
      "Epoch 71/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 0.5530 - val_accuracy: 0.9200\n",
      "Epoch 72/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0338 - accuracy: 0.9865 - val_loss: 0.6028 - val_accuracy: 0.9313\n",
      "Epoch 73/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0250 - accuracy: 0.9905 - val_loss: 0.6233 - val_accuracy: 0.9329\n",
      "Epoch 74/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.5944 - val_accuracy: 0.9154\n",
      "Epoch 75/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0225 - accuracy: 0.9916 - val_loss: 0.5101 - val_accuracy: 0.9072\n",
      "Epoch 76/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 0.5390 - val_accuracy: 0.9096\n",
      "Epoch 77/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0213 - accuracy: 0.9926 - val_loss: 0.7083 - val_accuracy: 0.9316\n",
      "Epoch 78/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0311 - accuracy: 0.9882 - val_loss: 0.7067 - val_accuracy: 0.9329\n",
      "Epoch 79/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.5777 - val_accuracy: 0.9316\n",
      "Epoch 80/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.4444 - val_accuracy: 0.9213\n",
      "Epoch 81/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0276 - accuracy: 0.9891 - val_loss: 0.5994 - val_accuracy: 0.9277\n",
      "Epoch 82/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0254 - accuracy: 0.9900 - val_loss: 0.4594 - val_accuracy: 0.8802\n",
      "Epoch 83/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0137 - accuracy: 0.9950 - val_loss: 0.7663 - val_accuracy: 0.9218\n",
      "Epoch 84/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0252 - accuracy: 0.9893 - val_loss: 0.7010 - val_accuracy: 0.9174\n",
      "Epoch 85/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0186 - accuracy: 0.9931 - val_loss: 0.3838 - val_accuracy: 0.9057\n",
      "Epoch 86/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.5477 - val_accuracy: 0.8703\n",
      "Epoch 87/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0278 - accuracy: 0.9893 - val_loss: 0.7203 - val_accuracy: 0.9295\n",
      "Epoch 88/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.6549 - val_accuracy: 0.9240\n",
      "Epoch 89/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0220 - accuracy: 0.9913 - val_loss: 0.5895 - val_accuracy: 0.9161\n",
      "Epoch 90/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.7765 - val_accuracy: 0.9320\n",
      "Epoch 91/500\n",
      "388/388 [==============================] - 58s 150ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.6620 - val_accuracy: 0.9230\n",
      "Epoch 92/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.8783 - val_accuracy: 0.9340\n",
      "Epoch 93/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0263 - accuracy: 0.9901 - val_loss: 0.9234 - val_accuracy: 0.9313\n",
      "Epoch 94/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.8140 - val_accuracy: 0.9293\n",
      "Epoch 95/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0199 - accuracy: 0.9935 - val_loss: 0.6037 - val_accuracy: 0.9340\n",
      "Epoch 96/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0164 - accuracy: 0.9938 - val_loss: 0.6643 - val_accuracy: 0.9261\n",
      "Epoch 97/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 0.8461 - val_accuracy: 0.9318\n",
      "Epoch 98/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 1.0467 - val_accuracy: 0.9335\n",
      "Epoch 99/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.5382 - val_accuracy: 0.9195\n",
      "Epoch 100/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0230 - accuracy: 0.9918 - val_loss: 0.8716 - val_accuracy: 0.9325\n",
      "Epoch 101/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.5833 - val_accuracy: 0.9276\n",
      "Epoch 102/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.8346 - val_accuracy: 0.9324\n",
      "Epoch 103/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.3684 - val_accuracy: 0.9081\n",
      "Epoch 104/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0226 - accuracy: 0.9913 - val_loss: 0.6928 - val_accuracy: 0.9311\n",
      "Epoch 105/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 0.4977 - val_accuracy: 0.8960\n",
      "Epoch 106/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0160 - accuracy: 0.9943 - val_loss: 0.7234 - val_accuracy: 0.9288\n",
      "Epoch 107/500\n",
      "388/388 [==============================] - 56s 146ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.6947 - val_accuracy: 0.9078\n",
      "Epoch 108/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.4992 - val_accuracy: 0.9276\n",
      "Epoch 109/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.7451 - val_accuracy: 0.9327\n",
      "Epoch 110/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.5559 - val_accuracy: 0.9178\n",
      "Epoch 111/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.5985 - val_accuracy: 0.9219\n",
      "Epoch 112/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.6593 - val_accuracy: 0.9315\n",
      "Epoch 113/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.4962 - val_accuracy: 0.8954\n",
      "Epoch 114/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0139 - accuracy: 0.9948 - val_loss: 1.0291 - val_accuracy: 0.9325\n",
      "Epoch 115/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.4796 - val_accuracy: 0.9031\n",
      "Epoch 116/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.8820 - val_accuracy: 0.9308\n",
      "Epoch 117/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0140 - accuracy: 0.9948 - val_loss: 0.6134 - val_accuracy: 0.8986\n",
      "Epoch 118/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 1.0964 - val_accuracy: 0.9321\n",
      "Epoch 119/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0268 - accuracy: 0.9910 - val_loss: 0.9399 - val_accuracy: 0.9329\n",
      "Epoch 120/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 0.7391 - val_accuracy: 0.9333\n",
      "Epoch 121/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.5881 - val_accuracy: 0.9280\n",
      "Epoch 122/500\n",
      "388/388 [==============================] - 56s 143ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.7505 - val_accuracy: 0.9317\n",
      "Epoch 123/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.5542 - val_accuracy: 0.9298\n",
      "Epoch 124/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.5540 - val_accuracy: 0.9062\n",
      "Epoch 125/500\n",
      "388/388 [==============================] - 56s 143ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.5965 - val_accuracy: 0.9250\n",
      "Epoch 126/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.6080 - val_accuracy: 0.9090\n",
      "Epoch 127/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.6411 - val_accuracy: 0.9321\n",
      "Epoch 128/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.5727 - val_accuracy: 0.9281\n",
      "Epoch 129/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.5067 - val_accuracy: 0.8990\n",
      "Epoch 130/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.6783 - val_accuracy: 0.9321\n",
      "Epoch 131/500\n",
      "388/388 [==============================] - 56s 143ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.6677 - val_accuracy: 0.9273\n",
      "Epoch 132/500\n",
      "388/388 [==============================] - 56s 146ms/step - loss: 0.0168 - accuracy: 0.9935 - val_loss: 0.6682 - val_accuracy: 0.9303\n",
      "Epoch 133/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0189 - accuracy: 0.9929 - val_loss: 0.4237 - val_accuracy: 0.8878\n",
      "Epoch 134/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.6233 - val_accuracy: 0.9268\n",
      "Epoch 135/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.8128 - val_accuracy: 0.9311\n",
      "Epoch 136/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.9322 - val_accuracy: 0.9334\n",
      "Epoch 137/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0134 - accuracy: 0.9946 - val_loss: 0.5514 - val_accuracy: 0.9161\n",
      "Epoch 138/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.6572 - val_accuracy: 0.9308\n",
      "Epoch 139/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.6519 - val_accuracy: 0.9280\n",
      "Epoch 140/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.5007 - val_accuracy: 0.9156\n",
      "Epoch 141/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.5439 - val_accuracy: 0.9227\n",
      "Epoch 142/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.6110 - val_accuracy: 0.9214\n",
      "Epoch 143/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.5439 - val_accuracy: 0.9263\n",
      "Epoch 144/500\n",
      "388/388 [==============================] - 55s 143ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.6363 - val_accuracy: 0.9174\n",
      "Epoch 145/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.5981 - val_accuracy: 0.9188\n",
      "Epoch 146/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.6913 - val_accuracy: 0.9300\n",
      "Epoch 147/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.7610 - val_accuracy: 0.9297\n",
      "Epoch 148/500\n",
      "388/388 [==============================] - 56s 143ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.8629 - val_accuracy: 0.9313\n",
      "Epoch 149/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.8760 - val_accuracy: 0.9279\n",
      "Epoch 150/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.7907 - val_accuracy: 0.9259\n",
      "Epoch 151/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 0.6484 - val_accuracy: 0.8473\n",
      "Epoch 152/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.4960 - val_accuracy: 0.9170\n",
      "Epoch 153/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.9837 - val_accuracy: 0.9334\n",
      "Epoch 154/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.6886 - val_accuracy: 0.9210\n",
      "Epoch 155/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.6143 - val_accuracy: 0.9142\n",
      "Epoch 156/500\n",
      "388/388 [==============================] - 56s 146ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.5134 - val_accuracy: 0.9258\n",
      "Epoch 157/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.6083 - val_accuracy: 0.9218\n",
      "Epoch 158/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.5476 - val_accuracy: 0.9201\n",
      "Epoch 159/500\n",
      "388/388 [==============================] - 56s 143ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.7776 - val_accuracy: 0.9294\n",
      "Epoch 160/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.7228 - val_accuracy: 0.9311\n",
      "Epoch 161/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.7091 - val_accuracy: 0.9302\n",
      "Epoch 162/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.7486 - val_accuracy: 0.9309\n",
      "Epoch 163/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.6053 - val_accuracy: 0.9182\n",
      "Epoch 164/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.4575 - val_accuracy: 0.9284\n",
      "Epoch 165/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0172 - accuracy: 0.9936 - val_loss: 0.6120 - val_accuracy: 0.9312\n",
      "Epoch 166/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.5998 - val_accuracy: 0.9311\n",
      "Epoch 167/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.5989 - val_accuracy: 0.9300\n",
      "Epoch 168/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.6193 - val_accuracy: 0.9210\n",
      "Epoch 169/500\n",
      "388/388 [==============================] - 58s 150ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.6594 - val_accuracy: 0.9248\n",
      "Epoch 170/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.6376 - val_accuracy: 0.9286\n",
      "Epoch 171/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.7250 - val_accuracy: 0.9299\n",
      "Epoch 172/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.5045 - val_accuracy: 0.9098\n",
      "Epoch 173/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.7287 - val_accuracy: 0.9324\n",
      "Epoch 174/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.6801 - val_accuracy: 0.9303\n",
      "Epoch 175/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.6016 - val_accuracy: 0.9318\n",
      "Epoch 176/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.6516 - val_accuracy: 0.9326\n",
      "Epoch 177/500\n",
      "388/388 [==============================] - 56s 146ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.6619 - val_accuracy: 0.9318\n",
      "Epoch 178/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.6821 - val_accuracy: 0.9333\n",
      "Epoch 179/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.6623 - val_accuracy: 0.9297\n",
      "Epoch 180/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.6386 - val_accuracy: 0.9297\n",
      "Epoch 181/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.4205 - val_accuracy: 0.9132\n",
      "Epoch 182/500\n",
      "388/388 [==============================] - 56s 146ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.5956 - val_accuracy: 0.9306\n",
      "Epoch 183/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.7564 - val_accuracy: 0.9315\n",
      "Epoch 184/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.5219 - val_accuracy: 0.9272\n",
      "Epoch 185/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.6081 - val_accuracy: 0.9318\n",
      "Epoch 186/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 0.5433 - val_accuracy: 0.9284\n",
      "Epoch 187/500\n",
      "388/388 [==============================] - 58s 148ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.5567 - val_accuracy: 0.9242\n",
      "Epoch 188/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.6862 - val_accuracy: 0.9293\n",
      "Epoch 189/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.6253 - val_accuracy: 0.9284\n",
      "Epoch 190/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.7515 - val_accuracy: 0.9320\n",
      "Epoch 191/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.5209 - val_accuracy: 0.9286\n",
      "Epoch 192/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.6432 - val_accuracy: 0.9273\n",
      "Epoch 193/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.6868 - val_accuracy: 0.9302\n",
      "Epoch 194/500\n",
      "388/388 [==============================] - 56s 146ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.6547 - val_accuracy: 0.9304\n",
      "Epoch 195/500\n",
      "388/388 [==============================] - 60s 155ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.6185 - val_accuracy: 0.9228\n",
      "Epoch 196/500\n",
      "388/388 [==============================] - 56s 146ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.7981 - val_accuracy: 0.9299\n",
      "Epoch 197/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.6407 - val_accuracy: 0.9308\n",
      "Epoch 198/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.7423 - val_accuracy: 0.9290\n",
      "Epoch 199/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.8856 - val_accuracy: 0.9291\n",
      "Epoch 200/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.7378 - val_accuracy: 0.9318\n",
      "Epoch 201/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.7996 - val_accuracy: 0.9324\n",
      "Epoch 202/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 0.7446 - val_accuracy: 0.9335\n",
      "Epoch 203/500\n",
      "388/388 [==============================] - 58s 151ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.5109 - val_accuracy: 0.9326\n",
      "Epoch 204/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.8044 - val_accuracy: 0.9318\n",
      "Epoch 205/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.8419 - val_accuracy: 0.9320\n",
      "Epoch 206/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.6577 - val_accuracy: 0.9266\n",
      "Epoch 207/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.5730 - val_accuracy: 0.9311\n",
      "Epoch 208/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.5478 - val_accuracy: 0.9239\n",
      "Epoch 209/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.5969 - val_accuracy: 0.9303\n",
      "Epoch 210/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.7054 - val_accuracy: 0.9300\n",
      "Epoch 211/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.7254 - val_accuracy: 0.9337\n",
      "Epoch 212/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.5028 - val_accuracy: 0.9226\n",
      "Epoch 213/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.4762 - val_accuracy: 0.9320\n",
      "Epoch 214/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.3945 - val_accuracy: 0.9322\n",
      "Epoch 215/500\n",
      "388/388 [==============================] - 56s 146ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.6960 - val_accuracy: 0.9335\n",
      "Epoch 216/500\n",
      "388/388 [==============================] - 56s 146ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.4721 - val_accuracy: 0.9264\n",
      "Epoch 217/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.6594 - val_accuracy: 0.9329\n",
      "Epoch 218/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.6468 - val_accuracy: 0.9317\n",
      "Epoch 219/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.5667 - val_accuracy: 0.9298\n",
      "Epoch 220/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.4530 - val_accuracy: 0.9304\n",
      "Epoch 221/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.5394 - val_accuracy: 0.9335\n",
      "Epoch 222/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.5586 - val_accuracy: 0.9324\n",
      "Epoch 223/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.5920 - val_accuracy: 0.9303\n",
      "Epoch 224/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.4768 - val_accuracy: 0.9267\n",
      "Epoch 225/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.6929 - val_accuracy: 0.9321\n",
      "Epoch 226/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.6427 - val_accuracy: 0.9267\n",
      "Epoch 227/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.6666 - val_accuracy: 0.9290\n",
      "Epoch 228/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.7992 - val_accuracy: 0.9316\n",
      "Epoch 229/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.6350 - val_accuracy: 0.9308\n",
      "Epoch 230/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.6534 - val_accuracy: 0.9290\n",
      "Epoch 231/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.6446 - val_accuracy: 0.9277\n",
      "Epoch 232/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.6822 - val_accuracy: 0.9212\n",
      "Epoch 233/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 0.4794 - val_accuracy: 0.9249\n",
      "Epoch 234/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.4962 - val_accuracy: 0.9318\n",
      "Epoch 235/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.6047 - val_accuracy: 0.9295\n",
      "Epoch 236/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.6684 - val_accuracy: 0.9266\n",
      "Epoch 237/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.7342 - val_accuracy: 0.9303\n",
      "Epoch 238/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.6966 - val_accuracy: 0.9288\n",
      "Epoch 239/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.4474 - val_accuracy: 0.8879\n",
      "Epoch 240/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.5351 - val_accuracy: 0.9295\n",
      "Epoch 241/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.6134 - val_accuracy: 0.9294\n",
      "Epoch 242/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.5052 - val_accuracy: 0.9155\n",
      "Epoch 243/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.5175 - val_accuracy: 0.9228\n",
      "Epoch 244/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.6510 - val_accuracy: 0.9272\n",
      "Epoch 245/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.7421 - val_accuracy: 0.9289\n",
      "Epoch 246/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.7525 - val_accuracy: 0.9290\n",
      "Epoch 247/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.7377 - val_accuracy: 0.9307\n",
      "Epoch 248/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.8085 - val_accuracy: 0.9315\n",
      "Epoch 249/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.5636 - val_accuracy: 0.9187\n",
      "Epoch 250/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.5027 - val_accuracy: 0.9208\n",
      "Epoch 251/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.8160 - val_accuracy: 0.9325\n",
      "Epoch 252/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.9047 - val_accuracy: 0.9322\n",
      "Epoch 253/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.6832 - val_accuracy: 0.9270\n",
      "Epoch 254/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 0.6815 - val_accuracy: 0.9320\n",
      "Epoch 255/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.7655 - val_accuracy: 0.9317\n",
      "Epoch 256/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.8297 - val_accuracy: 0.9291\n",
      "Epoch 257/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.7237 - val_accuracy: 0.9282\n",
      "Epoch 258/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.8737 - val_accuracy: 0.9329\n",
      "Epoch 259/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.8498 - val_accuracy: 0.9334\n",
      "Epoch 260/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.7281 - val_accuracy: 0.9298\n",
      "Epoch 261/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.7081 - val_accuracy: 0.9288\n",
      "Epoch 262/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.7934 - val_accuracy: 0.9300\n",
      "Epoch 263/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.7807 - val_accuracy: 0.9293\n",
      "Epoch 264/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.7071 - val_accuracy: 0.9280\n",
      "Epoch 265/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.8567 - val_accuracy: 0.9308\n",
      "Epoch 266/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.9243 - val_accuracy: 0.9309\n",
      "Epoch 267/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.6764 - val_accuracy: 0.9289\n",
      "Epoch 268/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.6673 - val_accuracy: 0.9251\n",
      "Epoch 269/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.6446 - val_accuracy: 0.9318\n",
      "Epoch 270/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.7708 - val_accuracy: 0.9315\n",
      "Epoch 271/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.6826 - val_accuracy: 0.9277\n",
      "Epoch 272/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.7122 - val_accuracy: 0.9277\n",
      "Epoch 273/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.5715 - val_accuracy: 0.8530\n",
      "Epoch 274/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0107 - accuracy: 0.9959 - val_loss: 0.6443 - val_accuracy: 0.9251\n",
      "Epoch 275/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.7551 - val_accuracy: 0.9266\n",
      "Epoch 276/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.7123 - val_accuracy: 0.9226\n",
      "Epoch 277/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.5168 - val_accuracy: 0.9289\n",
      "Epoch 278/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.6401 - val_accuracy: 0.9311\n",
      "Epoch 279/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.5374 - val_accuracy: 0.9302\n",
      "Epoch 280/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.6778 - val_accuracy: 0.9272\n",
      "Epoch 281/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.7479 - val_accuracy: 0.9286\n",
      "Epoch 282/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.8049 - val_accuracy: 0.9267\n",
      "Epoch 283/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.7835 - val_accuracy: 0.9279\n",
      "Epoch 284/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.5696 - val_accuracy: 0.9262\n",
      "Epoch 285/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.6464 - val_accuracy: 0.9282\n",
      "Epoch 286/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.6526 - val_accuracy: 0.9230\n",
      "Epoch 287/500\n",
      "388/388 [==============================] - 56s 146ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.5912 - val_accuracy: 0.9276\n",
      "Epoch 288/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.7391 - val_accuracy: 0.9322\n",
      "Epoch 289/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.5362 - val_accuracy: 0.9266\n",
      "Epoch 290/500\n",
      "388/388 [==============================] - 58s 148ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.5614 - val_accuracy: 0.9257\n",
      "Epoch 291/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.6511 - val_accuracy: 0.9282\n",
      "Epoch 292/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.7222 - val_accuracy: 0.9293\n",
      "Epoch 293/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.5498 - val_accuracy: 0.9179\n",
      "Epoch 294/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 0.5725 - val_accuracy: 0.9282\n",
      "Epoch 295/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.6279 - val_accuracy: 0.9313\n",
      "Epoch 296/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.6710 - val_accuracy: 0.9290\n",
      "Epoch 297/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.6865 - val_accuracy: 0.9279\n",
      "Epoch 298/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.7331 - val_accuracy: 0.9322\n",
      "Epoch 299/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.8332 - val_accuracy: 0.9331\n",
      "Epoch 300/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.7752 - val_accuracy: 0.9320\n",
      "Epoch 301/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.5778 - val_accuracy: 0.9293\n",
      "Epoch 302/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.6542 - val_accuracy: 0.9299\n",
      "Epoch 303/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.6884 - val_accuracy: 0.9268\n",
      "Epoch 304/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.4384 - val_accuracy: 0.9218\n",
      "Epoch 305/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.6019 - val_accuracy: 0.9206\n",
      "Epoch 306/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.6177 - val_accuracy: 0.9282\n",
      "Epoch 307/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.6644 - val_accuracy: 0.9338\n",
      "Epoch 308/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.7253 - val_accuracy: 0.9322\n",
      "Epoch 309/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.6613 - val_accuracy: 0.9277\n",
      "Epoch 310/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.6443 - val_accuracy: 0.9279\n",
      "Epoch 311/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.6828 - val_accuracy: 0.9308\n",
      "Epoch 312/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.6883 - val_accuracy: 0.9282\n",
      "Epoch 313/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.6386 - val_accuracy: 0.9339\n",
      "Epoch 314/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.6302 - val_accuracy: 0.9261\n",
      "Epoch 315/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.7372 - val_accuracy: 0.9307\n",
      "Epoch 316/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.7895 - val_accuracy: 0.9308\n",
      "Epoch 317/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.6808 - val_accuracy: 0.9277\n",
      "Epoch 318/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.5562 - val_accuracy: 0.9231\n",
      "Epoch 319/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.7165 - val_accuracy: 0.9300\n",
      "Epoch 320/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.5067 - val_accuracy: 0.9087\n",
      "Epoch 321/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.6604 - val_accuracy: 0.9288\n",
      "Epoch 322/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.6214 - val_accuracy: 0.9327\n",
      "Epoch 323/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.5915 - val_accuracy: 0.9263\n",
      "Epoch 324/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.7582 - val_accuracy: 0.9337\n",
      "Epoch 325/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.8286 - val_accuracy: 0.9327\n",
      "Epoch 326/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.6208 - val_accuracy: 0.9304\n",
      "Epoch 327/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 0.6012 - val_accuracy: 0.9285\n",
      "Epoch 328/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.7234 - val_accuracy: 0.9300\n",
      "Epoch 329/500\n",
      "388/388 [==============================] - 58s 148ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.8174 - val_accuracy: 0.9320\n",
      "Epoch 330/500\n",
      "388/388 [==============================] - 58s 150ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.6932 - val_accuracy: 0.9281\n",
      "Epoch 331/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.6675 - val_accuracy: 0.9282\n",
      "Epoch 332/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.7695 - val_accuracy: 0.9299\n",
      "Epoch 333/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.8186 - val_accuracy: 0.9295\n",
      "Epoch 334/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.8462 - val_accuracy: 0.9298\n",
      "Epoch 335/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.8685 - val_accuracy: 0.9299\n",
      "Epoch 336/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.8752 - val_accuracy: 0.9295\n",
      "Epoch 337/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.9102 - val_accuracy: 0.9295\n",
      "Epoch 338/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.9146 - val_accuracy: 0.9299\n",
      "Epoch 339/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.9306 - val_accuracy: 0.9298\n",
      "Epoch 340/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.9328 - val_accuracy: 0.9299\n",
      "Epoch 341/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.9463 - val_accuracy: 0.9299\n",
      "Epoch 342/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.9667 - val_accuracy: 0.9300\n",
      "Epoch 343/500\n",
      "388/388 [==============================] - 59s 151ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.9710 - val_accuracy: 0.9299\n",
      "Epoch 344/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.9807 - val_accuracy: 0.9299\n",
      "Epoch 345/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 1.0196 - val_accuracy: 0.9300\n",
      "Epoch 346/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 1.0082 - val_accuracy: 0.9299\n",
      "Epoch 347/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 1.0247 - val_accuracy: 0.9300\n",
      "Epoch 348/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 1.0535 - val_accuracy: 0.9300\n",
      "Epoch 349/500\n",
      "388/388 [==============================] - 58s 148ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 1.0475 - val_accuracy: 0.9299\n",
      "Epoch 350/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.8140 - val_accuracy: 0.9286\n",
      "Epoch 351/500\n",
      "388/388 [==============================] - 59s 151ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.9029 - val_accuracy: 0.9306\n",
      "Epoch 352/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.8130 - val_accuracy: 0.9285\n",
      "Epoch 353/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.9345 - val_accuracy: 0.9290\n",
      "Epoch 354/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.9521 - val_accuracy: 0.9300\n",
      "Epoch 355/500\n",
      "388/388 [==============================] - 56s 146ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.7295 - val_accuracy: 0.9230\n",
      "Epoch 356/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.8702 - val_accuracy: 0.9293\n",
      "Epoch 357/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.8790 - val_accuracy: 0.9294\n",
      "Epoch 358/500\n",
      "388/388 [==============================] - 58s 148ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.8276 - val_accuracy: 0.9280\n",
      "Epoch 359/500\n",
      "388/388 [==============================] - 59s 151ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.6895 - val_accuracy: 0.9312\n",
      "Epoch 360/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.7553 - val_accuracy: 0.9294\n",
      "Epoch 361/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.7818 - val_accuracy: 0.9295\n",
      "Epoch 362/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.8200 - val_accuracy: 0.9268\n",
      "Epoch 363/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.8843 - val_accuracy: 0.9285\n",
      "Epoch 364/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.6177 - val_accuracy: 0.9272\n",
      "Epoch 365/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.6399 - val_accuracy: 0.9241\n",
      "Epoch 366/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.7454 - val_accuracy: 0.9276\n",
      "Epoch 367/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.5844 - val_accuracy: 0.9293\n",
      "Epoch 368/500\n",
      "388/388 [==============================] - 58s 148ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.5972 - val_accuracy: 0.9264\n",
      "Epoch 369/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.8722 - val_accuracy: 0.9280\n",
      "Epoch 370/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0282 - accuracy: 0.9874 - val_loss: 0.5923 - val_accuracy: 0.9199\n",
      "Epoch 371/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.5576 - val_accuracy: 0.9240\n",
      "Epoch 372/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.5571 - val_accuracy: 0.9284\n",
      "Epoch 373/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.6738 - val_accuracy: 0.9273\n",
      "Epoch 374/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.7046 - val_accuracy: 0.9231\n",
      "Epoch 375/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.7374 - val_accuracy: 0.9246\n",
      "Epoch 376/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.7752 - val_accuracy: 0.9249\n",
      "Epoch 377/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.7953 - val_accuracy: 0.9244\n",
      "Epoch 378/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.8131 - val_accuracy: 0.9248\n",
      "Epoch 379/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.8260 - val_accuracy: 0.9248\n",
      "Epoch 380/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.5760 - val_accuracy: 0.9157\n",
      "Epoch 381/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.8849 - val_accuracy: 0.9325\n",
      "Epoch 382/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.7583 - val_accuracy: 0.9284\n",
      "Epoch 383/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.6222 - val_accuracy: 0.9284\n",
      "Epoch 384/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.6770 - val_accuracy: 0.9231\n",
      "Epoch 385/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.7798 - val_accuracy: 0.9290\n",
      "Epoch 386/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.8681 - val_accuracy: 0.9281\n",
      "Epoch 387/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.8171 - val_accuracy: 0.9276\n",
      "Epoch 388/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.5587 - val_accuracy: 0.9251\n",
      "Epoch 389/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.6539 - val_accuracy: 0.9294\n",
      "Epoch 390/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.7366 - val_accuracy: 0.9325\n",
      "Epoch 391/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.5932 - val_accuracy: 0.9286\n",
      "Epoch 392/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.4437 - val_accuracy: 0.9112\n",
      "Epoch 393/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.6102 - val_accuracy: 0.9281\n",
      "Epoch 394/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.6653 - val_accuracy: 0.9299\n",
      "Epoch 395/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.6939 - val_accuracy: 0.9299\n",
      "Epoch 396/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.7722 - val_accuracy: 0.9320\n",
      "Epoch 397/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.5697 - val_accuracy: 0.9233\n",
      "Epoch 398/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.7111 - val_accuracy: 0.9330\n",
      "Epoch 399/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.5256 - val_accuracy: 0.9280\n",
      "Epoch 400/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.6363 - val_accuracy: 0.9288\n",
      "Epoch 401/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.6917 - val_accuracy: 0.9309\n",
      "Epoch 402/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6531 - val_accuracy: 0.9146\n",
      "Epoch 403/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.6471 - val_accuracy: 0.9266\n",
      "Epoch 404/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.5416 - val_accuracy: 0.9288\n",
      "Epoch 405/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5822 - val_accuracy: 0.9257\n",
      "Epoch 406/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.6562 - val_accuracy: 0.9288\n",
      "Epoch 407/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.7048 - val_accuracy: 0.9312\n",
      "Epoch 408/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.5837 - val_accuracy: 0.9300\n",
      "Epoch 409/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.7477 - val_accuracy: 0.9320\n",
      "Epoch 410/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.7385 - val_accuracy: 0.9312\n",
      "Epoch 411/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.7734 - val_accuracy: 0.9329\n",
      "Epoch 412/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.6501 - val_accuracy: 0.9255\n",
      "Epoch 413/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.4918 - val_accuracy: 0.9277\n",
      "Epoch 414/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5817 - val_accuracy: 0.9302\n",
      "Epoch 415/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.6606 - val_accuracy: 0.9326\n",
      "Epoch 416/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.6537 - val_accuracy: 0.9311\n",
      "Epoch 417/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.5456 - val_accuracy: 0.9169\n",
      "Epoch 418/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.5683 - val_accuracy: 0.9242\n",
      "Epoch 419/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.6631 - val_accuracy: 0.9089\n",
      "Epoch 420/500\n",
      "388/388 [==============================] - 56s 146ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.7001 - val_accuracy: 0.9254\n",
      "Epoch 421/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.6281 - val_accuracy: 0.9157\n",
      "Epoch 422/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.7506 - val_accuracy: 0.9308\n",
      "Epoch 423/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.7913 - val_accuracy: 0.9304\n",
      "Epoch 424/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.8073 - val_accuracy: 0.9288\n",
      "Epoch 425/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.6128 - val_accuracy: 0.9223\n",
      "Epoch 426/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.6953 - val_accuracy: 0.9249\n",
      "Epoch 427/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.6186 - val_accuracy: 0.9186\n",
      "Epoch 428/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.7186 - val_accuracy: 0.9227\n",
      "Epoch 429/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.7938 - val_accuracy: 0.9298\n",
      "Epoch 430/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.7913 - val_accuracy: 0.9272\n",
      "Epoch 431/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.8455 - val_accuracy: 0.9297\n",
      "Epoch 432/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.8911 - val_accuracy: 0.9308\n",
      "Epoch 433/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.9060 - val_accuracy: 0.9291\n",
      "Epoch 434/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.7105 - val_accuracy: 0.9298\n",
      "Epoch 435/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.8294 - val_accuracy: 0.9337\n",
      "Epoch 436/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.7384 - val_accuracy: 0.9245\n",
      "Epoch 437/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.9094 - val_accuracy: 0.9309\n",
      "Epoch 438/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.7568 - val_accuracy: 0.9169\n",
      "Epoch 439/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.6802 - val_accuracy: 0.9130\n",
      "Epoch 440/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.8536 - val_accuracy: 0.9254\n",
      "Epoch 441/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.8466 - val_accuracy: 0.9308\n",
      "Epoch 442/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.8472 - val_accuracy: 0.9272\n",
      "Epoch 443/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.8993 - val_accuracy: 0.9290\n",
      "Epoch 444/500\n",
      "388/388 [==============================] - 56s 146ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.9165 - val_accuracy: 0.9299\n",
      "Epoch 445/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.9351 - val_accuracy: 0.9303\n",
      "Epoch 446/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.9383 - val_accuracy: 0.9302\n",
      "Epoch 447/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.9532 - val_accuracy: 0.9300\n",
      "Epoch 448/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.9595 - val_accuracy: 0.9302\n",
      "Epoch 449/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.9674 - val_accuracy: 0.9303\n",
      "Epoch 450/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 1.0009 - val_accuracy: 0.9304\n",
      "Epoch 451/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.9922 - val_accuracy: 0.9304\n",
      "Epoch 452/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 1.0231 - val_accuracy: 0.9304\n",
      "Epoch 453/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 1.2779 - val_accuracy: 0.6750\n",
      "Epoch 454/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.7455 - val_accuracy: 0.9272\n",
      "Epoch 455/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.8155 - val_accuracy: 0.9200\n",
      "Epoch 456/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.8368 - val_accuracy: 0.9159\n",
      "Epoch 457/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.9737 - val_accuracy: 0.9308\n",
      "Epoch 458/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.9527 - val_accuracy: 0.9275\n",
      "Epoch 459/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.9588 - val_accuracy: 0.9273\n",
      "Epoch 460/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.9914 - val_accuracy: 0.9303\n",
      "Epoch 461/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.9843 - val_accuracy: 0.9250\n",
      "Epoch 462/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.9881 - val_accuracy: 0.9261\n",
      "Epoch 463/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.5220 - val_accuracy: 0.9285\n",
      "Epoch 464/500\n",
      "388/388 [==============================] - 58s 150ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.6456 - val_accuracy: 0.9333\n",
      "Epoch 465/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.6771 - val_accuracy: 0.9280\n",
      "Epoch 466/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.6664 - val_accuracy: 0.9288\n",
      "Epoch 467/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.6878 - val_accuracy: 0.9288\n",
      "Epoch 468/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.6200 - val_accuracy: 0.9291\n",
      "Epoch 469/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.7045 - val_accuracy: 0.9307\n",
      "Epoch 470/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.7467 - val_accuracy: 0.9304\n",
      "Epoch 471/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.7900 - val_accuracy: 0.9253\n",
      "Epoch 472/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.5865 - val_accuracy: 0.9235\n",
      "Epoch 473/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.8170 - val_accuracy: 0.9321\n",
      "Epoch 474/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.7762 - val_accuracy: 0.9293\n",
      "Epoch 475/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.8328 - val_accuracy: 0.9313\n",
      "Epoch 476/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.8653 - val_accuracy: 0.9315\n",
      "Epoch 477/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.8935 - val_accuracy: 0.9320\n",
      "Epoch 478/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.8869 - val_accuracy: 0.9317\n",
      "Epoch 479/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.9185 - val_accuracy: 0.9307\n",
      "Epoch 480/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.9418 - val_accuracy: 0.9302\n",
      "Epoch 481/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.9342 - val_accuracy: 0.9302\n",
      "Epoch 482/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.9546 - val_accuracy: 0.9308\n",
      "Epoch 483/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.9784 - val_accuracy: 0.9316\n",
      "Epoch 484/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.9681 - val_accuracy: 0.9313\n",
      "Epoch 485/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.6275 - val_accuracy: 0.9295\n",
      "Epoch 486/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.6140 - val_accuracy: 0.9281\n",
      "Epoch 487/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.7016 - val_accuracy: 0.9307\n",
      "Epoch 488/500\n",
      "388/388 [==============================] - 56s 145ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.7556 - val_accuracy: 0.9312\n",
      "Epoch 489/500\n",
      "388/388 [==============================] - 56s 144ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.7936 - val_accuracy: 0.9306\n",
      "Epoch 490/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.8286 - val_accuracy: 0.9307\n",
      "Epoch 491/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.9011 - val_accuracy: 0.9302\n",
      "Epoch 492/500\n",
      "388/388 [==============================] - 59s 152ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.6108 - val_accuracy: 0.9282\n",
      "Epoch 493/500\n",
      "388/388 [==============================] - 58s 149ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.7822 - val_accuracy: 0.9303\n",
      "Epoch 494/500\n",
      "388/388 [==============================] - 57s 146ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.7012 - val_accuracy: 0.9246\n",
      "Epoch 495/500\n",
      "388/388 [==============================] - 58s 148ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.6829 - val_accuracy: 0.9321\n",
      "Epoch 496/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.7012 - val_accuracy: 0.9303\n",
      "Epoch 497/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.7325 - val_accuracy: 0.9306\n",
      "Epoch 498/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.7797 - val_accuracy: 0.9312\n",
      "Epoch 499/500\n",
      "388/388 [==============================] - 57s 147ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.8076 - val_accuracy: 0.9312\n",
      "Epoch 500/500\n",
      "388/388 [==============================] - 57s 148ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.8171 - val_accuracy: 0.9311\n"
     ]
    }
   ],
   "source": [
    "def batch_generator(image, label, batchsize):\n",
    "    N = len(image)\n",
    "    indices = np.arange(N)  # 0부터 N-1까지의 인덱스 배열 생성\n",
    "    np.random.shuffle(indices)  # 인덱스 배열을 무작위로 섞음\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i + batchsize <= N:\n",
    "            batch_indices = indices[i:i+batchsize]\n",
    "            i = i + batchsize\n",
    "        else:  # 남은 데이터가 batchsize보다 작을 때, 배열을 wrap around하여 다시 섞음\n",
    "            batch_indices = np.concatenate((indices[i:], indices[:batchsize - (N - i)]))\n",
    "            i = batchsize - (N - i)\n",
    "\n",
    "            np.random.shuffle(indices)  # 다음 에포크를 위해 인덱스 배열을 무작위로 섞음\n",
    "\n",
    "        yield image[batch_indices], label[batch_indices]\n",
    "        \n",
    "checkpoint_filepath = \"../../model/skip/DenseNet121_checkpoints.h5\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only= True\n",
    ")\n",
    "class_weight_ratio=compute_class_weight(class_weight = \"balanced\" , \n",
    "                     classes=np.unique(y_train), \n",
    "                     y = y_train)\n",
    "class_weight = {0:class_weight_ratio[0],1:class_weight_ratio[1]}\n",
    "\n",
    "input_t=K.Input(shape=(size,size, 3))\n",
    "input_tensor = layers.experimental.preprocessing.Resizing(size, size, interpolation=\"bilinear\", input_shape=x_train.shape[1:])(input_t)\n",
    "ResNet=DenseNet121(include_top=True,weights='imagenet',input_tensor=input_tensor)\n",
    "model = K.models.Sequential()\n",
    "model.add(ResNet)\n",
    "model.add(tf.keras.layers.Dropout(.2, input_shape=(64,)))\n",
    "model.add(K.layers.Dense(64, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "model.add(K.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=K.optimizers.Adam(lr=2e-4),\n",
    "                loss=tf.keras.losses.binary_crossentropy,\n",
    "                metrics=[\"accuracy\"])\n",
    "histo=model.fit(\n",
    "    batch_generator(x_train,y_train,64),\n",
    "    validation_data=(x_val,y_val),\n",
    "    epochs=500,\n",
    "    steps_per_epoch=len(x_train)//64,\n",
    "    callbacks=model_checkpoint_callback,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weight\n",
    ")\n",
    "model.save('../../model/skip/DenseNet121.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
