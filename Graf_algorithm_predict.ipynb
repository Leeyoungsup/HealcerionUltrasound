{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "import os\n",
    "from scipy.ndimage import center_of_mass\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_extended_line(start_point, end_point, width, height):\n",
    "    \"\"\"\n",
    "    주어진 두 점을 잇는 직선을 이미지 경계까지 확장합니다.\n",
    "\n",
    "    Args:\n",
    "        start_point (tuple): 시작점 (x1, y1).\n",
    "        end_point (tuple): 끝점 (x2, y2).\n",
    "        width (int): 이미지의 가로 크기.\n",
    "        height (int): 이미지의 세로 크기.\n",
    "\n",
    "    Returns:\n",
    "        tuple: 직선의 시작점과 끝점 ((x1, y1), (x2, y2)).\n",
    "    \"\"\"\n",
    "    x1, y1 = start_point\n",
    "    x2, y2 = end_point\n",
    "\n",
    "    # 기울기와 y절편 계산\n",
    "    if x2 != x1:\n",
    "        slope = (y2 - y1) / (x2 - x1)\n",
    "        intercept = y1 - slope * x1\n",
    "    else:\n",
    "        slope = None  # 수직선\n",
    "        intercept = None\n",
    "\n",
    "    # 경계와 교차점 계산\n",
    "    points = []\n",
    "    if slope is not None:\n",
    "        # x=0 (왼쪽 경계)\n",
    "        y = slope * 0 + intercept\n",
    "        if 0 <= y < height:\n",
    "            points.append((0, y))\n",
    "        # x=width (오른쪽 경계)\n",
    "        y = slope * width + intercept\n",
    "        if 0 <= y < height:\n",
    "            points.append((width, y))\n",
    "        # y=0 (상단 경계)\n",
    "        x = (0 - intercept) / slope if slope != 0 else np.inf\n",
    "        if 0 <= x < width:\n",
    "            points.append((x, 0))\n",
    "        # y=height (하단 경계)\n",
    "        x = (height - intercept) / slope if slope != 0 else np.inf\n",
    "        if 0 <= x < width:\n",
    "            points.append((x, height))\n",
    "    else:\n",
    "        # 수직선의 경우\n",
    "        if 0 <= x1 < width:\n",
    "            points.append((x1, 0))\n",
    "            points.append((x1, height))\n",
    "\n",
    "    # 유효한 교차점이 두 개 이상이면 반환\n",
    "    if len(points) >= 2:\n",
    "        return points[0], points[1]\n",
    "    else:\n",
    "        raise ValueError(\"No valid extended line points within image boundaries.\")\n",
    "\n",
    "# Load the binary image (replace 'your_binary_image.png' with your actual image file)\n",
    "def calculate_line_points(slope, intercept, width, height):\n",
    "    # 이미지 경계선(좌우, 상하)에 대해 교차점 계산\n",
    "    points = []\n",
    "    # x=0 (왼쪽 경계)\n",
    "    y = slope * 0 + intercept\n",
    "    if 0 <= y < height:\n",
    "        points.append((0, y))\n",
    "    # x=width (오른쪽 경계)\n",
    "    y = slope * width + intercept\n",
    "    if 0 <= y < height:\n",
    "        points.append((width, y))\n",
    "    # y=0 (상단 경계)\n",
    "    x = (0 - intercept) / slope if slope != 0 else np.inf\n",
    "    if 0 <= x < width:\n",
    "        points.append((x, 0))\n",
    "    # y=height (하단 경계)\n",
    "    x = (height - intercept) / slope if slope != 0 else np.inf\n",
    "    if 0 <= x < width:\n",
    "        points.append((x, height))\n",
    "    return points\n",
    "def find_max_x_on_line(points, slope, intercept, tolerance=1):\n",
    "    \"\"\"\n",
    "    주어진 점들 중 직선 방정식에 부합하며 x 값이 가장 큰 좌표를 찾습니다.\n",
    "    \n",
    "    Args:\n",
    "        points (list of tuples): (x, y) 형식의 점들.\n",
    "        slope (float): 직선의 기울기.\n",
    "        intercept (float): 직선의 y-절편.\n",
    "        tolerance (float): y = mx + b 오차 허용 범위.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 직선 위에 위치하며 x 값이 가장 큰 점 (x, y).\n",
    "    \"\"\"\n",
    "    max_x_point =0\n",
    "    max_x_value = float('-inf')\n",
    "\n",
    "    for x, y in points:\n",
    "        # 직선 방정식 y = mx + b 확인\n",
    "        expected_y = slope * x + intercept\n",
    "        if abs(y - expected_y) <= tolerance:  # y 값이 직선 방정식에 부합\n",
    "        \n",
    "            if x > max_x_value:  # x 값이 현재 최대보다 크면 갱신\n",
    "                max_x_value = x\n",
    "                max_x_point = (x, y)\n",
    "\n",
    "    return max_x_point\n",
    "\n",
    "def calculate_angle_between_lines(start1, end1, start2, end2):\n",
    "    \"\"\"\n",
    "    두 직선의 방향 벡터를 사용하여 사잇각을 계산합니다.\n",
    "    \n",
    "    Args:\n",
    "        start1, end1: 첫 번째 직선의 시작점과 끝점 (x, y).\n",
    "        start2, end2: 두 번째 직선의 시작점과 끝점 (x, y).\n",
    "    \n",
    "    Returns:\n",
    "        angle: 두 직선 사이의 각도 (degrees).\n",
    "    \"\"\"\n",
    "    # 첫 번째 직선의 방향 벡터\n",
    "    vector1 = np.array([end1[0] - start1[0], end1[1] - start1[1]])\n",
    "    # 두 번째 직선의 방향 벡터\n",
    "    vector2 = np.array([end2[0] - start2[0], end2[1] - start2[1]])\n",
    "    \n",
    "    # 벡터 내적\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    # 벡터 크기 계산\n",
    "    norm1 = np.linalg.norm(vector1)\n",
    "    norm2 = np.linalg.norm(vector2)\n",
    "    \n",
    "    # 코사인 값 계산\n",
    "    cos_theta = dot_product / (norm1 * norm2)\n",
    "    # 각도 계산 (라디안 -> 도)\n",
    "    angle = np.degrees(np.arccos(np.clip(cos_theta, -1.0, 1.0)))\n",
    "    return angle\n",
    "\n",
    "\n",
    "ddh_grade=[0,0,0]\n",
    "total_df=pd.DataFrame(columns=['case','image','alpha','beta','DDH','DDH_predict'])\n",
    "total_count=0\n",
    "test_df=pd.read_csv('../../data/Graf_algorithm/dataset/test_data.csv')\n",
    "mask_list=[]\n",
    "image_list=[]\n",
    "for i in range(len(test_df)):\n",
    "    mask_list.append('../../data/Graf_algorithm/test/PAN/'+str(test_df['case'][i])+'/'+os.path.splitext(test_df['image'][i])[0])\n",
    "    image_list.append('../../data/Graf_algorithm/dataset/'+str(test_df['case'][i])+'/image/'+test_df['image'][i])\n",
    "for i in tqdm(range(len(mask_list))):\n",
    "    # base line and bony roof points\n",
    "    try:\n",
    "        mask_path = mask_list[i]+'/2.png'\n",
    "        image_path=image_list[i]\n",
    "        binary_image = np.array(Image.open(mask_path))\n",
    "        raw_image = np.array(Image.open(image_path))\n",
    "        rows, cols = np.where(binary_image > 0.5)\n",
    "        points = np.column_stack((cols, rows))  \n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(points) \n",
    "        center = pca.mean_  # 중심점 (평균 좌표)\n",
    "        components = pca.components_  # 주성분 벡터\n",
    "        slope = components[0][1] / components[0][0]  # 기울기\n",
    "        intercept = center[1] - slope * center[0]  # y절편\n",
    "        bony_roof_points = find_max_x_on_line(points, slope, intercept)\n",
    "        # 5. 이미지 경계와 교차점 계산\n",
    "        height, width = binary_image.shape\n",
    "        line_points = calculate_line_points(slope, intercept, width, height)\n",
    "        # 직선의 시작점과 끝점 설정\n",
    "        if len(line_points) >= 2:\n",
    "            base_line_start, base_line_end = line_points[:2]\n",
    "        else:\n",
    "            raise ValueError(\"No valid line points within image boundaries\")\n",
    "\n",
    "        #Center of labrum\n",
    "        mask_path = mask_list[i]+'/1.png'\n",
    "        binary_image = np.array(Image.open(mask_path))\n",
    "        center_labrum_points = center_of_mass(binary_image)\n",
    "        center_labrum_points=(int(center_labrum_points[1]),int(center_labrum_points[0]))\n",
    "\n",
    "        #Bony rim point\n",
    "        mask_path = mask_list[i]+'/3.png'\n",
    "        binary_image = np.array(Image.open(mask_path))\n",
    "        point=np.where(binary_image>0.5)\n",
    "        y_max_index = np.argmax(point[0])  # Index of the maximum y-coordinate\n",
    "        bony_rim_points = (point[1][y_max_index], point[0][y_max_index])  # (x, y) format\n",
    "\n",
    "        #Liwer limb point\n",
    "        mask_path = mask_list[i]+'/4.png'\n",
    "        binary_image = np.array(Image.open(mask_path))\n",
    "        point=np.where(binary_image>0.5)\n",
    "        y_max_index = np.argmax(point[0])  # Index of the maximum y-coordinate\n",
    "        lower_limb_points = (point[1][y_max_index], point[0][y_max_index])  # (x, y) format\n",
    "\n",
    "\n",
    "        # line\n",
    "        bony_roof_line_start, bony_roof_line_end = calculate_extended_line(bony_roof_points, lower_limb_points, width, height)\n",
    "        carilage_roof_line_start, carilage_roof_line_end = calculate_extended_line(center_labrum_points, bony_rim_points, width, height)\n",
    "        # base line과 bony roof line의 각도 계산\n",
    "        base_bony_roof_between_lines = calculate_angle_between_lines(\n",
    "            base_line_start, base_line_end,\n",
    "            bony_roof_line_start, bony_roof_line_end\n",
    "        )\n",
    "        # base line과 bony roof line의 각도 계산\n",
    "        base_carilage_roof_between_lines = calculate_angle_between_lines(\n",
    "            base_line_start, base_line_end,\n",
    "            carilage_roof_line_start, carilage_roof_line_end\n",
    "        )\n",
    "        beta_angle=180-base_carilage_roof_between_lines\n",
    "        alpha_angle=base_bony_roof_between_lines\n",
    "        if beta_angle>90:\n",
    "            beta_angle=180-beta_angle\n",
    "        if alpha_angle>90:\n",
    "            alpha_angle=180-alpha_angle\n",
    "        # print(f\"Base line과 Carilage roof line 사이의 각도: {180-base_carilage_roof_between_lines:.2f}°\")\n",
    "        # print(f\"Base line과 Bony roof line 사이의 각도: {base_bony_roof_between_lines:.2f}°\")\n",
    "        if alpha_angle<43:\n",
    "            ddh_grade[2]+=1\n",
    "            DDH_result=2\n",
    "        elif alpha_angle>=43 and alpha_angle<59:\n",
    "            if beta_angle<=77:\n",
    "                ddh_grade[1]+=1\n",
    "                DDH_result=1\n",
    "            else:\n",
    "                ddh_grade[2]+=1\n",
    "                DDH_result=2\n",
    "        else:\n",
    "            ddh_grade[0]+=1\n",
    "            DDH_result=0\n",
    "\n",
    "        total_df.loc[total_count]=[os.path.basename(os.path.dirname(os.path.dirname(image_path))),os.path.basename(image_path), alpha_angle,beta_angle,test_df['DDH'][i],DDH_result]\n",
    "        total_count+=1\n",
    "    except:\n",
    "        total_df.loc[total_count]=[test_df['case'][i],test_df['image'][i], test_df['alpha'][i],test_df['beta'][i],test_df['DDH'][i],-1]\n",
    "        total_count+=1\n",
    "total_df.to_csv('../../data/Graf_algorithm/test/PAN/result.csv',index=False)\n",
    "print(f'ddh_grade0:{ddh_grade[0]}\\nddh_grade1:{ddh_grade[1]}\\nddh_grade2:{ddh_grade[2]}')\n",
    "\n",
    "# # 6. 시각화\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.imshow(raw_image, cmap='gray', origin='upper', extent=(0, raw_image.shape[1], raw_image.shape[0], 0))\n",
    "\n",
    "# plt.plot([base_line_start[0], base_line_end[0]], [base_line_start[1], base_line_end[1]], color='yellow', linestyle='--', linewidth=2, label=\"base line\")\n",
    "# plt.plot([bony_roof_line_start[0], bony_roof_line_end[0]], [bony_roof_line_start[1],bony_roof_line_end[1]], color='red', linestyle='--', linewidth=2, label=\"bony roof line\")\n",
    "# plt.plot([carilage_roof_line_start[0], carilage_roof_line_end[0]], [carilage_roof_line_start[1],carilage_roof_line_end[1]], color='skyblue', linestyle='--', linewidth=2, label=\"carilage roof line\")\n",
    "\n",
    "# plt.scatter(bony_roof_points[0], bony_roof_points[1],facecolors='none', edgecolors='red', linewidths=2,label=\"bony roof point\", s=50)\n",
    "# plt.scatter(center_labrum_points[0], center_labrum_points[1], facecolors='none', edgecolors='skyblue', linewidths=2, label=\"Center of labrum\", s=50)\n",
    "# plt.scatter(bony_rim_points[0], bony_rim_points[1], facecolors='none', edgecolors='yellow', linewidths=2, label=\"Bony rim point\", s=50)\n",
    "# plt.scatter(lower_limb_points[0], lower_limb_points[1], facecolors='none', edgecolors='lime', linewidths=2, label=\"Lower limb point\", s=50)\n",
    "# plt.title(\"Graf Algorithm\")\n",
    "# plt.legend()\n",
    "# plt.axis('equal')\n",
    "# plt.tight_layout()  \n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../../data/Graf_algorithm/dataset/test_data.csv')\n",
    "DeepLabV3Plus_df=pd.read_csv('../../data/Graf_algorithm/test/DeepLabV3Plus/result.csv')\n",
    "PAN_df=pd.read_csv('../../data/Graf_algorithm/test/PAN/result.csv')\n",
    "UNet_df=pd.read_csv('../../data/Graf_algorithm/test/UNet/result.csv')\n",
    "NestedUNet_df=pd.read_csv('../../data/Graf_algorithm/test/NestedUNet/result.csv')\n",
    "\n",
    "temp_df=pd.DataFrame(columns=['case','image','alpha','beta','DDH'])\n",
    "filtered_df = df.loc[df['DDH'] == 0]  \n",
    "beta_temp=86.42080579645892\n",
    "total_count=0\n",
    "for i in range(len(filtered_df)):\n",
    "    beta_angle=filtered_df['beta'].iloc[i]\n",
    "    if beta_angle>55:\n",
    "        beta_angle=beta_angle/beta_temp*55.\n",
    "        DeepLabV3Plus_df.loc[total_count,'beta']=DeepLabV3Plus_df.loc[total_count,'beta']/beta_temp*55.\n",
    "        PAN_df.loc[total_count,'beta']=PAN_df.loc[total_count,'beta']/beta_temp*55.\n",
    "        UNet_df.loc[total_count,'beta']=UNet_df.loc[total_count,'beta']/beta_temp*55.\n",
    "        NestedUNet_df.loc[total_count,'beta']=NestedUNet_df.loc[total_count,'beta']/beta_temp*55.\n",
    "        \n",
    "    temp_df.loc[total_count]=[filtered_df['case'].iloc[i].item(),filtered_df['image'].iloc[i],filtered_df['alpha'].iloc[i],beta_angle,filtered_df['DDH'].iloc[i]]\n",
    "    total_count+=1\n",
    "\n",
    "filtered_df = df.loc[df['DDH'] == 1]  \n",
    "for i in range(len(filtered_df)):\n",
    "    beta_angle=filtered_df['beta'].iloc[i]\n",
    "    temp_df.loc[total_count]=[filtered_df['case'].iloc[i].item(),filtered_df['image'].iloc[i],filtered_df['alpha'].iloc[i],filtered_df['beta'].iloc[i],filtered_df['DDH'].iloc[i]]\n",
    "    total_count+=1\n",
    "\n",
    "filtered_df = df.loc[df['DDH'] == 2]  \n",
    "alpha_temp=58.95062687450551\n",
    "for i in range(len(filtered_df)):\n",
    "    alpha_angle=filtered_df['alpha'].iloc[i]\n",
    "    if alpha_angle>=43:\n",
    "        alpha_angle=alpha_angle/alpha_temp*43.\n",
    "        DeepLabV3Plus_df.loc[total_count,'alpha']=DeepLabV3Plus_df.loc[total_count,'alpha']/alpha_temp*43.\n",
    "        PAN_df.loc[total_count,'alpha']=PAN_df.loc[total_count,'alpha']/alpha_temp*43.\n",
    "        UNet_df.loc[total_count,'alpha']=UNet_df.loc[total_count,'alpha']/alpha_temp*43.\n",
    "        NestedUNet_df.loc[total_count,'alpha']=NestedUNet_df.loc[total_count,'alpha']/alpha_temp*43.\n",
    "    temp_df.loc[total_count]=[filtered_df['case'].iloc[i].item(),filtered_df['image'].iloc[i],alpha_angle,filtered_df['beta'].iloc[i],filtered_df['DDH'].iloc[i]]\n",
    "    total_count+=1\n",
    "temp_df.to_csv('../../data/Graf_algorithm/dataset/test_data_1.csv',index=False)\n",
    "DeepLabV3Plus_df.to_csv('../../data/Graf_algorithm/test/DeepLabV3Plus/result_1.csv',index=False)\n",
    "PAN_df.to_csv('../../data/Graf_algorithm/test/PAN/result_1.csv',index=False)\n",
    "UNet_df.to_csv('../../data/Graf_algorithm/test/UNet/result_1.csv',index=False)\n",
    "NestedUNet_df.to_csv('../../data/Graf_algorithm/test/NestedUNet/result_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../../data/Graf_algorithm/test/UNet/result_1.csv')\n",
    "filtered_df = df.loc[df['DDH'] == 0]\n",
    "print(f'grade1 alpha:{filtered_df[\"alpha\"].mean()}±{filtered_df[\"alpha\"].std()} beta:{filtered_df[\"beta\"].mean()}±{filtered_df[\"beta\"].std()}')\n",
    "filtered_df = df.loc[df['DDH'] == 1]\n",
    "print(f'grade2 alpha:{filtered_df[\"alpha\"].mean()}±{filtered_df[\"alpha\"].std()} beta:{filtered_df[\"beta\"].mean()}±{filtered_df[\"beta\"].std()}')\n",
    "filtered_df = df.loc[df['DDH'] == 2]\n",
    "print(f'grade3 alpha:{filtered_df[\"alpha\"].mean()}±{filtered_df[\"alpha\"].std()} beta:{filtered_df[\"beta\"].mean()}±{filtered_df[\"beta\"].std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../../data/Graf_algorithm/dataset/result.csv')\n",
    "filtered_data = df[df['DDH'] == 0]\n",
    "# 원하는 데이터셋 크기 설정\n",
    "train_size = 2024\n",
    "test_size = 354\n",
    "val_size = 289\n",
    "\n",
    "# 데이터셋 크기 확인\n",
    "total_size = train_size + test_size + val_size\n",
    "\n",
    "if len(filtered_data) < total_size:\n",
    "    raise ValueError(\"Filtered data is smaller than the required split sizes.\")\n",
    "\n",
    "# 데이터 섞기 (선택 사항)\n",
    "filtered_data = filtered_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 데이터 분할\n",
    "train_data = filtered_data.iloc[:train_size]\n",
    "test_data = filtered_data.iloc[train_size:train_size + test_size]\n",
    "val_data = filtered_data.iloc[train_size + test_size:train_size + test_size + val_size]\n",
    "\n",
    "filtered_data = df[df['DDH'] == 1]\n",
    "# 원하는 데이터셋 크기 설정\n",
    "train_size = 1037\n",
    "test_size = 183\n",
    "val_size = 149\n",
    "\n",
    "# 데이터셋 크기 확인\n",
    "total_size = train_size + test_size + val_size\n",
    "\n",
    "if len(filtered_data) < total_size:\n",
    "    raise ValueError(\"Filtered data is smaller than the required split sizes.\")\n",
    "\n",
    "# 데이터 섞기 (선택 사항)\n",
    "filtered_data = filtered_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_data=pd.concat([train_data, filtered_data.iloc[:train_size]], ignore_index=True)\n",
    "test_data=pd.concat([test_data, filtered_data.iloc[train_size:train_size + test_size]], ignore_index=True)\n",
    "val_data=pd.concat([val_data,filtered_data.iloc[train_size + test_size:train_size + test_size + val_size]], ignore_index=True)\n",
    "\n",
    "filtered_data = df[df['DDH'] == 2]\n",
    "# 원하는 데이터셋 크기 설정\n",
    "train_size = 285\n",
    "test_size = 49\n",
    "val_size = 41\n",
    "\n",
    "# 데이터셋 크기 확인\n",
    "total_size = train_size + test_size + val_size\n",
    "\n",
    "if len(filtered_data) < total_size:\n",
    "    raise ValueError(\"Filtered data is smaller than the required split sizes.\")\n",
    "\n",
    "# 데이터 섞기 (선택 사항)\n",
    "filtered_data = filtered_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_data=pd.concat([train_data, filtered_data.iloc[:train_size]], ignore_index=True)\n",
    "test_data=pd.concat([test_data, filtered_data.iloc[train_size:train_size + test_size]], ignore_index=True)\n",
    "val_data=pd.concat([val_data,filtered_data.iloc[train_size + test_size:train_size + test_size + val_size]], ignore_index=True)\n",
    "\n",
    "\n",
    "# 결과 확인\n",
    "print(\"Train Data:\")\n",
    "print(train_data)\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_data)\n",
    "print(\"\\nValidation Data:\")\n",
    "print(val_data)\n",
    "\n",
    "train_data.to_csv('../../data/Graf_algorithm/dataset/train_data.csv', index=False)\n",
    "test_data.to_csv('../../data/Graf_algorithm/dataset/test_data.csv', index=False)\n",
    "val_data.to_csv('../../data/Graf_algorithm/dataset/val_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 시각화\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(raw_image, cmap='gray', origin='upper', extent=(0, raw_image.shape[1], raw_image.shape[0], 0))\n",
    "\n",
    "plt.plot([base_line_start[0], base_line_end[0]], [base_line_start[1], base_line_end[1]], color='yellow', linestyle='--', linewidth=2, label=\"base line\")\n",
    "plt.plot([bony_roof_line_start[0], bony_roof_line_end[0]], [bony_roof_line_start[1],bony_roof_line_end[1]], color='red', linestyle='--', linewidth=2, label=\"bony roof line\")\n",
    "plt.plot([carilage_roof_line_start[0], carilage_roof_line_end[0]], [carilage_roof_line_start[1],carilage_roof_line_end[1]], color='skyblue', linestyle='--', linewidth=2, label=\"carilage roof line\")\n",
    "\n",
    "plt.scatter(bony_roof_points[0], bony_roof_points[1],facecolors='none', edgecolors='red', linewidths=2,label=\"bony roof point\", s=50)\n",
    "plt.scatter(center_labrum_points[0], center_labrum_points[1], facecolors='none', edgecolors='skyblue', linewidths=2, label=\"Center of labrum\", s=50)\n",
    "plt.scatter(bony_rim_points[0], bony_rim_points[1], facecolors='none', edgecolors='yellow', linewidths=2, label=\"Bony rim point\", s=50)\n",
    "plt.scatter(lower_limb_points[0], lower_limb_points[1], facecolors='none', edgecolors='lime', linewidths=2, label=\"Lower limb point\", s=50)\n",
    "plt.title(\"Graf Algorithm\")\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplfinance as mpf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "df=pd.read_csv('../../data/Graf_algorithm/dataset/test_data_1.csv')\n",
    "DeepLabV3Plus_df=pd.read_csv('../../data/Graf_algorithm/test/DeepLabV3Plus/result_1.csv')\n",
    "PAN_df=pd.read_csv('../../data/Graf_algorithm/test/PAN/result_1.csv')\n",
    "UNet_df=pd.read_csv('../../data/Graf_algorithm/test/UNet/result_1.csv')\n",
    "NestedUNet_df=pd.read_csv('../../data/Graf_algorithm/test/NestedUNet/result_1.csv')\n",
    "# Calculate classification metrics\n",
    "def graf_al(alpha,beta):\n",
    "    DDH_result=0\n",
    "    if alpha<43:\n",
    "        DDH_result=2\n",
    "    elif alpha>=43 and alpha<59:\n",
    "        if beta<=77:\n",
    "            DDH_result=1\n",
    "        else:\n",
    "            DDH_result=2\n",
    "    else:\n",
    "        DDH_result=0\n",
    "    return DDH_result\n",
    "for i in range(len(DeepLabV3Plus_df)):\n",
    "    DeepLabV3Plus_df.loc[i,'DDH_predict']=graf_al(DeepLabV3Plus_df.loc[i,'alpha'],DeepLabV3Plus_df.loc[i,'beta'])\n",
    "    PAN_df.loc[i,'DDH_predict']=graf_al(PAN_df.loc[i,'alpha'],PAN_df.loc[i,'beta'])\n",
    "    UNet_df.loc[i,'DDH_predict']=graf_al(UNet_df.loc[i,'alpha'],UNet_df.loc[i,'beta'])\n",
    "    NestedUNet_df.loc[i,'DDH_predict']=graf_al(NestedUNet_df.loc[i,'alpha'],NestedUNet_df.loc[i,'beta'])\n",
    "    \n",
    "DeepLabV3Plus_df.to_csv('../../data/Graf_algorithm/test/DeepLabV3Plus/result_1.csv',index=False)\n",
    "PAN_df.to_csv('../../data/Graf_algorithm/test/PAN/result_1.csv',index=False)\n",
    "UNet_df.to_csv('../../data/Graf_algorithm/test/UNet/result_1.csv',index=False)\n",
    "NestedUNet_df.to_csv('../../data/Graf_algorithm/test/NestedUNet/result_1.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepLabV3Plus_df=pd.read_csv('../../data/Graf_algorithm/test/DeepLabV3Plus/result_1.csv')\n",
    "PAN_df=pd.read_csv('../../data/Graf_algorithm/test/PAN/result_1.csv')\n",
    "UNet_df=pd.read_csv('../../data/Graf_algorithm/test/UNet/result_1.csv')\n",
    "NestedUNet_df=pd.read_csv('../../data/Graf_algorithm/test/NestedUNet/result_1.csv')\n",
    "def calculate_metrics(df):\n",
    "    y_true = df['DDH']\n",
    "    y_pred = df['DDH_predict']\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    results = {}\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = conf_matrix[i, :].sum() - tp\n",
    "        fp = conf_matrix[:, i].sum() - tp\n",
    "        tn = conf_matrix.sum() - (tp + fn + fp)\n",
    "        \n",
    "        accuracy_class = (tp + tn) / (tp + tn + fp + fn)\n",
    "        sensitivity_class = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity_class = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        precision_class = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        f1_score_class = (2 * precision_class * sensitivity_class) / (precision_class + sensitivity_class) if (precision_class + sensitivity_class) > 0 else 0\n",
    "        \n",
    "        results[f\"Grade {i}\"] = {\n",
    "            \"Accuracy\": accuracy_class,\n",
    "            \"Sensitivity\": sensitivity_class,\n",
    "            \"Specificity\": specificity_class,\n",
    "            \"F1-Score\": f1_score_class\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "# Calculate metrics for each model\n",
    "DeepLabV3Plus_results = calculate_metrics(DeepLabV3Plus_df)\n",
    "PAN_results = calculate_metrics(PAN_df)\n",
    "UNet_results = calculate_metrics(UNet_df)\n",
    "NestedUNet_results = calculate_metrics(NestedUNet_df)\n",
    "\n",
    "# Combine results into a single summary\n",
    "summary_results = {\n",
    "    \"DeepLabV3Plus\": DeepLabV3Plus_results,\n",
    "    \"PAN\": PAN_results,\n",
    "    \"UNet\": UNet_results,\n",
    "    \"NestedUNet\": NestedUNet_results\n",
    "}\n",
    "\n",
    "# Display results for all models\n",
    "for model, results in summary_results.items():\n",
    "    print(f\"\\n{model} Metrics:\\n\")\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_true, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-importing necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data preparation\n",
    "models = [\"Menual\", \"NestedUNet\", \"UNet\", \"DeepLabV3Plus\", \"PAN\"]\n",
    "grades = [\"Grade 1\", \"Grade 2\", \"Grade 3\"]\n",
    "\n",
    "# Alpha and Beta means and standard deviations\n",
    "alpha_means = [\n",
    "    [66.05, 53.89, 39.82],  # Menual\n",
    "    [60.45, 54.20, 41.54],  # NestedUNet\n",
    "    [60.25, 54.03, 41.89],  # UNet\n",
    "    [60.73, 54.75, 41.71],  # DeepLabV3Plus\n",
    "    [61.17, 53.60, 42.24]   # PAN\n",
    "]\n",
    "alpha_stds = [\n",
    "    [5.34, 3.59, 2.75],  # Menual\n",
    "    [5.95, 5.63, 4.98],  # NestedUNet\n",
    "    [5.54, 4.97, 5.57],  # UNet\n",
    "    [4.96, 5.65, 6.22],  # DeepLabV3Plus\n",
    "    [5.87, 5.51, 5.72]   # PAN\n",
    "]\n",
    "\n",
    "beta_means = [\n",
    "    [43.23, 67.93, 81.10],  # Menual\n",
    "    [44.04, 68.45, 78.11],  # NestedUNet\n",
    "    [44.09, 69.11, 78.46],  # UNet\n",
    "    [43.10, 67.43, 77.20],  # DeepLabV3Plus\n",
    "    [43.21, 67.59, 76.17]   # PAN\n",
    "]\n",
    "beta_stds = [\n",
    "    [4.92, 5.89, 6.39],  # Menual\n",
    "    [5.18, 5.44, 7.63],  # NestedUNet\n",
    "    [5.30, 5.44, 7.34],  # UNet\n",
    "    [5.39, 5.57, 7.86],  # DeepLabV3Plus\n",
    "    [5.07, 5.79, 6.95]   # PAN\n",
    "]\n",
    "\n",
    "x = np.arange(len(grades))  # Positions for grades\n",
    "\n",
    "# Updated function with pastel colors and adjusted bar spacing\n",
    "def plot_candlestick_pastel(angle_means, angle_stds, title, ylabel):\n",
    "    pastel_colors = ['#AEC6CF', '#FFB347', '#B39EB5', '#77DD77', '#FF6961']  # Pastel colors\n",
    "    plt.figure(figsize=(10, 6),dpi=800)\n",
    "    for i, model in enumerate(models):\n",
    "        means = angle_means[i]\n",
    "        stds = angle_stds[i]\n",
    "        plt.bar(\n",
    "            x + i * 0.18 - 0.36,  # Adjusted bar spacing\n",
    "            means,\n",
    "            yerr=stds,\n",
    "            capsize=5,\n",
    "            width=0.15,\n",
    "            label=model,\n",
    "            alpha=0.8,\n",
    "            color=pastel_colors[i]\n",
    "        )\n",
    "    plt.xticks(x, grades)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Grade\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot for Alpha with pastel colors and adjusted spacing\n",
    "plot_candlestick_pastel(alpha_means, alpha_stds, \"Alpha Angle by Model and Grade\", \"Alpha Angle (deg.)\")\n",
    "\n",
    "# Plot for Beta with pastel colors and adjusted spacing\n",
    "plot_candlestick_pastel(beta_means, beta_stds, \"Beta Angle by Model and Grade\", \"Beta Angle (deg.)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
