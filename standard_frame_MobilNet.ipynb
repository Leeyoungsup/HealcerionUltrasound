{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 20:08:10.162765: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-27 20:08:11.087056: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras import datasets, layers, models, losses, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pre\n",
    "from glob import glob\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_img_list=pd.read_csv('../../data/standardFrame_data/scale_ignore/Train_dataframe.csv')['file_path'].to_list()\n",
    "Train_label_list=pd.read_csv('../../data/standardFrame_data/scale_ignore/Train_dataframe.csv')['standard'].to_list()\n",
    "Test_img_list=pd.read_csv('../../data/standardFrame_data/scale_ignore/Test_dataframe.csv')['file_path'].to_list()\n",
    "Test_label_list=pd.read_csv('../../data/standardFrame_data/scale_ignore/Test_dataframe.csv')['standard'].to_list()\n",
    "Val_img_list=pd.read_csv('../../data/standardFrame_data/scale_ignore/Validation_dataframe.csv')['file_path'].to_list()\n",
    "Val_label_list=pd.read_csv('../../data/standardFrame_data/scale_ignore/Validation_dataframe.csv')['standard'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_img_path='../../data/standardFrame_data/scale_ignore/train'\n",
    "Test_img_path='../../data/standardFrame_data/scale_ignore/test'\n",
    "Val_img_path='../../data/standardFrame_data/scale_ignore/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=224\n",
    "x_train = np.zeros((len(Train_img_list),size,size,3))\n",
    "for i in range(len(Train_img_list)):\n",
    "    x_train[i] =np.array(Image.open(Train_img_path+Train_img_list[i]).resize((size,size)))\n",
    "x_train=x_train/255\n",
    "y_train=np.array(Train_label_list)\n",
    "\n",
    "x_test = np.zeros((len(Test_img_list),size,size,3))\n",
    "for i in range(len(Test_img_list)):\n",
    "    x_test[i] =np.array(Image.open(Test_img_path+Test_img_list[i]).resize((size,size)))\n",
    "x_test=x_test/255\n",
    "y_test=np.array(Test_label_list)\n",
    "\n",
    "x_val = np.zeros((len(Val_img_list),size,size,3))\n",
    "for i in range(len(Val_img_list)):\n",
    "    x_val[i] =np.array(Image.open(Val_img_path+Val_img_list[i]).resize((size,size)))\n",
    "x_val=x_val/255\n",
    "y_val=np.array(Val_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 20:11:01.048917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38163 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:61:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "2023-07-27 20:11:09.794104: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 16925970432 exceeds 10% of free system memory.\n",
      "2023-07-27 20:11:18.808672: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 16925970432 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 20:11:32.443591: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/MobilenetV3large/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-07-27 20:11:34.534992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8902\n",
      "2023-07-27 20:11:36.041820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-07-27 20:11:36.061296: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f5ac75d6790 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-27 20:11:36.061331: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2023-07-27 20:11:36.065530: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-27 20:11:36.192204: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879/879 [==============================] - 79s 56ms/step - loss: 0.6938 - accuracy: 0.4691 - val_loss: 0.7283 - val_accuracy: 0.0665\n",
      "Epoch 2/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6937 - accuracy: 0.4567 - val_loss: 0.6926 - val_accuracy: 0.9335\n",
      "Epoch 3/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6936 - accuracy: 0.4828 - val_loss: 0.7012 - val_accuracy: 0.0665\n",
      "Epoch 4/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6935 - accuracy: 0.5182 - val_loss: 0.7120 - val_accuracy: 0.0665\n",
      "Epoch 5/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6934 - accuracy: 0.3821 - val_loss: 0.6745 - val_accuracy: 0.9335\n",
      "Epoch 6/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6933 - accuracy: 0.5003 - val_loss: 0.6943 - val_accuracy: 0.0665\n",
      "Epoch 7/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6933 - accuracy: 0.5578 - val_loss: 0.7071 - val_accuracy: 0.0665\n",
      "Epoch 8/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6934 - accuracy: 0.4242 - val_loss: 0.7022 - val_accuracy: 0.0665\n",
      "Epoch 9/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6935 - accuracy: 0.5085 - val_loss: 0.6863 - val_accuracy: 0.9335\n",
      "Epoch 10/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6934 - accuracy: 0.6515 - val_loss: 0.6933 - val_accuracy: 0.0665\n",
      "Epoch 11/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.5300 - val_loss: 0.6977 - val_accuracy: 0.0665\n",
      "Epoch 12/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4586 - val_loss: 0.6936 - val_accuracy: 0.0665\n",
      "Epoch 13/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.6076 - val_loss: 0.6961 - val_accuracy: 0.0665\n",
      "Epoch 14/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4231 - val_loss: 0.6931 - val_accuracy: 0.9335\n",
      "Epoch 15/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4890 - val_loss: 0.6956 - val_accuracy: 0.0665\n",
      "Epoch 16/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.2206 - val_loss: 0.6849 - val_accuracy: 0.9335\n",
      "Epoch 17/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5792 - val_loss: 0.6904 - val_accuracy: 0.9335\n",
      "Epoch 18/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6645 - val_loss: 0.6971 - val_accuracy: 0.0665\n",
      "Epoch 19/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6933 - accuracy: 0.4137 - val_loss: 0.6958 - val_accuracy: 0.0665\n",
      "Epoch 20/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4605 - val_loss: 0.6978 - val_accuracy: 0.0665\n",
      "Epoch 21/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.2977 - val_loss: 0.6905 - val_accuracy: 0.9335\n",
      "Epoch 22/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5549 - val_loss: 0.6948 - val_accuracy: 0.0665\n",
      "Epoch 23/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.3616 - val_loss: 0.6858 - val_accuracy: 0.9335\n",
      "Epoch 24/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6692 - val_loss: 0.6909 - val_accuracy: 0.9335\n",
      "Epoch 25/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4532 - val_loss: 0.6930 - val_accuracy: 0.9335\n",
      "Epoch 26/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.5813 - val_loss: 0.6940 - val_accuracy: 0.0665\n",
      "Epoch 27/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5983 - val_loss: 0.6979 - val_accuracy: 0.0665\n",
      "Epoch 28/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4301 - val_loss: 0.6921 - val_accuracy: 0.9335\n",
      "Epoch 29/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3470 - val_loss: 0.6920 - val_accuracy: 0.9335\n",
      "Epoch 30/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6577 - val_loss: 0.7022 - val_accuracy: 0.0665\n",
      "Epoch 31/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.2992 - val_loss: 0.6964 - val_accuracy: 0.0665\n",
      "Epoch 32/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5841 - val_loss: 0.6999 - val_accuracy: 0.0665\n",
      "Epoch 33/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4069 - val_loss: 0.6933 - val_accuracy: 0.0665\n",
      "Epoch 34/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6237 - val_loss: 0.6948 - val_accuracy: 0.0665\n",
      "Epoch 35/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4042 - val_loss: 0.6932 - val_accuracy: 0.0665\n",
      "Epoch 36/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.5674 - val_loss: 0.6985 - val_accuracy: 0.0665\n",
      "Epoch 37/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.6075 - val_loss: 0.7013 - val_accuracy: 0.0665\n",
      "Epoch 38/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3784 - val_loss: 0.6975 - val_accuracy: 0.0665\n",
      "Epoch 39/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.2973 - val_loss: 0.6894 - val_accuracy: 0.9335\n",
      "Epoch 40/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.6713 - val_loss: 0.6970 - val_accuracy: 0.0665\n",
      "Epoch 41/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.2222 - val_loss: 0.6913 - val_accuracy: 0.9335\n",
      "Epoch 42/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5282 - val_loss: 0.6904 - val_accuracy: 0.9335\n",
      "Epoch 43/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.4791 - val_loss: 0.6857 - val_accuracy: 0.9335\n",
      "Epoch 44/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6845 - val_loss: 0.6955 - val_accuracy: 0.0665\n",
      "Epoch 45/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.6312 - val_loss: 0.6975 - val_accuracy: 0.0665\n",
      "Epoch 46/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.2635 - val_loss: 0.6896 - val_accuracy: 0.9335\n",
      "Epoch 47/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5387 - val_loss: 0.6886 - val_accuracy: 0.9335\n",
      "Epoch 48/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6011 - val_loss: 0.6898 - val_accuracy: 0.9335\n",
      "Epoch 49/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.5252 - val_loss: 0.6874 - val_accuracy: 0.9335\n",
      "Epoch 50/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6742 - val_loss: 0.6921 - val_accuracy: 0.9335\n",
      "Epoch 51/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.2621 - val_loss: 0.6908 - val_accuracy: 0.9335\n",
      "Epoch 52/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.8537 - val_loss: 0.6973 - val_accuracy: 0.0665\n",
      "Epoch 53/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6933 - accuracy: 0.4414 - val_loss: 0.6980 - val_accuracy: 0.0665\n",
      "Epoch 54/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5163 - val_loss: 0.7053 - val_accuracy: 0.0665\n",
      "Epoch 55/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6933 - accuracy: 0.2796 - val_loss: 0.6945 - val_accuracy: 0.0665\n",
      "Epoch 56/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.3576 - val_loss: 0.6848 - val_accuracy: 0.9335\n",
      "Epoch 57/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6339 - val_loss: 0.6956 - val_accuracy: 0.0665\n",
      "Epoch 58/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5255 - val_loss: 0.6943 - val_accuracy: 0.0665\n",
      "Epoch 59/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.2166 - val_loss: 0.6724 - val_accuracy: 0.9335\n",
      "Epoch 60/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.7696 - val_loss: 0.6993 - val_accuracy: 0.0665\n",
      "Epoch 61/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4098 - val_loss: 0.6981 - val_accuracy: 0.0665\n",
      "Epoch 62/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.3704 - val_loss: 0.6882 - val_accuracy: 0.9335\n",
      "Epoch 63/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4747 - val_loss: 0.6946 - val_accuracy: 0.0665\n",
      "Epoch 64/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5556 - val_loss: 0.7004 - val_accuracy: 0.0665\n",
      "Epoch 65/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3195 - val_loss: 0.6964 - val_accuracy: 0.0665\n",
      "Epoch 66/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4093 - val_loss: 0.6982 - val_accuracy: 0.0665\n",
      "Epoch 67/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4546 - val_loss: 0.6960 - val_accuracy: 0.0665\n",
      "Epoch 68/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4587 - val_loss: 0.6932 - val_accuracy: 0.0665\n",
      "Epoch 69/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6141 - val_loss: 0.7010 - val_accuracy: 0.0665\n",
      "Epoch 70/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.2228 - val_loss: 0.6883 - val_accuracy: 0.9335\n",
      "Epoch 71/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.7327 - val_loss: 0.6945 - val_accuracy: 0.0665\n",
      "Epoch 72/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.5424 - val_loss: 0.6944 - val_accuracy: 0.0665\n",
      "Epoch 73/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.2480 - val_loss: 0.6903 - val_accuracy: 0.9335\n",
      "Epoch 74/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5454 - val_loss: 0.6933 - val_accuracy: 0.0665\n",
      "Epoch 75/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6939 - val_accuracy: 0.0665\n",
      "Epoch 76/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5763 - val_loss: 0.6904 - val_accuracy: 0.9335\n",
      "Epoch 77/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.4271 - val_loss: 0.6738 - val_accuracy: 0.9335\n",
      "Epoch 78/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.7218 - val_loss: 0.6902 - val_accuracy: 0.9335\n",
      "Epoch 79/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6933 - accuracy: 0.5748 - val_loss: 0.6968 - val_accuracy: 0.0665\n",
      "Epoch 80/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4760 - val_loss: 0.6999 - val_accuracy: 0.0665\n",
      "Epoch 81/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.3026 - val_loss: 0.6886 - val_accuracy: 0.9335\n",
      "Epoch 82/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.6581 - val_loss: 0.6987 - val_accuracy: 0.0665\n",
      "Epoch 83/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4764 - val_loss: 0.6969 - val_accuracy: 0.0665\n",
      "Epoch 84/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.1973 - val_loss: 0.6861 - val_accuracy: 0.9335\n",
      "Epoch 85/500\n",
      "879/879 [==============================] - 44s 49ms/step - loss: 0.6933 - accuracy: 0.5763 - val_loss: 0.6916 - val_accuracy: 0.9335\n",
      "Epoch 86/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5285 - val_loss: 0.6969 - val_accuracy: 0.0665\n",
      "Epoch 87/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4245 - val_loss: 0.6950 - val_accuracy: 0.0665\n",
      "Epoch 88/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4468 - val_loss: 0.6937 - val_accuracy: 0.0665\n",
      "Epoch 89/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6858 - val_loss: 0.6981 - val_accuracy: 0.0665\n",
      "Epoch 90/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4344 - val_loss: 0.6956 - val_accuracy: 0.0665\n",
      "Epoch 91/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5970 - val_loss: 0.6988 - val_accuracy: 0.0665\n",
      "Epoch 92/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6849 - val_accuracy: 0.9335\n",
      "Epoch 93/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.5808 - val_loss: 0.6896 - val_accuracy: 0.9335\n",
      "Epoch 94/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6854 - val_accuracy: 0.9335\n",
      "Epoch 95/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.6730 - val_loss: 0.6965 - val_accuracy: 0.0665\n",
      "Epoch 96/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.5595 - val_loss: 0.6935 - val_accuracy: 0.0665\n",
      "Epoch 97/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6930 - accuracy: 0.7368 - val_loss: 0.7337 - val_accuracy: 0.0665\n",
      "Epoch 98/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4664 - val_loss: 0.6877 - val_accuracy: 0.9335\n",
      "Epoch 99/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4967 - val_loss: 0.6847 - val_accuracy: 0.9335\n",
      "Epoch 100/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.6677 - val_loss: 0.6929 - val_accuracy: 0.9335\n",
      "Epoch 101/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.5763 - val_loss: 0.6912 - val_accuracy: 0.9335\n",
      "Epoch 102/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.3846 - val_loss: 0.6906 - val_accuracy: 0.9335\n",
      "Epoch 103/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6393 - val_loss: 0.6907 - val_accuracy: 0.9335\n",
      "Epoch 104/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.7883 - val_loss: 0.6943 - val_accuracy: 0.0665\n",
      "Epoch 105/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.2385 - val_loss: 0.6910 - val_accuracy: 0.9335\n",
      "Epoch 106/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4252 - val_loss: 0.6772 - val_accuracy: 0.9335\n",
      "Epoch 107/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6388 - val_loss: 0.6974 - val_accuracy: 0.0665\n",
      "Epoch 108/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6921 - val_accuracy: 0.9335\n",
      "Epoch 109/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.3088 - val_loss: 0.6860 - val_accuracy: 0.9335\n",
      "Epoch 110/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6245 - val_loss: 0.6951 - val_accuracy: 0.0665\n",
      "Epoch 111/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.3134 - val_loss: 0.6910 - val_accuracy: 0.9335\n",
      "Epoch 112/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6024 - val_loss: 0.7021 - val_accuracy: 0.0665\n",
      "Epoch 113/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.2099 - val_loss: 0.6868 - val_accuracy: 0.9335\n",
      "Epoch 114/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.6019 - val_loss: 0.6943 - val_accuracy: 0.0665\n",
      "Epoch 115/500\n",
      "879/879 [==============================] - 45s 51ms/step - loss: 0.6932 - accuracy: 0.3941 - val_loss: 0.6895 - val_accuracy: 0.9335\n",
      "Epoch 116/500\n",
      "879/879 [==============================] - 44s 51ms/step - loss: 0.6933 - accuracy: 0.3943 - val_loss: 0.6856 - val_accuracy: 0.9335\n",
      "Epoch 117/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.7138 - val_loss: 0.7029 - val_accuracy: 0.0665\n",
      "Epoch 118/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5671 - val_loss: 0.6976 - val_accuracy: 0.0665\n",
      "Epoch 119/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.2691 - val_loss: 0.6935 - val_accuracy: 0.0665\n",
      "Epoch 120/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.6450 - val_loss: 0.6987 - val_accuracy: 0.0665\n",
      "Epoch 121/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.3986 - val_loss: 0.6965 - val_accuracy: 0.0665\n",
      "Epoch 122/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5698 - val_loss: 0.7017 - val_accuracy: 0.0665\n",
      "Epoch 123/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4069 - val_loss: 0.7047 - val_accuracy: 0.0665\n",
      "Epoch 124/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.2685 - val_loss: 0.6907 - val_accuracy: 0.9335\n",
      "Epoch 125/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4232 - val_loss: 0.6944 - val_accuracy: 0.0665\n",
      "Epoch 126/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5158 - val_loss: 0.6957 - val_accuracy: 0.0665\n",
      "Epoch 127/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.3688 - val_loss: 0.6914 - val_accuracy: 0.9335\n",
      "Epoch 128/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4516 - val_loss: 0.6880 - val_accuracy: 0.9335\n",
      "Epoch 129/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.6430 - val_loss: 0.6953 - val_accuracy: 0.0665\n",
      "Epoch 130/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5082 - val_loss: 0.6980 - val_accuracy: 0.0665\n",
      "Epoch 131/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6931 - accuracy: 0.2275 - val_loss: 0.6797 - val_accuracy: 0.9335\n",
      "Epoch 132/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.7724 - val_loss: 0.7026 - val_accuracy: 0.0665\n",
      "Epoch 133/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6933 - accuracy: 0.4887 - val_loss: 0.6711 - val_accuracy: 0.9335\n",
      "Epoch 134/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4538 - val_loss: 0.6973 - val_accuracy: 0.0665\n",
      "Epoch 135/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.3886 - val_loss: 0.6926 - val_accuracy: 0.9335\n",
      "Epoch 136/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.6880 - val_loss: 0.6952 - val_accuracy: 0.0665\n",
      "Epoch 137/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.3816 - val_loss: 0.6886 - val_accuracy: 0.9335\n",
      "Epoch 138/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.7255 - val_loss: 0.6967 - val_accuracy: 0.0665\n",
      "Epoch 139/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.2940 - val_loss: 0.6853 - val_accuracy: 0.9335\n",
      "Epoch 140/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.7270 - val_loss: 0.6996 - val_accuracy: 0.0665\n",
      "Epoch 141/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4878 - val_loss: 0.6987 - val_accuracy: 0.0665\n",
      "Epoch 142/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3551 - val_loss: 0.6929 - val_accuracy: 0.9335\n",
      "Epoch 143/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3188 - val_loss: 0.6941 - val_accuracy: 0.0665\n",
      "Epoch 144/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.7004 - val_accuracy: 0.0665\n",
      "Epoch 145/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.2362 - val_loss: 0.6680 - val_accuracy: 0.9335\n",
      "Epoch 146/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6934 - accuracy: 0.6546 - val_loss: 0.6944 - val_accuracy: 0.0665\n",
      "Epoch 147/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6933 - accuracy: 0.4936 - val_loss: 0.7012 - val_accuracy: 0.0665\n",
      "Epoch 148/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.4366 - val_loss: 0.6941 - val_accuracy: 0.0665\n",
      "Epoch 149/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6890 - val_accuracy: 0.9335\n",
      "Epoch 150/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.2764 - val_loss: 0.6814 - val_accuracy: 0.9335\n",
      "Epoch 151/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6200 - val_loss: 0.6875 - val_accuracy: 0.9335\n",
      "Epoch 152/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5049 - val_loss: 0.6865 - val_accuracy: 0.9335\n",
      "Epoch 153/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5325 - val_loss: 0.6936 - val_accuracy: 0.0665\n",
      "Epoch 154/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.3819 - val_loss: 0.6724 - val_accuracy: 0.9335\n",
      "Epoch 155/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.5788 - val_loss: 0.6811 - val_accuracy: 0.9335\n",
      "Epoch 156/500\n",
      "879/879 [==============================] - 45s 51ms/step - loss: 0.6932 - accuracy: 0.5311 - val_loss: 0.6796 - val_accuracy: 0.9335\n",
      "Epoch 157/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6931 - accuracy: 0.6651 - val_loss: 0.6904 - val_accuracy: 0.9335\n",
      "Epoch 158/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.5030 - val_loss: 0.6916 - val_accuracy: 0.9335\n",
      "Epoch 159/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4050 - val_loss: 0.6946 - val_accuracy: 0.0665\n",
      "Epoch 160/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.6111 - val_loss: 0.7003 - val_accuracy: 0.0665\n",
      "Epoch 161/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.5639 - val_loss: 0.7028 - val_accuracy: 0.0665\n",
      "Epoch 162/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.3207 - val_loss: 0.6932 - val_accuracy: 0.0665\n",
      "Epoch 163/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.4145 - val_loss: 0.6922 - val_accuracy: 0.9335\n",
      "Epoch 164/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.4168 - val_loss: 0.6874 - val_accuracy: 0.9335\n",
      "Epoch 165/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.5467 - val_loss: 0.6958 - val_accuracy: 0.0665\n",
      "Epoch 166/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4036 - val_loss: 0.6982 - val_accuracy: 0.0665\n",
      "Epoch 167/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.4010 - val_loss: 0.6952 - val_accuracy: 0.0665\n",
      "Epoch 168/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.5461 - val_loss: 0.6972 - val_accuracy: 0.0665\n",
      "Epoch 169/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.4230 - val_loss: 0.6948 - val_accuracy: 0.0665\n",
      "Epoch 170/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3154 - val_loss: 0.6924 - val_accuracy: 0.9335\n",
      "Epoch 171/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.5188 - val_loss: 0.6952 - val_accuracy: 0.0665\n",
      "Epoch 172/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.4072 - val_loss: 0.6903 - val_accuracy: 0.9335\n",
      "Epoch 173/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6933 - accuracy: 0.3532 - val_loss: 0.6890 - val_accuracy: 0.9335\n",
      "Epoch 174/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5767 - val_loss: 0.6892 - val_accuracy: 0.9335\n",
      "Epoch 175/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.6065 - val_loss: 0.6937 - val_accuracy: 0.0665\n",
      "Epoch 176/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5326 - val_loss: 0.6996 - val_accuracy: 0.0665\n",
      "Epoch 177/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3235 - val_loss: 0.6877 - val_accuracy: 0.9335\n",
      "Epoch 178/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.6210 - val_loss: 0.6923 - val_accuracy: 0.9335\n",
      "Epoch 179/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3814 - val_loss: 0.6910 - val_accuracy: 0.9335\n",
      "Epoch 180/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.6813 - val_loss: 0.6941 - val_accuracy: 0.0665\n",
      "Epoch 181/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.3816 - val_loss: 0.6940 - val_accuracy: 0.0665\n",
      "Epoch 182/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6570 - val_loss: 0.6998 - val_accuracy: 0.0665\n",
      "Epoch 183/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3699 - val_loss: 0.6958 - val_accuracy: 0.0665\n",
      "Epoch 184/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.1778 - val_loss: 0.6885 - val_accuracy: 0.9335\n",
      "Epoch 185/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6792 - val_loss: 0.6955 - val_accuracy: 0.0665\n",
      "Epoch 186/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.5197 - val_loss: 0.6932 - val_accuracy: 0.0665\n",
      "Epoch 187/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5109 - val_loss: 0.6945 - val_accuracy: 0.0665\n",
      "Epoch 188/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.4160 - val_loss: 0.6891 - val_accuracy: 0.9335\n",
      "Epoch 189/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.7115 - val_loss: 0.7080 - val_accuracy: 0.0665\n",
      "Epoch 190/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.3922 - val_loss: 0.6983 - val_accuracy: 0.0665\n",
      "Epoch 191/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4096 - val_loss: 0.6894 - val_accuracy: 0.9335\n",
      "Epoch 192/500\n",
      "879/879 [==============================] - 45s 51ms/step - loss: 0.6933 - accuracy: 0.6114 - val_loss: 0.6965 - val_accuracy: 0.0665\n",
      "Epoch 193/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4932 - val_loss: 0.6910 - val_accuracy: 0.9335\n",
      "Epoch 194/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.5161 - val_loss: 0.6940 - val_accuracy: 0.0665\n",
      "Epoch 195/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.6812 - val_loss: 0.6975 - val_accuracy: 0.0665\n",
      "Epoch 196/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.4467 - val_loss: 0.6931 - val_accuracy: 0.9335\n",
      "Epoch 197/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.7295 - val_loss: 0.6938 - val_accuracy: 0.0665\n",
      "Epoch 198/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4277 - val_loss: 0.6909 - val_accuracy: 0.9335\n",
      "Epoch 199/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6933 - accuracy: 0.6216 - val_loss: 0.6974 - val_accuracy: 0.0665\n",
      "Epoch 200/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.2170 - val_loss: 0.6955 - val_accuracy: 0.0665\n",
      "Epoch 201/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6933 - accuracy: 0.5504 - val_loss: 0.6903 - val_accuracy: 0.9335\n",
      "Epoch 202/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.4362 - val_loss: 0.6852 - val_accuracy: 0.9335\n",
      "Epoch 203/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6933 - accuracy: 0.7302 - val_loss: 0.6915 - val_accuracy: 0.9335\n",
      "Epoch 204/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.5110 - val_loss: 0.6915 - val_accuracy: 0.9335\n",
      "Epoch 205/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.5654 - val_loss: 0.6922 - val_accuracy: 0.9335\n",
      "Epoch 206/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.5785 - val_loss: 0.6932 - val_accuracy: 0.0665\n",
      "Epoch 207/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4172 - val_loss: 0.6949 - val_accuracy: 0.0665\n",
      "Epoch 208/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4078 - val_loss: 0.6891 - val_accuracy: 0.9335\n",
      "Epoch 209/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6585 - val_loss: 0.6966 - val_accuracy: 0.0665\n",
      "Epoch 210/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.2435 - val_loss: 0.6882 - val_accuracy: 0.9335\n",
      "Epoch 211/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.7892 - val_loss: 0.6998 - val_accuracy: 0.0665\n",
      "Epoch 212/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.2896 - val_loss: 0.6956 - val_accuracy: 0.0665\n",
      "Epoch 213/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.5536 - val_loss: 0.7063 - val_accuracy: 0.0665\n",
      "Epoch 214/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.3070 - val_loss: 0.6933 - val_accuracy: 0.0665\n",
      "Epoch 215/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.5627 - val_loss: 0.6927 - val_accuracy: 0.9335\n",
      "Epoch 216/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.5111 - val_loss: 0.6927 - val_accuracy: 0.9335\n",
      "Epoch 217/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6879 - val_accuracy: 0.9335\n",
      "Epoch 218/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.6250 - val_loss: 0.7073 - val_accuracy: 0.0665\n",
      "Epoch 219/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.5151 - val_loss: 0.6981 - val_accuracy: 0.0665\n",
      "Epoch 220/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6069 - val_loss: 0.7027 - val_accuracy: 0.0665\n",
      "Epoch 221/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5569 - val_loss: 0.7110 - val_accuracy: 0.0665\n",
      "Epoch 222/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6933 - accuracy: 0.3986 - val_loss: 0.6933 - val_accuracy: 0.0665\n",
      "Epoch 223/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.6523 - val_loss: 0.7006 - val_accuracy: 0.0665\n",
      "Epoch 224/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6933 - accuracy: 0.4808 - val_loss: 0.6933 - val_accuracy: 0.0665\n",
      "Epoch 225/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6934 - accuracy: 0.7016 - val_loss: 0.7007 - val_accuracy: 0.0665\n",
      "Epoch 226/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4041 - val_loss: 0.6953 - val_accuracy: 0.0665\n",
      "Epoch 227/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.3672 - val_loss: 0.6817 - val_accuracy: 0.9335\n",
      "Epoch 228/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6934 - accuracy: 0.4482 - val_loss: 0.6877 - val_accuracy: 0.9335\n",
      "Epoch 229/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3850 - val_loss: 0.6922 - val_accuracy: 0.9335\n",
      "Epoch 230/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.5432 - val_loss: 0.6931 - val_accuracy: 0.9335\n",
      "Epoch 231/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.2820 - val_loss: 0.6927 - val_accuracy: 0.9335\n",
      "Epoch 232/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.7002 - val_loss: 0.6958 - val_accuracy: 0.0665\n",
      "Epoch 233/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.3731 - val_loss: 0.6942 - val_accuracy: 0.0665\n",
      "Epoch 234/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4796 - val_loss: 0.6956 - val_accuracy: 0.0665\n",
      "Epoch 235/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4775 - val_loss: 0.6844 - val_accuracy: 0.9335\n",
      "Epoch 236/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.8024 - val_loss: 0.6998 - val_accuracy: 0.0665\n",
      "Epoch 237/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.4803 - val_loss: 0.6969 - val_accuracy: 0.0665\n",
      "Epoch 238/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.3395 - val_loss: 0.6860 - val_accuracy: 0.9335\n",
      "Epoch 239/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.5444 - val_loss: 0.6937 - val_accuracy: 0.0665\n",
      "Epoch 240/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6146 - val_loss: 0.7100 - val_accuracy: 0.0665\n",
      "Epoch 241/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.4609 - val_loss: 0.6951 - val_accuracy: 0.0665\n",
      "Epoch 242/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.5313 - val_loss: 0.6962 - val_accuracy: 0.0665\n",
      "Epoch 243/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.4640 - val_loss: 0.6975 - val_accuracy: 0.0665\n",
      "Epoch 244/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.2885 - val_loss: 0.6911 - val_accuracy: 0.9335\n",
      "Epoch 245/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.4975 - val_loss: 0.6975 - val_accuracy: 0.0665\n",
      "Epoch 246/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6934 - accuracy: 0.4556 - val_loss: 0.6863 - val_accuracy: 0.9335\n",
      "Epoch 247/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6901 - val_accuracy: 0.9335\n",
      "Epoch 248/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6934 - accuracy: 0.5151 - val_loss: 0.6973 - val_accuracy: 0.0665\n",
      "Epoch 249/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.5124 - val_loss: 0.7018 - val_accuracy: 0.0665\n",
      "Epoch 250/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6933 - accuracy: 0.3711 - val_loss: 0.6968 - val_accuracy: 0.0665\n",
      "Epoch 251/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3799 - val_loss: 0.6963 - val_accuracy: 0.0665\n",
      "Epoch 252/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.4764 - val_loss: 0.6966 - val_accuracy: 0.0665\n",
      "Epoch 253/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3368 - val_loss: 0.6964 - val_accuracy: 0.0665\n",
      "Epoch 254/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6933 - accuracy: 0.4174 - val_loss: 0.6958 - val_accuracy: 0.0665\n",
      "Epoch 255/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.6526 - val_loss: 0.7041 - val_accuracy: 0.0665\n",
      "Epoch 256/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.1971 - val_loss: 0.6855 - val_accuracy: 0.9335\n",
      "Epoch 257/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.6506 - val_loss: 0.7023 - val_accuracy: 0.0665\n",
      "Epoch 258/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4138 - val_loss: 0.6877 - val_accuracy: 0.9335\n",
      "Epoch 259/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.6780 - val_loss: 0.6919 - val_accuracy: 0.9335\n",
      "Epoch 260/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.4202 - val_loss: 0.6907 - val_accuracy: 0.9335\n",
      "Epoch 261/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4448 - val_loss: 0.6914 - val_accuracy: 0.9335\n",
      "Epoch 262/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.5373 - val_loss: 0.6896 - val_accuracy: 0.9335\n",
      "Epoch 263/500\n",
      "879/879 [==============================] - 45s 51ms/step - loss: 0.6933 - accuracy: 0.5711 - val_loss: 0.6920 - val_accuracy: 0.9335\n",
      "Epoch 264/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.3493 - val_loss: 0.6921 - val_accuracy: 0.9335\n",
      "Epoch 265/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6933 - accuracy: 0.6751 - val_loss: 0.6924 - val_accuracy: 0.9335\n",
      "Epoch 266/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.2751 - val_loss: 0.6882 - val_accuracy: 0.9335\n",
      "Epoch 267/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.4019 - val_loss: 0.6837 - val_accuracy: 0.9335\n",
      "Epoch 268/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.6433 - val_loss: 0.6930 - val_accuracy: 0.9335\n",
      "Epoch 269/500\n",
      "879/879 [==============================] - 45s 51ms/step - loss: 0.6932 - accuracy: 0.5796 - val_loss: 0.6928 - val_accuracy: 0.9335\n",
      "Epoch 270/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.5364 - val_loss: 0.6915 - val_accuracy: 0.9335\n",
      "Epoch 271/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5145 - val_loss: 0.6920 - val_accuracy: 0.9335\n",
      "Epoch 272/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6933 - accuracy: 0.5410 - val_loss: 0.6908 - val_accuracy: 0.9335\n",
      "Epoch 273/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.7358 - val_loss: 0.6988 - val_accuracy: 0.0665\n",
      "Epoch 274/500\n",
      "879/879 [==============================] - 45s 51ms/step - loss: 0.6932 - accuracy: 0.2288 - val_loss: 0.6905 - val_accuracy: 0.9335\n",
      "Epoch 275/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6933 - accuracy: 0.5023 - val_loss: 0.6917 - val_accuracy: 0.9335\n",
      "Epoch 276/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5118 - val_loss: 0.6945 - val_accuracy: 0.0665\n",
      "Epoch 277/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.3841 - val_loss: 0.6979 - val_accuracy: 0.0665\n",
      "Epoch 278/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.3719 - val_loss: 0.6910 - val_accuracy: 0.9335\n",
      "Epoch 279/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5979 - val_loss: 0.6909 - val_accuracy: 0.9335\n",
      "Epoch 280/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5859 - val_loss: 0.6957 - val_accuracy: 0.0665\n",
      "Epoch 281/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.3061 - val_loss: 0.6935 - val_accuracy: 0.0665\n",
      "Epoch 282/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6931 - accuracy: 0.4545 - val_loss: 0.6977 - val_accuracy: 0.0665\n",
      "Epoch 283/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.3607 - val_loss: 0.6865 - val_accuracy: 0.9335\n",
      "Epoch 284/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.6040 - val_loss: 0.6944 - val_accuracy: 0.0665\n",
      "Epoch 285/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6931 - accuracy: 0.3445 - val_loss: 0.6920 - val_accuracy: 0.9335\n",
      "Epoch 286/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6934 - accuracy: 0.4767 - val_loss: 0.6945 - val_accuracy: 0.0665\n",
      "Epoch 287/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.4329 - val_loss: 0.6948 - val_accuracy: 0.0665\n",
      "Epoch 288/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6933 - accuracy: 0.4052 - val_loss: 0.6941 - val_accuracy: 0.0665\n",
      "Epoch 289/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.5261 - val_loss: 0.6948 - val_accuracy: 0.0665\n",
      "Epoch 290/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.3709 - val_loss: 0.6945 - val_accuracy: 0.0665\n",
      "Epoch 291/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.4687 - val_loss: 0.6942 - val_accuracy: 0.0665\n",
      "Epoch 292/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5294 - val_loss: 0.7067 - val_accuracy: 0.0665\n",
      "Epoch 293/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.5143 - val_loss: 0.7044 - val_accuracy: 0.0665\n",
      "Epoch 294/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.2892 - val_loss: 0.6942 - val_accuracy: 0.0665\n",
      "Epoch 295/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.6075 - val_loss: 0.6982 - val_accuracy: 0.0665\n",
      "Epoch 296/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.5984 - val_loss: 0.7002 - val_accuracy: 0.0665\n",
      "Epoch 297/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3662 - val_loss: 0.6963 - val_accuracy: 0.0665\n",
      "Epoch 298/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3425 - val_loss: 0.6934 - val_accuracy: 0.0665\n",
      "Epoch 299/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.6619 - val_loss: 0.6984 - val_accuracy: 0.0665\n",
      "Epoch 300/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5178 - val_loss: 0.6965 - val_accuracy: 0.0665\n",
      "Epoch 301/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6933 - accuracy: 0.4367 - val_loss: 0.6964 - val_accuracy: 0.0665\n",
      "Epoch 302/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.4657 - val_loss: 0.6972 - val_accuracy: 0.0665\n",
      "Epoch 303/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.2603 - val_loss: 0.6882 - val_accuracy: 0.9335\n",
      "Epoch 304/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.5249 - val_loss: 0.6938 - val_accuracy: 0.0665\n",
      "Epoch 305/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.4061 - val_loss: 0.6913 - val_accuracy: 0.9335\n",
      "Epoch 306/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.5859 - val_loss: 0.6921 - val_accuracy: 0.9335\n",
      "Epoch 307/500\n",
      "879/879 [==============================] - 42s 48ms/step - loss: 0.6932 - accuracy: 0.4592 - val_loss: 0.6763 - val_accuracy: 0.9335\n",
      "Epoch 308/500\n",
      "879/879 [==============================] - 44s 50ms/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6962 - val_accuracy: 0.0665\n",
      "Epoch 309/500\n",
      "879/879 [==============================] - 44s 51ms/step - loss: 0.6932 - accuracy: 0.3515 - val_loss: 0.6839 - val_accuracy: 0.9335\n",
      "Epoch 310/500\n",
      "879/879 [==============================] - 43s 48ms/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6889 - val_accuracy: 0.9335\n",
      "Epoch 311/500\n",
      "879/879 [==============================] - 45s 51ms/step - loss: 0.6933 - accuracy: 0.5967 - val_loss: 0.6913 - val_accuracy: 0.9335\n",
      "Epoch 312/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6933 - accuracy: 0.3541 - val_loss: 0.6942 - val_accuracy: 0.0665\n",
      "Epoch 313/500\n",
      "879/879 [==============================] - 43s 49ms/step - loss: 0.6932 - accuracy: 0.3072 - val_loss: 0.6939 - val_accuracy: 0.0665\n",
      "Epoch 314/500\n",
      "662/879 [=====================>........] - ETA: 10s - loss: 0.6906 - accuracy: 0.7494"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m model\u001b[39m.\u001b[39madd(K\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     19\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mK\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(lr\u001b[39m=\u001b[39m\u001b[39m2e-4\u001b[39m),\n\u001b[1;32m     20\u001b[0m                 loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mbinary_crossentropy,\n\u001b[1;32m     21\u001b[0m                 metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> 22\u001b[0m histo\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     23\u001b[0m     x_train,y_train,\n\u001b[1;32m     24\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(x_val,y_val),\n\u001b[1;32m     25\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[1;32m     26\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[model_checkpoint_callback],\n\u001b[1;32m     27\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     28\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39m../../model/full/MobileNetV3.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint_filepath = \"../../model/full/MobileNetV3_checkpoints.h5\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only= True\n",
    ")\n",
    "class_weight_ratio=compute_class_weight(class_weight = \"balanced\" , \n",
    "                     classes=np.unique(y_train), \n",
    "                     y = y_train)\n",
    "class_weight = {0:class_weight_ratio[0],1:class_weight_ratio[1]}\n",
    "\n",
    "input_t=K.Input(shape=(size,size, 3))\n",
    "input_tensor = layers.experimental.preprocessing.Resizing(size, size, interpolation=\"bilinear\", input_shape=x_train.shape[1:])(input_t)\n",
    "ResNet=K.applications.MobileNetV3Large(include_top=True,weights='imagenet',input_tensor=input_tensor)\n",
    "model = K.models.Sequential()\n",
    "model.add(ResNet)\n",
    "model.add(tf.keras.layers.Dropout(.2, input_shape=(64,)))\n",
    "model.add(K.layers.Dense(64, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "model.add(K.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=K.optimizers.Adam(lr=2e-4),\n",
    "                loss=tf.keras.losses.binary_crossentropy,\n",
    "                metrics=[\"accuracy\"])\n",
    "histo=model.fit(\n",
    "    x_train,y_train,\n",
    "    validation_data=(x_val,y_val),\n",
    "    epochs=500,\n",
    "    callbacks=[model_checkpoint_callback],\n",
    "    batch_size=32,shuffle=True,\n",
    "    class_weight=class_weight\n",
    ")\n",
    "model.save('../../model/full/MobileNetV3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
