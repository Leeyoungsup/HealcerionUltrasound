{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.losses import *\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import numpy.random as npr\n",
    "import os, time, gc, random\n",
    "import glob\n",
    "import PIL\n",
    "from keras.initializers import he_normal\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    concatenate,\n",
    "    Lambda\n",
    ")\n",
    "from keras.layers.convolutional import (\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D,\n",
    "    ZeroPadding2D\n",
    ")\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import sys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blocks used in GAN\n",
    "\n",
    "def minibatchStd(inputs):\n",
    "    inputs = tf.transpose(inputs, (0, 3, 1, 2)) # NHWC -> NCHW\n",
    "    group_size = tf.minimum(4, tf.shape(inputs)[0])             # Minibatch must be divisible by (or smaller than) group_size.\n",
    "    s = inputs.shape                                             # [NCHW]  Input shape.\n",
    "    y = tf.reshape(inputs, [group_size, -1, 1, s[1], s[2], s[3]])   # [GMncHW] Split minibatch into M groups of size G. Split channels into n channel groups c.\n",
    "    y -= tf.reduce_mean(y, axis=0, keepdims=True)           # [GMncHW] Subtract mean over group.\n",
    "    y = tf.reduce_mean(tf.square(y), axis=0)                # [MncHW]  Calc variance over group.\n",
    "    y = tf.sqrt(y + eps)                                    # [MncHW]  Calc stddev over group.\n",
    "    y = tf.reduce_mean(y, axis=[2,3,4], keepdims=True)      # [Mn111]  Take average over fmaps and pixels.\n",
    "    y = tf.reduce_mean(y, axis=[2])                         # [Mn11] Split channels into c channel groups\n",
    "    y = tf.tile(y, [group_size, 1, s[2], s[3]])             # [NnHW]  Replicate over group and pixels.\n",
    "    y = tf.concat([inputs, y], axis=1)                        # [NCHW]  Append as new fmap.\n",
    "    y = tf.transpose(y, (0, 2, 3, 1)) # NCHW -> NHWC\n",
    "    return y\n",
    "\n",
    "class DiffUS(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        return super().__init__()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        _N, H, W, C = inputs.shape.as_list()\n",
    "        x = K.reshape(inputs, (-1, H, 1, W, 1, C))\n",
    "        x = tf.tile(x, (1, 1, 2, 1, 2, 1))\n",
    "        used = K.reshape(x, (-1, H * 2, W * 2, C))\n",
    "        return used\n",
    "\n",
    "def crop_to_fit(x):\n",
    "    noise, img = x\n",
    "    height = img.shape[1]\n",
    "    width = img.shape[2]\n",
    "    \n",
    "    return noise[:, :height, :width, :]\n",
    "\n",
    "ndist = tf.random_normal_initializer(0, 1)\n",
    "zeros = tf.zeros_initializer()\n",
    "ones = tf.ones_initializer()\n",
    "\n",
    "class FCE(Dense): # fully connected equalized\n",
    "    def __init__(self, units, kernel_initializer=ndist, bias_initializer=zeros, lrelu=True, *args, **kwargs):\n",
    "        super().__init__(units, *args, **kwargs)\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.lrelu = lrelu\n",
    "        self.scale = 1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        #print('fce', input_shape)\n",
    "        n = input_shape[-1] # input_shape = (None, features_in) or (None, dimY, dimX, features_in)\n",
    "        if self.lrelu:\n",
    "            self.scale = np.sqrt((1 / 0.6) / n) # he but not really, 1 / 0.6 since lrelu(0.2) makes scales variance to 0.6 (0.2 if neg, 1 if pos, div by 2) and you want them to be 1\n",
    "        else:\n",
    "            self.scale = np.sqrt(1 / n)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = K.dot(inputs, self.kernel * self.scale)\n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias)\n",
    "        if self.activation is not tf.keras.activations.linear:\n",
    "            output = self.activation(output)\n",
    "        elif self.lrelu:\n",
    "            output = LeakyReLU(alpha=0.2)(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'kInit': self.kernel_initializer,\n",
    "            'bInit': self.bias_initializer,\n",
    "            'scale': self.scale,\n",
    "            'useLReLU': self.lrelu,\n",
    "                      })\n",
    "        return config\n",
    "\n",
    "class CVE(Conv2D):\n",
    "    def __init__(self, units, kernel_size=3, kernel_initializer=ndist, bias_initializer=zeros, padding='same', lrelu=True, *args, **kwargs):\n",
    "        super().__init__(units, kernel_size, *args, **kwargs)\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.padding = padding\n",
    "        self.lrelu = lrelu\n",
    "        self.scale = 1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        #print('cve', self.kernel.shape)\n",
    "        n = np.prod(self.kernel.shape[:-1]) # self.kernel.shape = (kernel_x, kernel_y, features_in, features_out)\n",
    "        if self.lrelu: # he\n",
    "            self.scale = np.sqrt((1 / 0.6) / n)\n",
    "        else:\n",
    "            self.scale = np.sqrt(1 / n)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = K.conv2d(inputs, self.kernel * self.scale, padding=self.padding)\n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias)\n",
    "        if self.activation is not tf.keras.activations.linear:\n",
    "            output = self.activation(output)\n",
    "        elif self.lrelu:\n",
    "            output = LeakyReLU(alpha=0.2)(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'kInit': self.kernel_initializer,\n",
    "            'bInit': self.bias_initializer,\n",
    "            'padding': self.padding,\n",
    "            'scale': self.scale,\n",
    "            'useLReLU': self.lrelu,\n",
    "                      })\n",
    "        return config\n",
    "\n",
    "class ConvMod(Layer):\n",
    "    def __init__(self, nf, x, w, kSize=3, demod=True):\n",
    "        super().__init__()\n",
    "        self.nf = nf\n",
    "        self.kSize = kSize\n",
    "        self.xShape = x.shape\n",
    "        self.wShape = w.shape\n",
    "        self.scale = FCE(self.xShape[-1], bias_initializer=ones, lrelu=False)\n",
    "        self.conv = CVE(nf, kSize, lrelu=demod)\n",
    "        self.conv(x) # create kernel without doing it in build method so h5py doesn't go sicko mode\n",
    "        self.demod = demod\n",
    "\n",
    "    def build(self, input_shape): # input_shape: [TensorShape([None, 4, 4, 256]), TensorShape([None, 256]), TensorShape([None, 4, 4, 1])]\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, w = inputs\n",
    "\n",
    "        x = tf.transpose(x, (0, 3, 1, 2)) # NHWC -> NCHW\n",
    "        weight = self.conv.kernel[np.newaxis] * self.conv.scale # kkio -> 1kkio (1, kernel_size, kernel_size, input_features, output_features)\n",
    "\n",
    "        scale = self.scale(w)\n",
    "        scale = scale[:, np.newaxis, np.newaxis, :, np.newaxis] # Bs -> B, 1, 1, s, 1 (s - scaling factor)\n",
    "\n",
    "        wp = weight * scale # 1kkio * B11s1 -> Bkk(s*i)o\n",
    "        wpp = wp\n",
    "\n",
    "        if self.demod:\n",
    "            wStd = tf.math.rsqrt(tf.reduce_sum(tf.math.square(wp), axis=[1,2,3]) + 1e-8) # Bkkio -> Bo\n",
    "            wpp = wp * wStd[:, np.newaxis, np.newaxis, np.newaxis, :] # [BkkIO] Scale output feature maps.\n",
    "\n",
    "        x = tf.reshape(x, (1, -1, x.shape[2], x.shape[3])) # N, C, H, W -> 1, (N*C), H, W\n",
    "\n",
    "        # B, k, k, i, o -> k, k, i, B, o -> k, k, i, (B*o)\n",
    "        wpp = tf.reshape(tf.transpose(wpp, [1, 2, 3, 0, 4]), [wpp.shape[1], wpp.shape[2], wpp.shape[3], -1])\n",
    "\n",
    "        x = tf.nn.conv2d(x, wpp, padding='SAME', data_format='NCHW', strides=[1, 1, 1, 1]) # grouped conv\n",
    "        x = tf.reshape(x, (-1, self.nf, x.shape[2], x.shape[3])) # 1, (N*C), H, W -> N, C, H, W\n",
    "        x = tf.transpose(x, (0, 2, 3, 1)) # NCHW -> NHWC\n",
    "        x = K.bias_add(x, self.conv.bias)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'num_filters': self.nf,\n",
    "            'kernel_size': self.kSize,\n",
    "            'xShape': self.xShape,\n",
    "            'wShape': self.wShape,\n",
    "            'demodulated': self.demod\n",
    "                      })\n",
    "        return config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TimeIt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom class to see how long tasks take\n",
    "class timeIt:\n",
    "    def __init__(self, description):\n",
    "        self.start = time.time()\n",
    "        self.description = description\n",
    "        self.running = True\n",
    "    \n",
    "    def new(self, description, verbose=True):\n",
    "        self.start = time.time()\n",
    "        self.description = description\n",
    "        \n",
    "        duration = time.time() - startTime\n",
    "        if verbose:\n",
    "            print('{}; {:.4f} seconds to complete'.format(self.description, duration))\n",
    "        \n",
    "        return duration\n",
    "    \n",
    "    def close(self, verbose=True):\n",
    "        duration = time.time() - self.start\n",
    "        if verbose:\n",
    "            print('{}; {:.4f} seconds to complete'.format(self.description, duration))\n",
    "            \n",
    "        self.start = None\n",
    "        self.description = None\n",
    "        self.running = False\n",
    "        return duration\n",
    "\n",
    "sess = timeIt('testing timer')\n",
    "time.sleep(0.005)\n",
    "_ = sess.close(verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reals - numpy array of the training images; ds - batched TF dataset given to the GPU\n",
    "datasetPath = '../../data/standardFrame_data/scale_skip/style/standard/*.jpg'\n",
    "modelPath = '../../model/styleGAN/'\n",
    "reals, ds = None, None\n",
    "gc.collect()\n",
    "\n",
    "batchSize = 16\n",
    "m = 10000 # amount of images stored in RAM (reduce if low RAM, increase if high RAM)\n",
    "m = min(m, int(len(glob.glob(datasetPath))))\n",
    "m1=m\n",
    "m = batchSize * (m // batchSize)\n",
    "imgSize = 256# size of images in pixels\n",
    "zdim = imgSize # number of elements in a latent vector\n",
    "p = 0.0 # probability of data augmentation\n",
    "n = 4 # number of minibatches before p is changed\n",
    "numImgsStep =5e5 # number of images needed to change p from 0 -> 1 or 1 -> 0\n",
    "pStep = n * batchSize / numImgsStep # how much p increases/decreases per n minibatches\n",
    "eps = 1e-8 # epsilon, small number used to prevent NaN errors\n",
    "pplEMA = 0.0 # exponential moving average for average PPL for PPL reg.\n",
    "depth=8\n",
    "teps=3\n",
    "Gen_layerFilters = (256, 256, 256, 128, 64,32)\n",
    "Dis_layerFilters = (32, 64, 128,256, 256, 256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "'''\n",
    "goes into datasetPath, chooses and stores image data from random files (repeats allowed)\n",
    "into a np array, converts the array into the TF dataset\n",
    "\n",
    "Args:\n",
    "others - random indices for files to choose to train the GAN on\n",
    "verbose - determines whether duration to complete is printed out or not\n",
    "'''\n",
    "def loadData(others=None, verbose=True):\n",
    "    global reals, ds, m\n",
    "    sess = timeIt('Loading data')\n",
    "    reals, ds = None, None\n",
    "    gc.collect()\n",
    "    files = glob.glob(datasetPath)\n",
    "    \n",
    "    reals = np.zeros((len(files), imgSize, imgSize,1))\n",
    "    for i in range(len(files)):\n",
    "        strI = str(files[i])\n",
    "        img1=PIL.Image.open(strI).convert(\"L\")\n",
    "        # if(img1.size[0]>=img1.size[1]):\n",
    "        #     ratio=imgSize/img1.size[0]\n",
    "        # else:\n",
    "        #     ratio=imgSize/img1.size[1]\n",
    "        # width=ratio*img1.size[0]\n",
    "        # height=ratio*img1.size[1]\n",
    "        # height_padding_size=int((imgSize-int(height))/2)\n",
    "        # width_padding_size=int((imgSize-int(width))/2)\n",
    "        # img1=np.array(img1.resize((int(width),int(height))))\n",
    "        # reals[i,height_padding_size:height_padding_size+int(height),width_padding_size:width_padding_size+int(width)] = img1\n",
    "        img1=np.array(img1.resize((int(imgSize),int(imgSize))))\n",
    "        reals[i] = img1.reshape((int(imgSize),int(imgSize),1))\n",
    "        del img1\n",
    "    \n",
    "    reals = reals[:m].astype(np.float32)/127.5-1.0\n",
    "\n",
    "    assert reals.shape[0] % batchSize == 0\n",
    "    assert type(reals) == np.ndarray\n",
    "    ds = (tf.data.Dataset.from_tensor_slices(reals).shuffle(3000).batch(batchSize))\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    gc.collect()\n",
    "    sess.close(verbose=verbose)\n",
    "    \n",
    "def aug(imgs, p):\n",
    "    augImgs = imgs\n",
    "    def augCond(x):\n",
    "        randInds = tf.random.uniform((batchSize,))\n",
    "        trueCond = tf.cast(randInds < p, tf.float32) # using tf.cast to turn booleans into ones and zeros\n",
    "        falseCond = tf.cast(randInds >= p, tf.float32)\n",
    "        auged = x * tf.reshape(trueCond, (batchSize, 1, 1, 1)) + augImgs * tf.reshape(falseCond, (batchSize, 1, 1, 1))\n",
    "        return auged\n",
    "    \n",
    "    height = tf.random.uniform((), minval=0.5, maxval=1)\n",
    "    width = tf.random.uniform((), minval=0.5, maxval=1)\n",
    "    boxLite = tf.random.uniform((batchSize, 2), maxval=(1-height, 1-width))\n",
    "    boxes = tf.concat([boxLite, tf.transpose(boxLite[:, 0][np.newaxis]) + height, tf.transpose(boxLite[:, 1][np.newaxis]) + width], axis=1)\n",
    "    boxLiteIso = tf.random.uniform((batchSize, 1), maxval=1-height)\n",
    "    boxIso = tf.concat([boxLite, tf.transpose(boxLiteIso[:, 0][np.newaxis]) + height, tf.transpose(boxLiteIso[:, 0][np.newaxis]) + height], axis=1)\n",
    "    rot90s = np.pi * 90 * tf.cast(tf.random.uniform((batchSize,), minval=0, maxval=4, dtype=tf.int32), tf.float32) / 180\n",
    "    augImgs = augCond(tf.image.random_brightness(augImgs, max_delta=0.25))\n",
    "    augImgs = augCond(tf.image.crop_and_resize(augImgs, boxIso, tf.range(batchSize), (imgSize, imgSize), extrapolation_value=1))\n",
    "    augImgs = augCond(tf.image.crop_and_resize(augImgs, boxes, tf.range(batchSize), (imgSize, imgSize), extrapolation_value=1))\n",
    "    augImgs = augCond(tfa.image.rotate(augImgs, rot90s))\n",
    "    augImgs = augCond(tfa.image.rotate(augImgs, tf.random.uniform((batchSize,), minval=-np.pi/6, maxval=np.pi/6)))\n",
    "    augImgs = augCond(tfa.image.translate(augImgs, tf.random.normal((batchSize, 2), 0, imgSize // 10)))\n",
    "    return augImgs\n",
    "loadData()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generator style block.\n",
    "Args:\n",
    "accum - accumulated output from the input/output skips\n",
    "x - the non-RGB image input\n",
    "w - the style (output of the mapping function with input of the latent vector)\n",
    "noiseInp - normally distributed noise\n",
    "filters - number of channels/feature maps the output of the style block will have\n",
    "us - whether or not to upsample the images\n",
    "'''\n",
    "def gblock(accum, x, w, noiseInp, filters, us=True):\n",
    "    if us:\n",
    "        x = DiffUS()(x) # using custom upsampling function since other upsampling methods didn't provide gradients of their gradients\n",
    "        accum = DiffUS()(accum)\n",
    "    \n",
    "    for i in range(2):\n",
    "        x = ConvMod(filters, x, w)([x, w])\n",
    "        noise = Lambda(crop_to_fit)([noiseInp, x]) # crop noises so it can be added with x\n",
    "        noise = FCE(filters, kernel_initializer=zeros, use_bias=False, lrelu=False)(noise) #scale noises\n",
    "        x = Add()([x, noise])\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    trgb = ConvMod(1, x, w, 1, demod=False)([x, w]) # toRGB 1x1 convolution\n",
    "    accum = Add()([accum, trgb]) * np.sqrt(1 / 2) # the sqrt(1/2) not included in original StyleGAN2 but i didn't see why not\n",
    "        \n",
    "    return accum, x\n",
    "\n",
    "# Discriminator block.\n",
    "def dblock(x, filters, maxFilters=256):\n",
    "    frgb = CVE(min(2 * filters, maxFilters), 1, lrelu=False, use_bias=False)(x)\n",
    "    \n",
    "    x = CVE(filters)(x)\n",
    "    x = CVE(min(2 * filters, maxFilters))(x)\n",
    "        \n",
    "    frgb = AveragePooling2D()(frgb)\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Add()([x, frgb])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBlocks = int(np.log2(imgSize / 4)) # number of upsampled style blocks\n",
    "def inception_v3(imgSize):\n",
    "    inp = Input((imgSize, imgSize, 1)); x = tf.image.grayscale_to_rgb(inp)\n",
    "    x =tf.keras.applications.InceptionV3(include_top=False, pooling='avg', input_shape=(imgSize, imgSize, 3))(x)\n",
    "    return Model(inp,x)\n",
    "# mapper architecture\n",
    "def ztow(nlayers=8):\n",
    "    z = Input((zdim,))\n",
    "    w = z\n",
    "    if nlayers > 0:\n",
    "        w = LayerNormalization()(w)\n",
    "    for i in range(max(nlayers-1, 0)):\n",
    "        w = FCE(zdim)(w)\n",
    "    return Model(z, w, name='mapping')\n",
    "\n",
    "# generator architecture\n",
    "def genGen():\n",
    "    ws = [Input((zdim,), name='w{}'.format(i)) for i in range(nBlocks+1)]\n",
    "    noiseInp = Input((imgSize, imgSize, 1), name='noiseInp')\n",
    "\n",
    "    x = Dense(1)(ws[0]); x = Lambda(lambda x: x * 0 + 1)(x)\n",
    "    x = FCE(4*4*zdim, lrelu=False, use_bias=False)(x)\n",
    "    x = Reshape((4, 4, zdim))(x)\n",
    "\n",
    "    layerFilters = Gen_layerFilters\n",
    "\n",
    "    x = ConvMod(layerFilters[0], x, ws[0])([x, ws[0]])\n",
    "    noise = Lambda(crop_to_fit)([noiseInp, x])\n",
    "    noise = FCE(layerFilters[0], kernel_initializer=zeros, use_bias=False, lrelu=False)(noise)\n",
    "    x = Add()([x, noise])\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    accum = ConvMod(1, x, ws[0], 1, demod=False)([x, ws[0]])  # 출력 채널 수를 1로 변경\n",
    "\n",
    "    for idx, f in enumerate(layerFilters):\n",
    "        accum, x = gblock(accum, x, ws[idx+1], noiseInp, f)\n",
    "\n",
    "    out = CVE(1, 1, lrelu=False)(accum)  # 출력 채널 수를 1로 변경\n",
    "    return tf.keras.Model([*ws, noiseInp], out, name='generator')\n",
    "\n",
    "# discriminator architecture\n",
    "def genDisc():\n",
    "    inp = Input((imgSize, imgSize, 1))  # 입력 채널 수를 1로 변경\n",
    "    x = inp\n",
    "\n",
    "    layerFilters = Dis_layerFilters\n",
    "\n",
    "    x = CVE(layerFilters[0], 1)(x)  # 출력 채널 수를 1로 변경\n",
    "    for fi, f in enumerate(layerFilters):\n",
    "        x = dblock(x, f, maxFilters=layerFilters[-1])\n",
    "\n",
    "    x = Lambda(minibatchStd)(x)\n",
    "    x = CVE(layerFilters[-1])(x)  # 출력 채널 수를 1로 변경\n",
    "    x = Flatten()(x)\n",
    "    x = FCE(layerFilters[-1])(x)\n",
    "    out = FCE(1, lrelu=False)(x)\n",
    "\n",
    "    return tf.keras.Model(inp, out, name='discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fids, gcosts, dcosts = [], [], []\n",
    "pplNorms = []\n",
    "gpcosts = []\n",
    "ps, rts = [], []\n",
    "\n",
    "mapper = ztow(nlayers=depth)\n",
    "generator = genGen()\n",
    "discriminator = genDisc()\n",
    "inception = inception_v3(imgSize)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizers and losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-3* batchSize / 32\n",
    "mapOpt = Adam(lr / 100, epsilon=1e-10)\n",
    "genOpt = Adam(lr, 0.9, 0.999, epsilon=1e-10)\n",
    "discOpt = Adam(lr, 0.9, 0.999, epsilon=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rt(truePreds): # overfitting metric\n",
    "    return tf.reduce_mean(tf.sign(truePreds))\n",
    "\n",
    "def dra(obsPreds, basePreds): # observe/baseline predictions (representing fake/true data)\n",
    "    meanBase = K.mean(basePreds)\n",
    "    return tf.nn.sigmoid(obsPreds - meanBase)\n",
    "\n",
    "def discLoss(truePreds, fakePreds, epsilon=eps):\n",
    "    trueLoss = K.mean(tf.nn.softplus(-truePreds)) # -log(sigmoid(real_scores_out))\n",
    "    fakeLoss = K.mean(tf.nn.softplus(fakePreds)) # -log(1-sigmoid(fake_scores_out))\n",
    "    classLoss = trueLoss + fakeLoss\n",
    "    return classLoss\n",
    "\n",
    "def genLoss(fakePreds, epsilon=eps):\n",
    "    classLoss = K.mean(tf.nn.softplus(-fakePreds))\n",
    "    return classLoss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path length reg.\n",
    "@tf.function\n",
    "def pplReg(a=0.0):\n",
    "    pplbatchSize = batchSize // 2\n",
    "    y = tf.random.normal((pplbatchSize, imgSize, imgSize, 3))\n",
    "    noise = tf.random.uniform((pplbatchSize, imgSize, imgSize, 1))\n",
    "    z = tf.random.normal((pplbatchSize, zdim))\n",
    "    \n",
    "    w = mapper(z, training=True)\n",
    "    ws = [w for _ in range(nBlocks+1)]\n",
    "    preds = generator([*ws, noise], training=True)\n",
    "    jacLite = tf.math.reduce_sum(preds * y)\n",
    "    \n",
    "    jac = tf.gradients(jacLite, w)[0]\n",
    "    norm = tf.norm(jac)\n",
    "    return K.mean(tf.square(norm - tf.cast(a, tf.float32))), norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FID function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "\n",
    "allRealFeatures = None\n",
    "\n",
    "# turn TF tensor outputs into numpy array outputs\n",
    "def toNp(*args):\n",
    "    ret = []\n",
    "    for i in args:\n",
    "        meanVal = i\n",
    "        try:\n",
    "            meanVal = i.numpy()\n",
    "        except:\n",
    "            pass\n",
    "        ret.append(meanVal)\n",
    "    return ret\n",
    "\n",
    "def calculate_fid():\n",
    "    global allRealFeatures\n",
    "    \n",
    "    def crunch(batch, bs=64):\n",
    "        z1, z2 = npr.randn(2, bs, zdim)\n",
    "        noise = npr.randn(bs, imgSize, imgSize, 1)\n",
    "        w1 = mapper(z1, training=False)\n",
    "        w2 = mapper(z2, training=False)\n",
    "        ws = [w1 for _ in range(teps)] + [w2 for _ in range(4)]\n",
    "        fakes = generator([*ws, noise], training=False)\n",
    "        fakeFeatures = inception(fakes/2+0.5, training=False)\n",
    "        realFeatures = inception(batch/2+0.5, training=False)\n",
    "        return fakeFeatures.numpy(), realFeatures.numpy()\n",
    "    def crunchLite(batch, bs=64):\n",
    "        z1, z2 = npr.randn(2, bs, zdim)\n",
    "        noise = npr.randn(bs, imgSize, imgSize, 1)\n",
    "        w1 = mapper(z1, training=False)\n",
    "        w2 = mapper(z2, training=False)\n",
    "        ws = [w1 for _ in range(teps)] + [w2 for _ in range(4)]\n",
    "        fakes = generator([*ws, noise], training=False)\n",
    "        fakeFeatures = inception(fakes/2+0.5, training=False)\n",
    "        return fakeFeatures.numpy(), -1\n",
    "    \n",
    "    K.clear_session()\n",
    "    bs = 16\n",
    "    expandM = bs * (m//bs)\n",
    "    crunchFunc = crunchLite\n",
    "    if allRealFeatures is None:\n",
    "        crunchFunc = crunch\n",
    "        allRealFeatures = np.zeros((expandM, 2048))\n",
    "        \n",
    "    allFakeFeatures = np.zeros((expandM, 2048))\n",
    "    for batchS in tqdm(range(0, expandM, bs)):\n",
    "        batch = reals[batchS: batchS + bs]\n",
    "        fakeFeatures, realFeatures = crunchFunc(batch, bs=bs)\n",
    "        allFakeFeatures[batchS: batchS + bs] = fakeFeatures\n",
    "        \n",
    "        if crunchFunc == crunch:\n",
    "            allRealFeatures[batchS: batchS + bs] = realFeatures\n",
    "        \n",
    "    # calculate mean and covariance statistics\n",
    "    fakeMean, fakeStd = np.mean(allFakeFeatures, axis=0), np.cov(allFakeFeatures, rowvar=False)\n",
    "    realMean, realStd = np.mean(allRealFeatures, axis=0), np.cov(allRealFeatures, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = np.sum((fakeMean - realMean) ** 2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sqrtm(np.dot(fakeStd, realStd))\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + np.trace(fakeStd + realStd - 2.0 * covmean)\n",
    "    K.clear_session()\n",
    "    return fid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "One training step for the GAN.\n",
    "Args:\n",
    "batch - input batch of real images\n",
    "p - probability of augmenting image\n",
    "pplEMA - skip PPL reg. if it is -1, else use the value for regularization\n",
    "useGP - skip R1 gradient penalty if it is -1\n",
    "'''\n",
    "@tf.function\n",
    "def trainStep(batch, p, pplEMA=-tf.ones(()), useGP=-tf.ones(())):\n",
    "    def genImgs():\n",
    "        z1 = tf.random.normal([batchSize, zdim])\n",
    "        z2 = tf.random.normal([batchSize, zdim])\n",
    "        noise = tf.random.normal([batchSize, imgSize, imgSize, 1])\n",
    "\n",
    "        w1 = z1; w2 = z2\n",
    "        w1 = mapper(z1, training=True)\n",
    "        w2 = tf.cond(tf.random.uniform(()) < 0.9, lambda: mapper(z2, training=True), lambda: w1)\n",
    "        splitInd = npr.randint(nBlocks+1)\n",
    "        ws = [w1 for _ in range(splitInd)] + [w2 for _ in range(nBlocks+1-splitInd)]\n",
    "        fakes = generator([*ws, noise], training=True)\n",
    "        return fakes\n",
    "    \n",
    "    fakes = genImgs()\n",
    "    augBatch = aug(batch, p)\n",
    "    augFakes = aug(fakes, p)\n",
    "    truePreds = discriminator(augBatch, training=True)\n",
    "    fakePreds = discriminator(augFakes, training=True)\n",
    "\n",
    "    gpWeight = 16 * 10 / 2\n",
    "    gploss = tf.cond(useGP >= 0, lambda: gpWeight * K.mean((tf.reduce_sum(tf.square(tf.gradients(truePreds, [augBatch])[0]), axis=[1,2,3]))), lambda: 0.0)\n",
    "\n",
    "    dloss = discLoss(truePreds, fakePreds) + gploss\n",
    "    rtBatch = rt(truePreds)\n",
    "    \n",
    "    fakes = genImgs()\n",
    "    augFakes = aug(fakes, p)\n",
    "    fakePreds = discriminator(augFakes, training=True)\n",
    "\n",
    "    pplWeight = 8 * 2 / (imgSize * imgSize * (nBlocks + 1))\n",
    "    pplLoss, pplNorm = tf.cond(pplEMA >= 0, lambda: pplReg(pplEMA), lambda: (0.0, 0.0))\n",
    "    pplLoss = pplWeight * pplLoss\n",
    "    gloss = genLoss(fakePreds) + pplLoss\n",
    "    \n",
    "    dGrad = tf.gradients(dloss, discriminator.trainable_variables)\n",
    "    discOpt.apply_gradients(zip(dGrad, discriminator.trainable_variables))\n",
    "\n",
    "    gGrad = tf.gradients(gloss, generator.trainable_variables)\n",
    "    genOpt.apply_gradients(zip(gGrad, generator.trainable_variables))\n",
    "    \n",
    "    mGrad = tf.gradients(gloss, mapper.trainable_variables)\n",
    "    mapOpt.apply_gradients(zip(mGrad, mapper.trainable_variables))\n",
    "    \n",
    "    return dloss, gploss, gloss, rtBatch, pplLoss, pplNorm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient visualization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retGrads(img):\n",
    "    z1 = tf.random.normal([1, zdim])\n",
    "    z2 = tf.random.normal([1, zdim])\n",
    "    noise = tf.random.normal([1, imgSize, imgSize, 1])\n",
    "    randImg = tf.convert_to_tensor(img[np.newaxis])\n",
    "\n",
    "    with tf.GradientTape() as tapeReal, tf.GradientTape() as tapeFake:\n",
    "        w1 = z1; w2 = z2\n",
    "        w1 = mapper(z1, training=False)\n",
    "        w2 = mapper(z2, training=False)\n",
    "        ws = [w1 for _ in range(teps)] + [w2 for _ in range(4)]\n",
    "        tapeReal.watch(randImg)\n",
    "        fakes = generator([*ws, noise], training=False)\n",
    "        tapeFake.watch(fakes)\n",
    "        truePreds = discriminator(randImg, training=False)\n",
    "        fakePreds = discriminator(fakes, training=False)\n",
    "        dloss = discLoss(truePreds, fakePreds)\n",
    "\n",
    "    realGrad = tapeReal.gradient(dloss, randImg)[0]\n",
    "    fakeGrad = tapeFake.gradient(dloss, fakes)[0]\n",
    "    realNorm = tf.norm(realGrad)\n",
    "    fakeNorm = tf.norm(fakeGrad)\n",
    "    return realGrad.numpy(), fakeGrad.numpy(), realNorm.numpy(), fakeNorm.numpy(), randImg[0].numpy(), fakes[0].numpy(), truePreds.numpy(), fakePreds.numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=None, steps=None, n=4):\n",
    "    global p, pplNorms, pplEMA\n",
    "    gc.collect()\n",
    "    rtBatches = 0\n",
    "    \n",
    "    if epochs != None:\n",
    "        for i in range(epochs):\n",
    "            gc.collect()\n",
    "            dcost, gpcost, gcost = 0, 0, 0\n",
    "            pplSum = 0\n",
    "            rtSum, pplCost = 0, 0\n",
    "            batchNum = 0\n",
    "            for batch in ds:\n",
    "                pTensor = tf.convert_to_tensor(p, dtype=tf.float32)\n",
    "                batch = reals[npr.randint(0, m, (batchSize,))]\n",
    "                if batchNum % 16 == 0:\n",
    "                    vals = toNp(*trainStep(batch, pTensor, tf.convert_to_tensor(pplEMA), useGP=tf.ones(())))\n",
    "                elif batchNum % 8 == 0:\n",
    "                    vals = toNp(*trainStep(batch, pTensor, tf.convert_to_tensor(pplEMA)))\n",
    "                else:\n",
    "                    vals = toNp(*trainStep(batch, pTensor))\n",
    "                dloss, gploss, gloss, rtBatch, pplLoss, pplNorm = vals\n",
    "\n",
    "                if pplNorm != 0:\n",
    "                    pplEMA = 0.01 * pplNorm + 0.99 * pplEMA\n",
    "                \n",
    "                rtBatches += rtBatch\n",
    "                if batchNum % n == 0:\n",
    "                    p += pStep * np.sign(rtBatches/n - 0.6)\n",
    "                    p = round(min(max(p, 0), 1), 6) % 0.8\n",
    "                    rtBatches = 0\n",
    "                batchNum += 1\n",
    "                dcost += dloss; gpcost += gploss; gcost += gloss; rtSum += rtBatch; pplCost += pplLoss; pplSum += pplNorm\n",
    "            \n",
    "            dcosts.append(dcost)\n",
    "            gcosts.append(gcost)\n",
    "            gpcosts.append(gpcost)\n",
    "            pplNorms.append(round(pplSum / batchNum, 4))\n",
    "            ps.append(p)\n",
    "            rts.append(rtBatch)\n",
    "            print('Epoch: {} | D Cost: {} | GP Cost: {} | G Cost: {}'.format(i, dcost, gpcost, gcost), end = ' | ')\n",
    "            print('P(aug): {} | Rt: {} | PPL Norm: {} | PPL Loss: {}'.format(p, round(rtSum / batchNum, 4), round(pplSum / batchNum, 4), round(pplCost, 4)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 2, 2\n",
    "\n",
    "'''\n",
    "Display generated images as well as a summary of model metrics.\n",
    "Args:\n",
    "z1/z2 - latent input vector 1/2\n",
    "noise - noise input\n",
    "verbose - 5-element list saying which metrics to calculate and print out\n",
    "verbose[0] - FID score\n",
    "verbose[1] - D(G(z)) - discriminator predictions on generated images\n",
    "verbose[2] - D(x) - discriminator predictions on real images\n",
    "verbose[3/4] - D/G Loss\n",
    "verbose=True/1: print everything\n",
    "verbose=False/0: print nothing\n",
    "'''\n",
    "\n",
    "def display(z1, z2, noise, verbose=True):\n",
    "    gc.collect()\n",
    "    fig = plt.figure(figsize=(cols*4, rows*4))\n",
    "    axes = fig.subplots(rows, cols)\n",
    "    \n",
    "    z1[0] = constZ; z2[0] = constZ; noise[0] = constNoise\n",
    "    assert z1.shape == (rows * cols, zdim)\n",
    "    assert z2.shape == (rows * cols, zdim)\n",
    "    assert noise.shape == (rows * cols, imgSize, imgSize, 1)\n",
    "        \n",
    "    randInds = npr.randint(0, reals.shape[0], (rows*cols,))\n",
    "    \n",
    "    w1 = z1; w2 = z2\n",
    "    w1 = mapper(z1, training=False)\n",
    "    w2 = mapper(z2, training=False)\n",
    "    ws = [w1 for _ in range(teps)] + [w2 for _ in range(4)]\n",
    "    preds = generator([*ws, noise], training=False)\n",
    "    df = discriminator(preds, training=False)\n",
    "    dr = discriminator(reals[randInds], training=False)\n",
    "    if type(verbose) == type(True):\n",
    "        verbose = [verbose for i in range(5)]\n",
    "    if type(verbose) == int:\n",
    "        if verbose == 0:\n",
    "            verbose = [False for i in range(5)]\n",
    "        elif verbose == 1:\n",
    "            verbose = [False, False, False, True, True]\n",
    "        elif verbose == 2:\n",
    "            verbose = [False, True, True, True, True]\n",
    "        elif verbose == 3:\n",
    "            verbose = [True for i in range(5)]\n",
    "            \n",
    "    if verbose[1]:\n",
    "        print('D(G(z)) (lower = better disc):', np.mean(df))\n",
    "    if verbose[2]:\n",
    "        print('D(x) (higher = better disc):', np.mean(dr))\n",
    "    if verbose[3]:\n",
    "        print('D Loss:', discLoss(dr, df))\n",
    "    if verbose[4]:\n",
    "        print('G Loss:', genLoss(df))\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            axes[i][j].imshow(preds[i*cols + j] / 2 + 0.5,cmap='gray')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    if verbose[0]:\n",
    "        fid = round(calculate_fid(), 4)\n",
    "        print('FID:', fid)\n",
    "        fids.append(fid)\n",
    "    return preds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save current state of model, overwriting past state of model on disk.\n",
    "Args:\n",
    "askInp - require user to place input before saving models - protects user from accidentally overwriting models with a collapsed model\n",
    "'''\n",
    "def save_models(epoch1,askInp=True):\n",
    "    if askInp:\n",
    "        input()\n",
    "    \n",
    "    \n",
    "    generator.save_weights(modelPath+'genWeights_gray_'+str(epoch1)+'.h5')\n",
    "    discriminator.save_weights(modelPath+'discWeights_gray_'+str(epoch1)+'.h5')\n",
    "    mapper.save_weights(modelPath+'mapWeights_gray_'+str(epoch1)+'.h5')\n",
    "\n",
    "def load_models(epoch1,askInp=True):\n",
    "    if askInp:\n",
    "        input()\n",
    "    discriminator.load_weights(modelPath+'discWeights_gray_'+str(epoch1)+'.h5')\n",
    "    mapper.load_weights(modelPath+'mapWeights_gray_'+str(epoch1)+'.h5')\n",
    "    generator.load_weights(modelPath+'genWeights_gray_'+str(epoch1)+'.h5')\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constZ = npr.randn(zdim,)\n",
    "constNoise = npr.randn(imgSize, imgSize, 1)\n",
    "epoch =0\n",
    "if type(reals) != np.ndarray or type(ds) == type(None):\n",
    "        loadData()\n",
    "load_models(13)\n",
    "while True:\n",
    "    sess = timeIt('Training')\n",
    "    display(z1=npr.randn(rows * cols, zdim), z2=npr.randn(rows * cols, zdim), noise=npr.randn(rows * cols, imgSize, imgSize, 1), verbose=True)\n",
    "    train(epochs=100)\n",
    "    epoch += 1\n",
    "    sess.close()\n",
    "    save_models(epoch,askInp=False)\n",
    "    np.save(os.path.join(modelPath, 'p.npy'), p) # save p value for future training if training on servers with time limits like Paperspace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(reals) != np.ndarray or type(ds) == type(None):\n",
    "    #loadData()\n",
    "    reals = np.load(os.path.join(datasetPath, 'imgs.npy'))\n",
    "    m = batchSize * (reals.shape[0] // batchSize)\n",
    "    reals = reals[:m].astype(np.float32)\n",
    "\n",
    "    assert reals.shape[0] % batchSize == 0\n",
    "    assert type(reals) == np.ndarray\n",
    "    ds = (tf.data.Dataset.from_tensor_slices(tf.cast(reals, tf.float32)).shuffle(3000).batch(batchSize))\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    gc.collect()\n",
    "\n",
    "dGrad, gGrad, dNorm, gNorm, img, fake, truePreds, fakePreds = retGrads(reals[35])\n",
    "dGrad = np.sum(dGrad, axis=2)\n",
    "gGrad = np.sum(gGrad, axis=2)\n",
    "print('D(x): {} | D(G(z)): {}'.format(truePreds, fakePreds))\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 20))\n",
    "dGrad = (dGrad - np.min(dGrad)) / (np.max(dGrad) - np.min(dGrad) + eps)\n",
    "gGrad = (gGrad - np.min(gGrad)) / (np.max(gGrad) - np.min(gGrad) + eps)\n",
    "axes[0][0].imshow(img/2+0.5)\n",
    "axes[0][1].imshow(fake/2+0.5)\n",
    "axes[1][0].imshow(dGrad)\n",
    "axes[1][0].set_title('Real Grad; Norm: {}'.format(round(dNorm, 4)))\n",
    "axes[1][1].imshow(gGrad)\n",
    "axes[1][1].set_title('Fake Grad; Norm: {}'.format(round(gNorm, 4)))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize mapping activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = npr.randn(1, zdim)\n",
    "w = mapper.predict(z)\n",
    "plt.imshow(z[0].reshape(16, 16))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(w[0].reshape(16, 16))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    constZ1s\n",
    "except Exception as e:\n",
    "    constZ1s = npr.randn(rows*cols, zdim)\n",
    "    constZ2s = npr.randn(rows*cols, zdim)\n",
    "    constNoises = npr.randn(rows * cols, imgSize, imgSize, 1)\n",
    "\n",
    "'''\n",
    "if z1s commented out, same content, different styles\n",
    "if z2s commented out, different content, same styles\n",
    "if noise = 0, undesirably smooth faces but just a test to make sure styles are working properly\n",
    "'''\n",
    "for i in range(1): \n",
    "    constZ1s = npr.randn(rows * cols, zdim)\n",
    "    #constZ2s = npr.randn(rows * cols, zdim)\n",
    "    constNoises = npr.randn(rows * cols, imgSize, imgSize, 1) * 0\n",
    "    pred11=display(z1=constZ1s, z2=constZ2s, noise=constNoises, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "for j in range(911):\n",
    "    constZ1s = npr.randn(rows*10, zdim)\n",
    "    constZ2s = npr.randn(rows*10, zdim)\n",
    "    constNoises = npr.randn(rows * 10, imgSize, imgSize, 1)\n",
    "    \n",
    "\n",
    "    z1 = constZ1s; z2 = constZ2s; noise = constNoises\n",
    "\n",
    "    randInds = npr.randint(0, reals.shape[0], (rows*10,))\n",
    "        \n",
    "    w1 = mapper(z1, training=False)\n",
    "    w2 = mapper(z2, training=False)\n",
    "    ws = [w1 for i in range(teps)] + [w2 for i in range(4)]\n",
    "    preds = generator([*ws, noise], training=False)\n",
    "\n",
    "    for i in range(5):\n",
    "        img=preds[i].numpy() / 2 + 0.5\n",
    "        img=((img-img.min())*255/(img-img.min()).max())\n",
    "        img= cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(\"../../data/6_Train_styleGAN/pred/pred\"+str(j*5+i)+\".jpg\",img)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See metrics over training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 4))\n",
    "pltX = range(len(dcosts))\n",
    "gcosts1=np.array(gcosts)\n",
    "axes[0].plot(pltX, dcosts); axes[0].set_title('D Loss')\n",
    "axes[1].plot(pltX, gcosts1); axes[1].set_title('G Loss')\n",
    "axes[2].plot(pltX, gpcosts); axes[2].set_title('GP')\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 4))\n",
    "axes[0].plot(pltX, ps); axes[0].set_title('Evolution of P(aug) over training')\n",
    "axes[1].plot(pltX, rts); axes[1].set_title('Evolution of r_t')\n",
    "axes[2].plot(pltX, pplNorms); axes[2].set_title('PPL_Norm')\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 8))\n",
    "axes.set_title('D Loss (Blue) vs. G Loss (Orange)')\n",
    "axes.plot(pltX, dcosts, color='blue')\n",
    "axes.plot(pltX, gcosts1, color='orange')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
