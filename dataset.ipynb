{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=glob(\"../../data/ddh_standard_frame_data/*\")\n",
    "\n",
    "\n",
    "def AnnotationsPd(annotations):\n",
    "    values_list = []\n",
    "    names_list = [] \n",
    "    df = pd.DataFrame(annotations['tags'])\n",
    "    for row in df['attributes']:\n",
    "        values_list.append(row[0]['value'])\n",
    "        names_list.append(row[0]['name'])\n",
    "\n",
    "    df=df.drop(['attributes'],axis=1)   \n",
    "    df.insert(3,'value',values_list)\n",
    "    df.insert(4,'name',names_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m frame \u001b[39min\u001b[39;00m std_frame:\n\u001b[1;32m     14\u001b[0m     file\u001b[39m=\u001b[39m data_img_path[frame]\n\u001b[0;32m---> 15\u001b[0m     Train_standard_file_path\u001b[39m.\u001b[39;49mappend(file)\n\u001b[1;32m     16\u001b[0m Train_not_standard_file_path\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(data_img_path)\u001b[39m-\u001b[39m\u001b[39mset\u001b[39m(Train_standard_file_path))   \n\u001b[1;32m     17\u001b[0m Train_standard_file_path\u001b[39m=\u001b[39m\u001b[39mset\u001b[39m(Train_standard_file_path)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'set' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "Train_standard_file_path=[]\n",
    "Train_not_standard_file_path=[]\n",
    "Test_standard_file_path=[]\n",
    "Test_not_standard_file_path=[]\n",
    "Val_standard_file_path=[]\n",
    "Val_not_standard_file_path=[]\n",
    "for i in range(20):\n",
    "    data_img_path=glob(folder_path[0]+\"/data/*.jpg\")\n",
    "    data_img_path.sort()\n",
    "    with open(folder_path[0]+'/annotations.json') as f:\n",
    "        annotations_json = json.load(f)\n",
    "    std_frame=AnnotationsPd(annotations_json[0])['frame']\n",
    "    for frame in std_frame:\n",
    "        file= data_img_path[frame]\n",
    "        Train_standard_file_path.append(file)\n",
    "    Train_not_standard_file_path=list(set(data_img_path)-set(Train_standard_file_path))   \n",
    "    Train_standard_file_path=set(Train_standard_file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(folder_path[2]+'/annotations.json') as f:\n",
    "    annotations_json = json.load(f)   \n",
    "std_frame=AnnotationsPd(annotations_json[0])['frame']\n",
    "for frame in std_frame:\n",
    "    file= [s for s in data2_img_path if str(frame).zfill(5) in s] \n",
    "    Train_file_path.append(file[0])\n",
    "\n",
    "with open(folder_path[1]+'/annotations.json') as f:\n",
    "    annotations_json = json.load(f)    \n",
    "std_frame=AnnotationsPd(annotations_json[0])['frame']\n",
    "for frame in std_frame:\n",
    "    file= [s for s in test_data_img_path if str(frame).zfill(5) in s] \n",
    "    Test_file_path.append(file[0])\n",
    "    \n",
    "with open(folder_path[3]+'/annotations.json') as f:\n",
    "    annotations_json = json.load(f)    \n",
    "std_frame=AnnotationsPd(annotations_json[0])['frame']\n",
    "for frame in std_frame:\n",
    "    file= [s for s in data4_img_path if str(frame).zfill(5) in s] \n",
    "    Train_file_path.append(file[0])\n",
    "Train_file_path=list(set(Train_file_path))\n",
    "Test_file_path=list(set(Test_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_standard_file=[]\n",
    "Train_TF_standard=[]\n",
    "Test_standard_file=[]\n",
    "Test_TF_standard=[]\n",
    "for i in range(len(Train_file_path)):\n",
    "    Train_TF_standard.append(1)\n",
    "    shutil.copy(Train_file_path[i],'../../data/original_dataset/StandardFrame/Train/'+str(i)+'.jpg')\n",
    "    Train_standard_file.append('StandardFrame/Train/'+str(i)+'.jpg')   \n",
    "for i in range(len(Test_file_path)):\n",
    "    Test_TF_standard.append(1)\n",
    "    shutil.copy(Test_file_path[i],'../../data/original_dataset/StandardFrame/Test/'+str(i)+'.jpg')\n",
    "    Test_standard_file.append('StandardFrame/Test/'+str(i)+'.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_not_standard_file1=list(set(data1_img_path)-set(Train_file_path))\n",
    "Test_not_standard_file1=list(set(test_data_img_path)-set(Test_file_path))\n",
    "\n",
    "for i in range(len(Train_not_standard_file1)):\n",
    "    Train_TF_standard.append(0)\n",
    "    shutil.copy(Train_not_standard_file1[i],'../../data/original_dataset/NotStandardFrame/Train/'+str(i)+'.jpg')\n",
    "    Train_standard_file.append('NotStandardFrame/Train/'+str(i)+'.jpg')\n",
    "for i in range(len(Test_not_standard_file1)):\n",
    "    Test_TF_standard.append(0)\n",
    "    shutil.copy(Test_not_standard_file1[i],'../../data/original_dataset/NotStandardFrame/Test/'+str(i)+'.jpg')\n",
    "    Test_standard_file.append('NotStandardFrame/Test/'+str(i)+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_original_standard_frame = pd.DataFrame({'file_path':Train_standard_file,\n",
    "                             'standard_frame':Train_TF_standard})\n",
    "Test_original_standard_frame = pd.DataFrame({'file_path':Test_standard_file,\n",
    "                             'standard_frame':Test_TF_standard})\n",
    "Train_original_standard_frame=shuffle(Train_original_standard_frame)\n",
    "Test_original_standard_frame=shuffle(Test_original_standard_frame)\n",
    "Test_original_standard_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_original_standard_frame.to_csv('../../data/original_dataset/Train_data_set.csv', index = None) #csv파일로 생성\n",
    "Test_original_standard_frame.to_csv('../../data/original_dataset/Test_data_set.csv', index = None) #csv파일로 생성"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS_tf210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
