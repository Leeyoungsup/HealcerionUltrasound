{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 11:24:35.330443: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-26 11:24:36.063016: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from math import isnan\n",
    "from numpy import average\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "import warnings\n",
    "size = 224\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras2TFlite(model_path,name):\n",
    "    #load a pre-trained model\n",
    "    with tf.device('/gpu:0'):\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        #convert the model\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        tflite_model = converter.convert()\n",
    "        #save the converted model\n",
    "        with open('../../model/classification/tflite/'+name+'.tflite', 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print('Model converted successfully')\n",
    "\n",
    "def createDirectory(directory):\n",
    "    \"\"\"_summary_\n",
    "        create Directory\n",
    "    Args:\n",
    "        directory (string): file_path\n",
    "    \"\"\"    \n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "\n",
    "def TFLiteInference(model_path, name, x_test, y_test):\n",
    "    # Load TFLite model and allocate tensors.\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    with tf.device('/gpu:0'):\n",
    "        input_index = interpreter.get_input_details()[0]['index']\n",
    "        output_index  = interpreter.get_output_details()[0]['index']\n",
    "        \n",
    "        sum_correct = 0\n",
    "        sum_time=0\n",
    "        predict=[]\n",
    "        for idx, data in tqdm(enumerate(zip(x_test,y_test))):\n",
    "            img = data[0]\n",
    "            label = data[1]\n",
    "            img= img.astype(np.float32)\n",
    "            img = tf.expand_dims(img, axis=0)\n",
    "            \n",
    "            interpreter.set_tensor(input_index, img)\n",
    "            start_time = time.time()\n",
    "            interpreter.invoke()\n",
    "            \n",
    "            output = interpreter.get_tensor(output_index)\n",
    "            stop_time = time.time()\n",
    "            sum_time += stop_time-start_time\n",
    "            \n",
    "            if (output[0][0]>0.34) == label:\n",
    "                sum_correct += 1.0\n",
    "            predict.append(output[0][0])\n",
    "            mean_acc=sum_correct/float(idx+1)\n",
    "            mean_time=sum_time/float(idx+1)\n",
    "        print('Model: ',name)\n",
    "        print('Mean Accuracy: ',mean_acc)\n",
    "        print('Mean Inference Time: ',mean_time)\n",
    "        return predict\n",
    "# keras2TFlite('../../model/classification/MobileNetV2_checkpoints.h5','MobileNetV2')\n",
    "# keras2TFlite('../../model/classification/MobileNetV1_acc_checkpoints.h5','MobileNetV1')\n",
    "# keras2TFlite('../../model/classification/DenseNet121_checkpoints.h5','DenseNet121')\n",
    "# keras2TFlite('../../model/classification/EfficientNetV2B0_checkpoints.h5','EfficientNetV2B0')\n",
    "# keras2TFlite('../../model/classification/NASNetMobile_checkpoints.h5','NASNetMobile')\n",
    "# keras2TFlite('../../model/classification/ResNet50_checkpoints.h5','ResNet50')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092a1141981a4094b8c2029c4afb69f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/584 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\n",
    "    '../../data/segmentationDDH/test_aug_segmentation_dataset.csv')\n",
    "\n",
    "test_img_list = test_df['file name'].to_list()\n",
    "test_label_list = test_df['standard mask'].to_list()\n",
    "test_case_list = test_df['case'].to_list()\n",
    "test_img_path = '../../data/segmentationDDH/aug_dataset/test/'\n",
    "   \n",
    "x_test=np.zeros((len(test_img_list),3,size,size),dtype=np.float32)\n",
    "y_test=np.zeros((len(test_img_list),4,size,size),dtype=np.float32)\n",
    "\n",
    "for i in tqdm(range(len(test_img_list))):\n",
    "    x_test[i] = np.swapaxes(np.array(Image.open(\n",
    "        test_img_path+str(test_case_list[i])+'/image/'+test_img_list[i]).resize((size, size))),0,2)\n",
    "    y_test[i,0]=np.array(Image.open(\n",
    "        test_img_path+str(test_case_list[i])+'/mask/'+str(test_label_list[i]).zfill(5)+'/1.png').resize((size, size)))\n",
    "    y_test[i,1]=np.array(Image.open(\n",
    "        test_img_path+str(test_case_list[i])+'/mask/'+str(test_label_list[i]).zfill(5)+'/2.png').resize((size, size)))\n",
    "    y_test[i,2]=np.array(Image.open(\n",
    "        test_img_path+str(test_case_list[i])+'/mask/'+str(test_label_list[i]).zfill(5)+'/3.png').resize((size, size)))\n",
    "    y_test[i,3]=np.array(Image.open(\n",
    "        test_img_path+str(test_case_list[i])+'/mask/'+str(test_label_list[i]).zfill(5)+'/4.png').resize((size, size)))\n",
    "\n",
    "x_test = x_test/255.0\n",
    "y_test = y_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0756ca8d204ee4999e6d393b233eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m stop_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     24\u001b[0m sum_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m stop_time\u001b[38;5;241m-\u001b[39mstart_time\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.34\u001b[39m) \u001b[38;5;241m==\u001b[39m label:\n\u001b[1;32m     27\u001b[0m     sum_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     28\u001b[0m predict\u001b[38;5;241m.\u001b[39mappend(output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path='../../model/segmentation/tflite/DeepLabV3Plus.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    input_index = interpreter.get_input_details()[0]['index']\n",
    "    output_index  = interpreter.get_output_details()[0]['index']\n",
    "    \n",
    "    sum_correct = 0\n",
    "    sum_time=0\n",
    "    predict=[]\n",
    "    for idx, data in tqdm(enumerate(zip(x_test,y_test))):\n",
    "        img = data[0]\n",
    "        label = data[1]\n",
    "        img= img.astype(np.float32)\n",
    "        img = tf.expand_dims(img, axis=0)\n",
    "        \n",
    "        interpreter.set_tensor(input_index, img)\n",
    "        start_time = time.time()\n",
    "        interpreter.invoke()\n",
    "        \n",
    "        output = interpreter.get_tensor(output_index)\n",
    "        stop_time = time.time()\n",
    "        sum_time += stop_time-start_time\n",
    "        \n",
    "        if (output[0][0]>0.34) == label:\n",
    "            sum_correct += 1.0\n",
    "        predict.append(output[0][0])\n",
    "        mean_acc=sum_correct/float(idx+1)\n",
    "        mean_time=sum_time/float(idx+1)\n",
    "    print('Model: ','DeepLabV3Plus')\n",
    "    print('Mean Accuracy: ',mean_acc)\n",
    "    print('Mean Inference Time: ',mean_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 5.1955569e-05,  1.4774126e-04,  2.4352694e-04, ...,\n",
       "           5.2988500e-04,  2.7685589e-04,  2.3826833e-05],\n",
       "         [ 1.6039588e-04,  1.9867472e-04,  2.3695355e-04, ...,\n",
       "           6.4433285e-04,  3.8997686e-04,  1.3562097e-04],\n",
       "         [ 2.6883619e-04,  2.4960819e-04,  2.3038016e-04, ...,\n",
       "           7.5878063e-04,  5.0309784e-04,  2.4741510e-04],\n",
       "         ...,\n",
       "         [ 1.2701368e-03,  1.0928160e-03,  9.1549521e-04, ...,\n",
       "          -5.5626594e-04, -9.0051902e-04, -1.2447720e-03],\n",
       "         [ 1.1696538e-03,  9.5761701e-04,  7.4558024e-04, ...,\n",
       "          -9.4896770e-04, -1.2720287e-03, -1.5950894e-03],\n",
       "         [ 1.0691708e-03,  8.2241802e-04,  5.7566521e-04, ...,\n",
       "          -1.3416695e-03, -1.6435382e-03, -1.9454069e-03]],\n",
       "\n",
       "        [[-8.1622059e-04, -9.3512412e-05,  6.2919577e-04, ...,\n",
       "           7.9359382e-04,  4.0234404e-04,  1.1094159e-05],\n",
       "         [-3.2825029e-04,  3.9350046e-04,  1.1152512e-03, ...,\n",
       "           1.4756324e-03,  1.2680960e-03,  1.0605593e-03],\n",
       "         [ 1.5972002e-04,  8.8051334e-04,  1.6013067e-03, ...,\n",
       "           2.1576709e-03,  2.1338481e-03,  2.1100244e-03],\n",
       "         ...,\n",
       "         [ 1.6252669e-03,  2.1768785e-03,  2.7284904e-03, ...,\n",
       "           5.1146168e-03,  5.4864306e-03,  5.8582444e-03],\n",
       "         [ 1.9821145e-03,  2.4879510e-03,  2.9937874e-03, ...,\n",
       "           5.4784496e-03,  5.8988719e-03,  6.3192947e-03],\n",
       "         [ 2.3389622e-03,  2.7990234e-03,  3.2590847e-03, ...,\n",
       "           5.8422829e-03,  6.3113137e-03,  6.7803450e-03]],\n",
       "\n",
       "        [[-1.3763704e-03, -9.0870226e-04, -4.4103403e-04, ...,\n",
       "          -5.2889751e-05,  3.5342702e-04,  7.5974379e-04],\n",
       "         [-1.1356163e-03, -6.5400958e-04, -1.7240280e-04, ...,\n",
       "          -4.0374781e-04, -2.1974056e-04, -3.5733392e-05],\n",
       "         [-8.9486217e-04, -3.9931689e-04,  9.6228439e-05, ...,\n",
       "          -7.5460586e-04, -7.9290813e-04, -8.3121058e-04],\n",
       "         ...,\n",
       "         [-1.6110688e-03, -8.2947750e-04, -4.7886162e-05, ...,\n",
       "          -1.3049832e-04, -1.9913452e-04, -2.6777078e-04],\n",
       "         [-1.1659780e-03, -4.0322228e-04,  3.5953335e-04, ...,\n",
       "           2.0159909e-04,  1.0402547e-04,  6.4517953e-06],\n",
       "         [-7.2088727e-04,  2.3032830e-05,  7.6695293e-04, ...,\n",
       "           5.3369650e-04,  4.0718543e-04,  2.8067440e-04]],\n",
       "\n",
       "        [[ 7.2448462e-04,  6.6927925e-04,  6.1407383e-04, ...,\n",
       "           8.7526237e-04,  9.2554273e-04,  9.7582309e-04],\n",
       "         [ 6.5753894e-04,  6.1937742e-04,  5.8121583e-04, ...,\n",
       "           1.0328839e-03,  1.0136131e-03,  9.9434238e-04],\n",
       "         [ 5.9059332e-04,  5.6947558e-04,  5.4835790e-04, ...,\n",
       "           1.1905053e-03,  1.1016836e-03,  1.0128616e-03],\n",
       "         ...,\n",
       "         [ 1.1719546e-03,  9.1962342e-04,  6.6729216e-04, ...,\n",
       "           6.2073371e-04,  5.1007612e-04,  3.9941852e-04],\n",
       "         [ 1.1754951e-03,  8.7312708e-04,  5.7075900e-04, ...,\n",
       "           7.8800839e-04,  5.9826247e-04,  4.0851653e-04],\n",
       "         [ 1.1790356e-03,  8.2663074e-04,  4.7422585e-04, ...,\n",
       "           9.5528312e-04,  6.8644882e-04,  4.1761453e-04]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNetV2_pre=TFLiteInference('../../model/classification/tflite/MobileNetV2.tflite','MobileNetV2',x_test,y_test)\n",
    "MobileNetV1_pre=TFLiteInference('../../model/classification/tflite/MobileNetV1.tflite','MobileNetV1',x_test,y_test)\n",
    "DenseNet121_pre=TFLiteInference('../../model/classification/tflite/DenseNet121.tflite','DenseNet121',x_test,y_test)\n",
    "EfficientNetV2B0_pre=TFLiteInference('../../model/classification/tflite/EfficientNetV2B0.tflite','EfficientNetV2B0',x_test,y_test)\n",
    "NASNetMobile_pre=TFLiteInference('../../model/classification/tflite/NASNetMobile.tflite','NASNetMobile',x_test,y_test)\n",
    "ResNet50_pre=TFLiteInference('../../model/classification/tflite/ResNet50.tflite','ResNet50',x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='../../model/classification/tflite/MobileNetV2.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNetV2_fper,MobileNetV2_tper, thresholds = roc_curve(y_test, MobileNetV2_pre)\n",
    "MobileNetV1_fper,MobileNetV1_tper, thresholds = roc_curve(y_test, MobileNetV1_pre)\n",
    "DenseNet121_fper,DenseNet121_tper, thresholds = roc_curve(y_test, DenseNet121_pre)\n",
    "EfficientNetV2B0_fper,EfficientNetV2B0_tper, thresholds = roc_curve(y_test, EfficientNetV2B0_pre)\n",
    "NASNetMobile_fper,NASNetMobile_tper, thresholds = roc_curve(y_test, NASNetMobile_pre)\n",
    "ResNet50_fper,ResNet50_tper, thresholds = roc_curve(y_test, ResNet50_pre)\n",
    "MobileNetV2_auc_score=roc_auc_score(y_test, MobileNetV2_pre)\n",
    "MobileNetV1_auc_score=roc_auc_score(y_test, MobileNetV1_pre)\n",
    "DenseNet121_auc_score=roc_auc_score(y_test, DenseNet121_pre)\n",
    "EfficientNetV2B0_auc_score=roc_auc_score(y_test, EfficientNetV2B0_pre)\n",
    "NASNetMobile_auc_score=roc_auc_score(y_test, NASNetMobile_pre)\n",
    "ResNet50_auc_score=roc_auc_score(y_test, ResNet50_pre)\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.plot(DenseNet121_fper, DenseNet121_tper,label='DenseNet121(Auc='+str(round(DenseNet121_auc_score, 3))+')',linestyle='--')\n",
    "plt.plot(EfficientNetV2B0_fper, EfficientNetV2B0_tper,label='EfficientNetV2B0(Auc='+str(round(EfficientNetV2B0_auc_score, 3))+')')\n",
    "plt.plot(MobileNetV1_fper, MobileNetV1_tper,label='MobileNetV1(Auc='+str(round(MobileNetV1_auc_score, 3))+')',linestyle='--')\n",
    "plt.plot(MobileNetV2_fper,MobileNetV2_tper,label='MobileNetV2(Auc='+str(round(MobileNetV2_auc_score, 3))+')')\n",
    "plt.plot(ResNet50_fper,ResNet50_tper,label='ResNet50(Auc='+str(round(ResNet50_auc_score, 3))+')',linestyle='--')\n",
    "plt.plot(NASNetMobile_fper,NASNetMobile_tper,label='NASNetMobile(Auc='+str(round(NASNetMobile_auc_score, 3))+')')\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('False positive rate',size=15)\n",
    "plt.ylabel('True positive rate',size=15)\n",
    "plt.xlim([0, 1])      # X축의 범위: [xmin, xmax]\n",
    "plt.ylim([0, 1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "def weight_metrics(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn*0.25)\n",
    "    specificity = tn / (tn + fp)\n",
    "    precision=tp/ (tp+fp)\n",
    "    f1 = f1_score(y_true, y_pred,average='micro')\n",
    "    weight=f1\n",
    "    \n",
    "    return weight\n",
    "# Define a function to find the optimal threshold\n",
    "def find_optimal_threshold(y_true, y_scores):\n",
    "    thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "    f1_scores = [weight_metrics(y_true, (y_scores >= t).astype(int)) for t in thresholds]\n",
    "    optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    return optimal_threshold\n",
    "MobileNetV2_pre=np.array(MobileNetV2_pre)\n",
    "MobileNetV1_pre=np.array(MobileNetV1_pre)\n",
    "DenseNet121_pre=np.array(DenseNet121_pre)\n",
    "EfficientNetV2B0_pre=np.array(EfficientNetV2B0_pre)\n",
    "NASNetMobile_pre=np.array(NASNetMobile_pre)\n",
    "ResNet50_pre=np.array(ResNet50_pre)\n",
    "\n",
    "# Find optimal threshold for each model\n",
    "MobileNetV2_optimal_threshold = find_optimal_threshold(y_test, MobileNetV2_pre)\n",
    "MobileNetV1_optimal_threshold = find_optimal_threshold(y_test, MobileNetV1_pre)\n",
    "DenseNet121_optimal_threshold = find_optimal_threshold(y_test, DenseNet121_pre)\n",
    "EfficientNetV2B0_optimal_threshold = find_optimal_threshold(y_test, EfficientNetV2B0_pre)\n",
    "NASNetMobile_optimal_threshold = find_optimal_threshold(y_test, NASNetMobile_pre)\n",
    "ResNet50_optimal_threshold = find_optimal_threshold(y_test, ResNet50_pre)\n",
    "# Define a function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn*0.25)\n",
    "    specificity = tn / (tn + fp)\n",
    "    precision=tp / (tp+fp)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 =f1_score(y_true, y_pred,average='micro')\n",
    "    return sensitivity, specificity, accuracy, f1\n",
    "\n",
    "def bootstrap_ci(metric, y_true, y_pred, n_iterations=1000, ci=95):\n",
    "    values = []\n",
    "    for _ in range(n_iterations):\n",
    "        indices = resample(range(len(y_true)), replace=True)\n",
    "        resampled_true = y_true[indices]\n",
    "        resampled_pred = y_pred[indices]\n",
    "        values.append(metric(resampled_true, resampled_pred))\n",
    "    \n",
    "    alpha = (100 - ci) / 2.0\n",
    "    lower = max(0.0, np.percentile(values, alpha))\n",
    "    upper = min(1.0, np.percentile(values, 100 - alpha))\n",
    "    \n",
    "    return lower, upper\n",
    "def bootstrap_f1_ci(metric, y_true, y_pred, n_iterations=1000, ci=95):\n",
    "    values = []\n",
    "    for _ in range(n_iterations):\n",
    "        indices = resample(range(len(y_true)), replace=True)\n",
    "        resampled_true = y_true[indices]\n",
    "        resampled_pred = y_pred[indices]\n",
    "        values.append(metric(resampled_true, resampled_pred,average='micro'))\n",
    "    \n",
    "    alpha = (100 - ci) / 2.0\n",
    "    lower = max(0.0, np.percentile(values, alpha))\n",
    "    upper = min(1.0, np.percentile(values, 100 - alpha))\n",
    "    \n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "def performance_ci(model_name,test,predict,threshold):\n",
    "    ci_auc_lower, ci_auc_upper = bootstrap_ci(roc_auc_score, test, predict)\n",
    "    ci_sensitivity_lower, ci_sensitivity_upper = bootstrap_f1_ci(recall_score, test, (predict >threshold).astype(int))\n",
    "    ci_specificity_lower, ci_specificity_upper = bootstrap_ci(\n",
    "    lambda x, y: confusion_matrix(x, y).ravel()[0] / (confusion_matrix(x, y).ravel()[0] + confusion_matrix(x, y).ravel()[1]),\n",
    "    test,\n",
    "    (predict > threshold).astype(int)\n",
    ")\n",
    "    ci_accuracy_lower, ci_accuracy_upper = bootstrap_ci(accuracy_score, test, (predict >threshold).astype(int))\n",
    "    ci_f1_lower, ci_f1_upper = bootstrap_f1_ci(f1_score, test, (predict >threshold).astype(int))\n",
    "    print(\"{}: AUC={}({}-{}), Sensitivity={}({}-{}), Specificity={}({}-{}), Accuracy={}({}-{}), F1-Score={}({}-{})\".format(model_name,round((ci_auc_upper+ci_auc_lower)/2,3),round(ci_auc_lower,3),round(ci_auc_upper,3),round((ci_sensitivity_upper+ci_sensitivity_lower)/2,3),round(ci_sensitivity_lower,3), round(ci_sensitivity_upper,3),round((ci_specificity_upper+ci_specificity_lower)/2,3),round(ci_specificity_lower,3),round(ci_specificity_upper,3), round((ci_accuracy_upper+ci_accuracy_lower)/2,3),round(ci_accuracy_lower,3),round(ci_accuracy_upper,3), round((ci_f1_upper+ci_f1_lower)/2,3),round(ci_f1_lower,3),round(ci_f1_upper,3)))\n",
    "    \n",
    "# Calculate metrics for each model\n",
    "MobileNetV2_sensitivity, MobileNetV2_specificity, MobileNetV2_accuracy, MobileNetV2_f1 = calculate_metrics(y_test, (MobileNetV2_pre > MobileNetV2_optimal_threshold ).astype(int))\n",
    "MobileNetV1_sensitivity, MobileNetV1_specificity, MobileNetV1_accuracy, MobileNetV1_f1 = calculate_metrics(y_test, (MobileNetV1_pre > MobileNetV1_optimal_threshold).astype(int))\n",
    "DenseNet121_sensitivity, DenseNet121_specificity, DenseNet121_accuracy, DenseNet121_f1 = calculate_metrics(y_test, (DenseNet121_pre > DenseNet121_optimal_threshold).astype(int))\n",
    "EfficientNetV2B0_sensitivity, EfficientNetV2B0_specificity, EfficientNetV2B0_accuracy, EfficientNetV2B0_f1 = calculate_metrics(y_test, (EfficientNetV2B0_pre > EfficientNetV2B0_optimal_threshold).astype(int))\n",
    "NASNetMobile_sensitivity, NASNetMobile_specificity, NASNetMobile_accuracy, NASNetMobile_f1 = calculate_metrics(y_test, (NASNetMobile_pre > NASNetMobile_optimal_threshold).astype(int))\n",
    "ResNet50_sensitivity, ResNet50_specificity, ResNet50_accuracy, ResNet50_f1 = calculate_metrics(y_test, (ResNet50_pre > ResNet50_optimal_threshold).astype(int))\n",
    "\n",
    "\n",
    "print(\"model performance(95% CI)\")\n",
    "performance_ci('MobileNetV2',y_test,MobileNetV2_pre,MobileNetV2_optimal_threshold)\n",
    "performance_ci('MobileNetV1',y_test,MobileNetV1_pre,MobileNetV1_optimal_threshold)\n",
    "performance_ci('DenseNet121',y_test,DenseNet121_pre,DenseNet121_optimal_threshold)\n",
    "performance_ci('EfficientNetV2B0',y_test,EfficientNetV2B0_pre,EfficientNetV2B0_optimal_threshold)\n",
    "performance_ci('NASNetMobile',y_test,NASNetMobile_pre,NASNetMobile_optimal_threshold)\n",
    "performance_ci('ResNet50',y_test,ResNet50_pre,ResNet50_optimal_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNetV2_sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
