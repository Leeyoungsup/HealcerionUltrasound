{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 12:01:23.231528: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-26 12:01:23.861714: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from math import isnan\n",
    "from numpy import average\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "import warnings\n",
    "size = 224\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diceloss(pred, target,threshold, num_classes=4):\n",
    "    smooth = 1.\n",
    "    dice_per_class = np.zeros(num_classes)\n",
    "    \n",
    "    for class_id in range(num_classes):\n",
    "        pred_class = pred[class_id, ...]\n",
    "        target_class = target[class_id, ...]\n",
    "\n",
    "        pred_int_class=np.where(pred_class>threshold,1,0)\n",
    "    \n",
    "        TP_pixel=np.sum(pred_int_class * target_class)\n",
    "        FP_pixel= np.sum(target_class *(1-(pred_int_class * target_class)))\n",
    "        FN_pixel= np.sum(pred_int_class *(1-(pred_int_class * target_class)))\n",
    "\n",
    "        dice_per_class[class_id] = 1 - (2. * TP_pixel) / (2. * TP_pixel + FP_pixel+FN_pixel)\n",
    "\n",
    "    return np.mean(dice_per_class)\n",
    "\n",
    "def keras2TFlite(model_path,name):\n",
    "    #load a pre-trained model\n",
    "    with tf.device('/gpu:0'):\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        #convert the model\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        tflite_model = converter.convert()\n",
    "        #save the converted model\n",
    "        with open('../../model/classification/tflite/'+name+'.tflite', 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print('Model converted successfully')\n",
    "\n",
    "def createDirectory(directory):\n",
    "    \"\"\"_summary_\n",
    "        create Directory\n",
    "    Args:\n",
    "        directory (string): file_path\n",
    "    \"\"\"    \n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "\n",
    "def TFLiteInference(model_path, name, x_test, y_test):\n",
    "    # Load TFLite model and allocate tensors.\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    with tf.device('/gpu:0'):\n",
    "        input_index = interpreter.get_input_details()[0]['index']\n",
    "        output_index  = interpreter.get_output_details()[0]['index']\n",
    "        \n",
    "        sum_correct = 0\n",
    "        sum_time=0\n",
    "        predict=np.zeros((len(x_test),4,size,size),dtype=np.float32)\n",
    "        for idx, data in tqdm(enumerate(zip(x_test,y_test))):\n",
    "            img = data[0]\n",
    "            label = data[1]\n",
    "            img= img.astype(np.float32)\n",
    "            img = tf.expand_dims(img, axis=0)\n",
    "            \n",
    "            interpreter.set_tensor(input_index, img)\n",
    "            start_time = time.time()\n",
    "            interpreter.invoke()\n",
    "            \n",
    "            output = interpreter.get_tensor(output_index)\n",
    "            stop_time = time.time()\n",
    "            sum_time += stop_time-start_time\n",
    "            \n",
    "            sum_correct+=1-diceloss(output[0], label,0.5, num_classes=4)\n",
    "            predict[idx]=output\n",
    "            mean_acc=sum_correct/float(idx+1)\n",
    "            mean_time=sum_time/float(idx+1)\n",
    "        print('Model: ',name)\n",
    "        print('Mean dice: ',mean_acc)\n",
    "        print('Mean Inference Time: ',mean_time)\n",
    "        return predict\n",
    "# keras2TFlite('../../model/classification/MobileNetV2_checkpoints.h5','MobileNetV2')\n",
    "# keras2TFlite('../../model/classification/MobileNetV1_acc_checkpoints.h5','MobileNetV1')\n",
    "# keras2TFlite('../../model/classification/DenseNet121_checkpoints.h5','DenseNet121')\n",
    "# keras2TFlite('../../model/classification/EfficientNetV2B0_checkpoints.h5','EfficientNetV2B0')\n",
    "# keras2TFlite('../../model/classification/NASNetMobile_checkpoints.h5','NASNetMobile')\n",
    "# keras2TFlite('../../model/classification/ResNet50_checkpoints.h5','ResNet50')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6349dbd0968a431d9e817fd257c4daeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/584 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\n",
    "    '../../data/segmentationDDH/test_aug_segmentation_dataset.csv')\n",
    "\n",
    "test_img_list = test_df['file name'].to_list()\n",
    "test_label_list = test_df['standard mask'].to_list()\n",
    "test_case_list = test_df['case'].to_list()\n",
    "test_img_path = '../../data/segmentationDDH/aug_dataset/test/'\n",
    "   \n",
    "x_test=np.zeros((len(test_img_list),3,size,size),dtype=np.float32)\n",
    "y_test=np.zeros((len(test_img_list),4,size,size),dtype=np.float32)\n",
    "\n",
    "for i in tqdm(range(len(test_img_list))):\n",
    "    x_test[i] = np.swapaxes(np.swapaxes(np.array(Image.open(\n",
    "        test_img_path+str(test_case_list[i])+'/image/'+test_img_list[i]).resize((size, size))),1,2),0,1)\n",
    "    y_test[i,0]=np.array(Image.open(\n",
    "        test_img_path+str(test_case_list[i])+'/mask/'+str(test_label_list[i]).zfill(5)+'/1.png').resize((size, size)))\n",
    "    y_test[i,1]=np.array(Image.open(\n",
    "        test_img_path+str(test_case_list[i])+'/mask/'+str(test_label_list[i]).zfill(5)+'/2.png').resize((size, size)))\n",
    "    y_test[i,2]=np.array(Image.open(\n",
    "        test_img_path+str(test_case_list[i])+'/mask/'+str(test_label_list[i]).zfill(5)+'/3.png').resize((size, size)))\n",
    "    y_test[i,3]=np.array(Image.open(\n",
    "        test_img_path+str(test_case_list[i])+'/mask/'+str(test_label_list[i]).zfill(5)+'/4.png').resize((size, size)))\n",
    "\n",
    "x_test = x_test/255.0\n",
    "y_test = y_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2024-02-26 12:01:39.109008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38158 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a765993241e942288f770b31a9179b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  DeepLabV3Plus\n",
      "Mean dice:  0.6241230808165933\n",
      "Mean Inference Time:  0.07776492262539798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c720da1eb4456fb20f2cf5481dae1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  NestedUNet\n",
      "Mean dice:  0.5977729413596834\n",
      "Mean Inference Time:  0.18499356916505996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5037cab078ec4a40b5c17c0f3c9551b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  PAN\n",
      "Mean dice:  0.5657209072467786\n",
      "Mean Inference Time:  0.0376259251816632\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd67f32c8624d999b7697111a513803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  UNet\n",
      "Mean dice:  0.6094783270514451\n",
      "Mean Inference Time:  0.13916936312636283\n"
     ]
    }
   ],
   "source": [
    "DeepLabV3Plus_pre=TFLiteInference('../../model/segmentation/tflite/DeepLabV3Plus.tflite','DeepLabV3Plus',x_test,y_test)\n",
    "NestedUNet_pre=TFLiteInference('../../model/segmentation/tflite/NestedUNet.tflite','NestedUNet',x_test,y_test)\n",
    "PAN_pre=TFLiteInference('../../model/segmentation/tflite/PAN.tflite','PAN',x_test,y_test)\n",
    "UNet_pre=TFLiteInference('../../model/segmentation/tflite/UNet.tflite','UNet',x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fbfe18652443b6a53605621a7300f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3823004/820554432.py:44: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  sensitivity_per_class[class_id] = TP_pixel / (TP_pixel + FN_pixel)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NestedUNet: Dice-Coeffidence = 0.664(0.625-0.702) RE = 0.625(0.585-0.664) PR = 0.713(0.677-0.750) SP  = 0.998(0.995-1.002)\n",
      "UNet: Dice-Coeffidence = 0.664(0.626-0.702) RE = 0.619(0.580-0.658) PR = 0.717(0.681-0.754) SP  = 0.998(0.995-1.002)\n",
      "DeepLabV3Plus: Dice-Coeffidence = 0.691(0.653-0.728) RE = 0.646(0.607-0.685) PR = 0.743(0.707-0.778) SP  = 0.998(0.995-1.002)\n",
      "PAN: Dice-Coeffidence = 0.646(0.608-0.685) RE = 0.612(0.572-0.651) PR = 0.688(0.651-0.726) SP  = 0.998(0.995-1.002)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def calculate_standard_error(p, n):\n",
    "    return math.sqrt((p * (1 - p)) / n)\n",
    "dsc_optim1=0\n",
    "dsc_optim2=0\n",
    "dsc_optim3=0\n",
    "dsc_optim4=0\n",
    "threshold1=0\n",
    "threshold2=0\n",
    "threshold3=0\n",
    "threshold4=0\n",
    "dsc1_1=[]\n",
    "dsc1_2=[]\n",
    "dsc2_1=[]\n",
    "dsc2_2=[]\n",
    "dsc3_1=[]\n",
    "dsc3_2=[]\n",
    "dsc4_1=[]\n",
    "dsc4_2=[]\n",
    "threshold_list=[]\n",
    "def total_performance(pred, target, threshold, num_classes=2):\n",
    "    dice_per_class = np.zeros(num_classes)\n",
    "    sensitivity_per_class = np.zeros(num_classes)\n",
    "    specificity_per_class = np.zeros(num_classes)\n",
    "    precision_per_class = np.zeros(num_classes)\n",
    "    f1_per_class = np.zeros(num_classes)\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        pred_class = pred[:, class_id, ...]\n",
    "        target_class = target[:, class_id, ...]\n",
    "\n",
    "        pred_int_class = np.where(pred_class >= threshold, 1, 0)\n",
    "\n",
    "        TP_pixel = np.sum(pred_int_class * target_class)\n",
    "        FN_pixel = np.sum(pred_int_class * (1 - target_class))\n",
    "        FP_pixel = np.sum((1 - pred_int_class) * target_class)\n",
    "        TN_pixel = np.sum((1 - pred_int_class) * (1 - target_class))\n",
    "\n",
    "        # Dice Loss\n",
    "        dice_per_class[class_id] = (2. * TP_pixel) / (2. * TP_pixel + FN_pixel + FP_pixel)\n",
    "\n",
    "        # Sensitivity\n",
    "        sensitivity_per_class[class_id] = TP_pixel / (TP_pixel + FN_pixel)\n",
    "\n",
    "        # Specificity\n",
    "        specificity_per_class[class_id] = TN_pixel / (TN_pixel + FP_pixel)\n",
    "\n",
    "        # Precision\n",
    "        precision_per_class[class_id] = TP_pixel / (TP_pixel + FP_pixel)\n",
    "\n",
    "        # F1 Score\n",
    "        f1_per_class[class_id] = 2 * (precision_per_class[class_id] * sensitivity_per_class[class_id]) / (\n",
    "                precision_per_class[class_id] + sensitivity_per_class[class_id])\n",
    "\n",
    "    return dice_per_class, sensitivity_per_class, specificity_per_class, precision_per_class, f1_per_class\n",
    "\n",
    "\n",
    "for i in tqdm(np.arange(-0.02,1.4,0.01)):\n",
    "    dice1,sensitivity1,specificity1, precision1, f1_1=total_performance(NestedUNet_pre[:], y_test[:],i)\n",
    "    dice1=dice1\n",
    "    sensitivity1=sensitivity1\n",
    "    dsc1_1.append(dice1[0].item())\n",
    "    dsc1_2.append(dice1[1].item())\n",
    "    dice2,sensitivity2,specificity2, precision2, f2_1=total_performance(UNet_pre[:], y_test[:],i)\n",
    "    dice2=dice2\n",
    "    sensitivity2=sensitivity2\n",
    "    dsc2_1.append(dice2[0].item())\n",
    "    dsc2_2.append(dice2[1].item())\n",
    "    dice3,sensitivity3,specificity3, precision3, f3_1=total_performance(DeepLabV3Plus_pre[:], y_test[:],i)\n",
    "    dice3=dice3\n",
    "    sensitivity1=sensitivity1\n",
    "    dsc3_1.append(dice3[0].item())\n",
    "    dsc3_2.append(dice3[1].item())\n",
    "    dice4,sensitivity4,specificity4, precision4, f4_1=total_performance(PAN_pre [:], y_test[:],i)\n",
    "    dice4=dice4\n",
    "    sensitivity4=sensitivity4\n",
    "    dsc4_1.append(dice4[0].item())\n",
    "    dsc4_2.append(dice4[1].item())\n",
    "    threshold_list.append(i)\n",
    "    if ((dice1[0].item()+dice1[1].item())/2)>=dsc_optim1:\n",
    "        dsc_optim1=((dice1[0].item()+dice1[1].item())/2)\n",
    "        threshold1=i\n",
    "        \n",
    "    if ((dice2[0].item()+dice2[1].item())/2)>=dsc_optim2:\n",
    "        dsc_optim2=((dice2[0].item()+dice2[1].item())/2)\n",
    "        threshold2=i\n",
    "        \n",
    "    if ((dice3[0].item()+dice3[1].item())/2)>=dsc_optim3:\n",
    "        dsc_optim3=((dice3[0].item()+dice3[1].item())/2)\n",
    "        threshold3=i\n",
    "        \n",
    "    if ((dice4[0].item()+dice4[1].item())/2)>=dsc_optim4:\n",
    "        dsc_optim4=((dice4[0].item()+dice4[1].item())/2)\n",
    "        threshold4=i\n",
    "# 표본 크기가 필요하다면 데이터에서 얻을 수 있습니다.\n",
    "n_NestedUNet = len(NestedUNet_pre)\n",
    "n_UNet = len(UNet_pre)\n",
    "n_DeepLabV3Plus = len(DeepLabV3Plus_pre)\n",
    "n_PAN = len(PAN_pre )\n",
    "\n",
    "# 성능 지표에 대한 확률 추정\n",
    "p_NestedUNet = dsc_optim1  # 또는 NestedUNet_sensitivity\n",
    "p_UNet = dsc_optim2  # 또는 UNet_sensitivity\n",
    "p_DeepLabV3Plus = dsc_optim3  # 또는 NestedUNet_sensitivity\n",
    "p_PAN = dsc_optim4  # 또는 UNet_sensitivity\n",
    "\n",
    "# 95% 신뢰구간 계산\n",
    "NestedUNet_dice_ci = (p_NestedUNet - 1.96 * calculate_standard_error(p_NestedUNet, n_NestedUNet),\n",
    "                  p_NestedUNet + 1.96 * calculate_standard_error(p_NestedUNet, n_NestedUNet))\n",
    "\n",
    "UNet_dice_ci = (p_UNet - 1.96 * calculate_standard_error(p_UNet, n_UNet),\n",
    "                   p_UNet + 1.96 * calculate_standard_error(p_UNet, n_UNet))\n",
    "\n",
    "DeepLabV3Plus_dice_ci = (p_DeepLabV3Plus - 1.96 * calculate_standard_error(p_DeepLabV3Plus, n_DeepLabV3Plus),\n",
    "                  p_DeepLabV3Plus + 1.96 * calculate_standard_error(p_DeepLabV3Plus, n_DeepLabV3Plus))\n",
    "\n",
    "PAN_dice_ci = (p_PAN - 1.96 * calculate_standard_error(p_PAN, n_PAN),\n",
    "                   p_PAN + 1.96 * calculate_standard_error(p_PAN, n_PAN))\n",
    "\n",
    "dice1,sensitivity1,specificity1, precision1, f1_1=total_performance(NestedUNet_pre, y_test,threshold1)\n",
    "dice2,sensitivity2,specificity2, precision2, f1_2=total_performance(UNet_pre, y_test,threshold2)\n",
    "dice3,sensitivity3,specificity3, precision3, f1_3=total_performance(DeepLabV3Plus_pre, y_test,threshold3)\n",
    "dice4,sensitivity4,specificity4, precision4, f1_4=total_performance(PAN_pre , y_test,threshold4)\n",
    "p_NestedUNet = ((sensitivity1[0].item()+sensitivity1[1].item())/2)\n",
    "p_UNet = ((sensitivity2[0].item()+sensitivity2[1].item())/2)\n",
    "p_DeepLabV3Plus = ((sensitivity3[0].item()+sensitivity3[1].item())/2)\n",
    "p_PAN = ((sensitivity4[0].item()+sensitivity4[1].item())/2)\n",
    "\n",
    "NestedUNet_sensitivity_ci = (p_NestedUNet - 1.96 * calculate_standard_error(p_NestedUNet, n_NestedUNet),\n",
    "                  p_NestedUNet + 1.96 * calculate_standard_error(p_NestedUNet, n_NestedUNet))\n",
    "\n",
    "UNet_sensitivity_ci = (p_UNet - 1.96 * calculate_standard_error(p_UNet, n_UNet),\n",
    "                   p_UNet + 1.96 * calculate_standard_error(p_UNet, n_UNet))\n",
    "DeepLabV3Plus_sensitivity_ci = (p_DeepLabV3Plus - 1.96 * calculate_standard_error(p_DeepLabV3Plus, n_DeepLabV3Plus),\n",
    "                  p_DeepLabV3Plus + 1.96 * calculate_standard_error(p_DeepLabV3Plus, n_DeepLabV3Plus))\n",
    "\n",
    "PAN_sensitivity_ci = (p_PAN - 1.96 * calculate_standard_error(p_PAN, n_PAN),\n",
    "                   p_PAN + 1.96 * calculate_standard_error(p_PAN, n_PAN))\n",
    "\n",
    "p_NestedUNet = ((specificity1[0].item()+specificity1[1].item())/2)\n",
    "p_UNet = ((specificity2[0].item()+specificity2[1].item())/2)\n",
    "p_DeepLabV3Plus = ((specificity3[0].item()+specificity3[1].item())/2)\n",
    "p_PAN = ((specificity4[0].item()+specificity4[1].item())/2)\n",
    "\n",
    "NestedUNet_specificity_ci = (p_NestedUNet - 1.96 * calculate_standard_error(p_NestedUNet, n_NestedUNet),\n",
    "                  p_NestedUNet + 1.96 * calculate_standard_error(p_NestedUNet, n_NestedUNet))\n",
    "\n",
    "UNet_specificity_ci = (p_UNet - 1.96 * calculate_standard_error(p_UNet, n_UNet),\n",
    "                   p_UNet + 1.96 * calculate_standard_error(p_UNet, n_UNet))\n",
    "DeepLabV3Plus_specificity_ci = (p_DeepLabV3Plus - 1.96 * calculate_standard_error(p_DeepLabV3Plus, n_DeepLabV3Plus),\n",
    "                  p_DeepLabV3Plus + 1.96 * calculate_standard_error(p_DeepLabV3Plus, n_DeepLabV3Plus))\n",
    "\n",
    "PAN_specificity_ci = (p_PAN - 1.96 * calculate_standard_error(p_PAN, n_PAN),\n",
    "                   p_PAN + 1.96 * calculate_standard_error(p_PAN, n_PAN))\n",
    "\n",
    "p_NestedUNet = ((precision1[0].item()+precision1[1].item())/2)\n",
    "p_UNet = ((precision2[0].item()+precision2[1].item())/2)\n",
    "p_DeepLabV3Plus = ((precision3[0].item()+precision3[1].item())/2)\n",
    "p_PAN = ((precision4[0].item()+precision4[1].item())/2)\n",
    "\n",
    "NestedUNet_precision_ci = (p_NestedUNet - 1.96 * calculate_standard_error(p_NestedUNet, n_NestedUNet),\n",
    "                  p_NestedUNet + 1.96 * calculate_standard_error(p_NestedUNet, n_NestedUNet))\n",
    "\n",
    "UNet_precision_ci = (p_UNet - 1.96 * calculate_standard_error(p_UNet, n_UNet),\n",
    "                   p_UNet + 1.96 * calculate_standard_error(p_UNet, n_UNet))\n",
    "DeepLabV3Plus_precision_ci = (p_DeepLabV3Plus - 1.96 * calculate_standard_error(p_DeepLabV3Plus, n_DeepLabV3Plus),\n",
    "                  p_DeepLabV3Plus + 1.96 * calculate_standard_error(p_DeepLabV3Plus, n_DeepLabV3Plus))\n",
    "\n",
    "PAN_precision_ci = (p_PAN - 1.96 * calculate_standard_error(p_PAN, n_PAN),\n",
    "                   p_PAN + 1.96 * calculate_standard_error(p_PAN, n_PAN))\n",
    "\n",
    "\n",
    "p_NestedUNet = ((f1_1[0].item()+f1_1[1].item())/2)\n",
    "p_UNet = ((f1_2[0].item()+f1_2[1].item())/2)\n",
    "p_DeepLabV3Plus = ((f1_3[0].item()+f1_3[1].item())/2)\n",
    "p_PAN = ((f1_4[0].item()+f1_4[1].item())/2)\n",
    "\n",
    "NestedUNet_f1_ci = (p_NestedUNet - 1.96 * calculate_standard_error(p_NestedUNet, n_NestedUNet),\n",
    "                  p_NestedUNet + 1.96 * calculate_standard_error(p_NestedUNet, n_NestedUNet))\n",
    "\n",
    "UNet_f1__ci = (p_UNet - 1.96 * calculate_standard_error(p_UNet, n_UNet),\n",
    "            p_UNet + 1.96 * calculate_standard_error(p_UNet, n_UNet))\n",
    "DeepLabV3Plus_f1_ci = (p_DeepLabV3Plus - 1.96 * calculate_standard_error(p_DeepLabV3Plus, n_DeepLabV3Plus),\n",
    "                  p_DeepLabV3Plus + 1.96 * calculate_standard_error(p_DeepLabV3Plus, n_DeepLabV3Plus))\n",
    "\n",
    "PAN_f1_ci = (p_PAN - 1.96 * calculate_standard_error(p_PAN, n_PAN),\n",
    "                   p_PAN + 1.96 * calculate_standard_error(p_PAN, n_PAN))\n",
    "\n",
    "print(f\"NestedUNet: Dice-Coeffidence = {dsc_optim1:.3f}({NestedUNet_dice_ci[0]:.3f}-{NestedUNet_dice_ci[1]:.3f}) RE = {(NestedUNet_sensitivity_ci[0]+NestedUNet_sensitivity_ci[1])/2:.3f}({NestedUNet_sensitivity_ci[0]:.3f}-{NestedUNet_sensitivity_ci[1]:.3f}) PR = {(NestedUNet_precision_ci[0]+NestedUNet_precision_ci[1])/2:.3f}({NestedUNet_precision_ci[0]:.3f}-{NestedUNet_precision_ci[1]:.3f}) SP  = {(NestedUNet_specificity_ci[0]+NestedUNet_specificity_ci[1])/2:.3f}({NestedUNet_specificity_ci[0]:.3f}-{NestedUNet_specificity_ci[1]:.3f})\")\n",
    "print(f\"UNet: Dice-Coeffidence = {dsc_optim2:.3f}({UNet_dice_ci[0]:.3f}-{UNet_dice_ci[1]:.3f}) RE = {(UNet_sensitivity_ci[0]+UNet_sensitivity_ci[1])/2:.3f}({UNet_sensitivity_ci[0]:.3f}-{UNet_sensitivity_ci[1]:.3f}) PR = {(UNet_precision_ci[0]+UNet_precision_ci[1])/2:.3f}({UNet_precision_ci[0]:.3f}-{UNet_precision_ci[1]:.3f}) SP  = {(UNet_specificity_ci[0]+UNet_specificity_ci[1])/2:.3f}({UNet_specificity_ci[0]:.3f}-{UNet_specificity_ci[1]:.3f})\")\n",
    "print(f\"DeepLabV3Plus: Dice-Coeffidence = {dsc_optim3:.3f}({DeepLabV3Plus_dice_ci[0]:.3f}-{DeepLabV3Plus_dice_ci[1]:.3f}) RE = {(DeepLabV3Plus_sensitivity_ci[0]+DeepLabV3Plus_sensitivity_ci[1])/2:.3f}({DeepLabV3Plus_sensitivity_ci[0]:.3f}-{DeepLabV3Plus_sensitivity_ci[1]:.3f}) PR = {(DeepLabV3Plus_precision_ci[0]+DeepLabV3Plus_precision_ci[1])/2:.3f}({DeepLabV3Plus_precision_ci[0]:.3f}-{DeepLabV3Plus_precision_ci[1]:.3f}) SP  = {(DeepLabV3Plus_specificity_ci[0]+DeepLabV3Plus_specificity_ci[1])/2:.3f}({DeepLabV3Plus_specificity_ci[0]:.3f}-{DeepLabV3Plus_specificity_ci[1]:.3f})\")\n",
    "print(f\"PAN: Dice-Coeffidence = {dsc_optim4:.3f}({PAN_dice_ci[0]:.3f}-{PAN_dice_ci[1]:.3f}) RE = {(PAN_sensitivity_ci[0]+PAN_sensitivity_ci[1])/2:.3f}({PAN_sensitivity_ci[0]:.3f}-{PAN_sensitivity_ci[1]:.3f}) PR = {(PAN_precision_ci[0]+PAN_precision_ci[1])/2:.3f}({PAN_precision_ci[0]:.3f}-{PAN_precision_ci[1]:.3f}) SP  = {(PAN_specificity_ci[0]+PAN_specificity_ci[1])/2:.3f}({PAN_specificity_ci[0]:.3f}-{PAN_specificity_ci[1]:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
